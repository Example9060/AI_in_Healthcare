[
  {
    "title": "White House releases AI Action Plan, looks to speed adoption in healthcare - Fierce Healthcare",
    "url": "https://news.google.com/rss/articles/CBMiwgFBVV95cUxORzZCZnVTeWZYSF9HZEItY1ZjZ09zYmpPRXgxN2J3VjRaVXRJTURVMkpkLXFSMk1EYVdpcEpBSTRVaUU0QkFhV2VCd1EzNUtmV3UxMXhQdnhkOXR3UEVHVjZDVGxlSjZzQ3hCSUphUVZ6aE9FWFhteDRoNGtjLWtBcEZWcm5vMVRudDE0d3d6QUZFNGw0ZXBCTmZFTkpPaEVjSDNQWjltVExuWHJveUxWd1VLUjJHcTN5MFpiQllNandyZw?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data. You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page. \nCloudflare Ray ID: 964633ba79a52577\n•\n\n      Your IP:\n      Click to reveal\n34.23.160.127\n•\n\nPerformance & security by Cloudflare"
  },
  {
    "title": "Cedars-Sinai's AI tool delivered 24/7 care to 42,000 patients. Now, doctors can focus more on treatment, less on paperwork. - Business Insider",
    "url": "https://news.google.com/rss/articles/CBMiswFBVV95cUxOOHdyZ2M4TEFHc3oySlo0b0NjaS1OZVRjME1KdXJPR1huS3RRUFdPc1ZCcjBkMUZZZlQzX1lMOGktTElsRGl2NWV2NmhiMFg5ZWV5Nzc3TmRqeHZXTk9KUnJ3ekpEQmdPNC1Dc2otU1FPMEtDRGxpeTZTdG16MTg4eVZieXJ1aGVOZWxKQ25JSndnZlVqRjd4MURySTNuMDFUbmIzekNCdTg3Vy01TG53VnptVQ?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "CXO AI Playbook Presented by Cedars-Sinai is a nonprofit healthcare organization based in Los Angeles. It's comprised of hospitals, clinics, and research facilities. Founded in 1902, Cedars-Sinai has more than 40 locations, employs over 4,500 physicians and nurses, and serves more than 1 million patients every year. Caroline Goldzweig, chief medical officer of Cedars-Sinai Medical Network, told Business Insider that the organization wanted to expand patients' access to primary care in a more efficient and convenient way. For instance, sometimes there are lengthy wait times for in-person doctor's appointments. At the same time, Goldzweig said the organization was looking to reduce the administrative burden on physicians, including patient intake and data entry, so that they could focus on providing care. To address these challenges, the organization launched Cedars-Sinai Connect in 2023. CS Connect is an artificial intelligence-powered virtual platform where patients can access healthcare support 24/7. Goldzweig said the AI technology allows healthcare providers to better support their patients while improving the speed of care delivery. \"The other exciting thing is the ability to offer patients care in ways that meet their needs,\" she said. Goldzweig told Business Insider that CS Connect was built using K Health, a digital healthcare company providing AI-powered primary and urgent care services. Cedars-Sinai's information technology teams worked with K Health to sync patients' electronic health records into the platform, she said. Cedars-Sinai's enterprise data intelligence and digital strategy teams were also involved in creating CS Connect. They continue to help manage it. The goal of the AI tool is to enable providers to spend more time counseling patients and making treatment decisions, rather than doing patient intake. To access the AI features, patients log into CS Connect via a mobile app or its website. Goldzweig said a chat feature then starts asking the user questions about their symptoms. The AI algorithm compares the patient's responses to their existing medical records and the records of other patients in the system who had similar symptoms. It then asks more detailed questions about a patient's specific health problems. The chatbot, for example, may prompt the patient to submit photos of their sore throat or rash. Goldzweig said the chat function is similar to how a physician might identify a patient's ailment. The AI then summarizes the patient's information — a task that usually demands manual effort from physicians — and recommends a treatment. The data collected by CS Connect is \"part of the efficiency process,\" Goldzweig said. \"It allows the physicians to review it, to understand what's going on, and to validate things with the patient — ask a couple of clarifying questions and maybe get a little bit more history.\" Physicians can choose to disagree with the AI's recommendations. Goldzweig said either way, they're required to sign off on each patient's treatment plan. Goldzweig told BI that about 42,000 individual patients have used CS Connect. In April 2025, Cedars-Sinai published a study in the journal Annals of Internal Medicine comparing AI treatment recommendations in CS Connect with final recommendations from doctors. The study reviewed 461 physician-managed visits with AI recommendations for respiratory, urinary, vaginal, eye, and dental symptoms. Results showed that when AI and physician recommendations differed, the AI suggestions were often rated as higher quality. The study found that 77% of AI recommendations were rated as optimal, while 67% of physicians' decisions were rated optimal. For example, patients with recurring urinary tract infections sometimes encounter antibiotic resistance. Goldzweig said the AI was successful at identifying these patients and recommended a bacterial culture before prescribing antibiotics. In contrast, doctors sometimes prescribe medication without testing, which she said could result in the infection coming back. Goldzweig added that the study suggests that the AI tool tends to be more guideline-focused, while physicians have the ability to adapt medical guidelines based on the nuance of a patient's case. Goldzweig said the study has limitations, though. It examined only a few medical conditions and didn't factor in the nuance of individual patient cases. Another limitation is that the medical chart reviewers could see whether the recommendation was made by the AI or a physician. Cedars-Sinai is working to expand CS Connect. The organization is piloting remote patient monitoring technology using AI to help people manage chronic diseases, like high blood pressure. It's also planning to use the AI technology to connect in-person urgent care visits with virtual care.         Jump to"
  },
  {
    "title": "Waystar to Acquire Iodine Software, Accelerating the AI-Powered Transformation of Healthcare Payments - PR Newswire",
    "url": "https://news.google.com/rss/articles/CBMi7AFBVV95cUxPVU0ydHhpWWNzOGV2U1AwTUdaQWdGZ1BIeHVDUDFpaUpOWXFYdUNWY0tUR0J2SkVzYkZYLUREQ2Nfdm5taGJVRVhGbW5iNHh6NDVaYWNXc3Jsald5UXJ3VUZCbUxXa19wN1lFdFM2cU5ZVFNPMllKMkhfY0UzZ0RGUW0yVFFBX1BaX2JfbEFDQ0FGUVhOTUp4OFpSeElCNDV2ZVhGQTh0OTB6Y05uczAtX29lU0NRY1hDN3Q5UHk1NWV2Z3YyZUwyMlpEejhQd1lxM0JLWWdzSS1sdmVlaXhxVDFwQktSTl82SnBnSg?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Searching for your content... \n                        In-Language News\n                     \nContact Us\n \n 888-776-0942\n\nfrom 8 AM - 10 PM ET\n Jul 23, 2025, 16:31 ET Share this article Extends Waystar's AI leadership into clinical intelligence software, unlocking greater value for clients and shareholders Highly recurring subscription-based business projected to be accretive to Waystar's financial profile  Expected to expand Waystar's total addressable market by more than 15% Conference call to be held Wednesday, July 23, 2025, at 5:30 p.m. ET LEHI, Utah and LOUISVILLE, Ky., and AUSTIN, Texas, July 23, 2025 /PRNewswire/ -- Waystar (Nasdaq: WAY), a provider of leading healthcare payment software, today announced a definitive agreement to acquire 100% of Iodine Software (\"Iodine\") from shareholders led by Advent International, a leading global private equity investor, for a total enterprise value of $1.25 billion. The proposed transaction is expected to accelerate Waystar's ability to transform healthcare payments through its leading cloud-based software platform, empowering more than one million providers with advanced AI capabilities to prevent denials, reduce manual work, and improve financial performance. Building on Waystar's track record of successful M&A execution and synergy realization, Waystar expects the acquisition of Iodine to be immediately accretive to gross margin and adjusted EBITDA margin, and accretive to revenue growth and non-GAAP net income per diluted share in 2027.  Iodine is trusted by many of the nation's premier health systems for its AI-powered clinical intelligence software. Up to 60 million claims are denied each year due to administrative errors in the critical stage between care delivery and submission, costing providers billions in lost revenue. This highlights the essential role of accurate clinical documentation and coding in preventing revenue leakage and underpayments. Together, Waystar and Iodine will be better positioned to help decrease the estimated $440 billion in annual administrative costs1 burdening providers. Waystar brings a decade-long track record of applying AI pervasively across its software platform to simplify healthcare payments. Iodine extends that leadership into clinical intelligence software, leveraging proprietary AI models trained on one of the industry's largest clinical datasets, representing more than a third of all U.S. inpatient discharges. \"Our mission is to simplify healthcare payments by eradicating unnecessary denied claims, automating manual work, and increasing transparency for providers and patients,\" said Matt Hawkins, Chief Executive Officer of Waystar. \"We are committed to transforming healthcare through harnessing the power of AI to tackle the most critical challenges in healthcare payments. Welcoming Iodine's talented team and clinical intelligence platform to Waystar is a terrific next step in achieving our mission.\" \"We are proud to have built a market-leading AI software company in partnership with Advent, Bain Capital Ventures, and Silversmith Capital Partners, and are thrilled to join Waystar, an organization that shares our deep commitment to modernizing the revenue cycle for providers,\" said William Chan, Co-Founder and Chief Executive Officer of Iodine Software. \"From day one, our focus has been helping hospitals and health systems capture the full value of care through transformational AI. As part of Waystar, we are excited to accelerate that mission and amplify the value delivered to healthcare providers.\" \"Our success has been driven by strong partnerships, continuous innovation, and meaningful outcomes,\" added Mike Kadyan, Co-Founder and Chairman of Iodine Software. \"We look forward to delivering even greater outcomes for providers as part of Waystar's market-leading platform.\" \"It has been a privilege to partner alongside the Iodine team as they have built a category-defining AI-powered revenue cycle platform consistently delivering exceptional ROI to its clients,\" said Lauren Young and Carmine Petrone, Managing Directors at Advent. \"We are excited to build on that foundation together with Waystar to drive even greater impact across healthcare, empowering organizations to optimize their financial performance.\" Strategic and Financial Benefits Transaction DetailsThe transaction will be funded with a 50/50 mix of cash and stock consideration. Upon closing of the transaction, current Waystar shareholders will own approximately 92% of the combined company on a fully diluted, pro forma basis and Iodine equity holders will own approximately 8%. Advent, Iodine's largest shareholder, is expected to only receive Waystar shares in connection with the transaction and will agree to be locked up for 18 months after closing. Following the transaction, Waystar expects to maintain a strong balance sheet with an estimated adjusted net leverage ratio at transaction close of approximately 3.5x. The transaction is anticipated to close by year-end 2025, subject to customary closing conditions and applicable regulatory approvals. Preliminary Second Quarter 2025 ResultsWaystar expects second quarter 2025 revenue to be approximately $271 million, representing approximately 15% year-over-year growth. The foregoing estimates are preliminary and unaudited and based on management's initial analysis of operations for the quarter. Waystar looks forward to sharing additional information regarding the company's second quarter 2025 results as previously scheduled on July 30, 2025. AdvisorsBarclays is serving as exclusive financial advisor, and Simpson Thacher & Bartlett LLP is serving as legal advisor to Waystar. J.P. Morgan Securities is serving as exclusive financial advisor, and Weil, Gotshal & Manges LLP and Queen Saenz + Schultz PLLC are serving as legal advisors to Iodine. Conference CallWaystar will discuss the transaction on a conference call today, Wednesday, July 23, 2025, at 5:30 p.m. Eastern Time. The conference call can be accessed by dialing (800) 715-9871 from the United States and Canada or (646) 307-1963 internationally and using conference code 8810133. A live audio webcast of the conference call will be available on Waystar's investor relations website at investors.waystar.com/news-events/events. Following the call, an audio replay will be archived on the site. About WaystarWaystar's mission-critical software is purpose-built to simplify healthcare payments so providers can prioritize patient care and optimize their financial performance. Waystar serves approximately 30,000 clients, representing over 1 million distinct providers, including 16 of 20 institutions on the U.S. News Best Hospitals list. Waystar's enterprise-grade platform annually processes over 6 billion healthcare payment transactions, including over $1.8 trillion in annual gross claims and spanning approximately 50% of U.S. patients. Waystar strives to transform healthcare payments so providers can focus on what matters most: their patients and communities. Discover the way forward at waystar.com. About Iodine Software Iodine Software is the leader in AI-powered clinical intelligence, built to eliminate revenue leakage, lower administrative burden, and ensure accurate reimbursement. Trusted by more than 1,000 hospitals and health systems, Iodine delivers real-time insight and automation across the mid-revenue cycle: connecting clinical documentation, utilization management, and prebill workflows from admission through claim submission. For over a decade, health systems have trusted Iodine to apply the right AI – from machine learning, deep learning, large language models, GenAI, to Agentic AI – to the right use case, consistently delivering reliable, high-impact financial results. At the core of the platform is IodineIQ, our proprietary Clinical Reasoning Knowledge Engine, featuring a robust clinical condition library and a dataset of millions of patient encounters and billions of clinical data points. IodineIQ mirrors clinical reasoning to surface opportunities, predict outcomes, and guide decisions; ensuring the patient's clinical picture is fully and accurately reflected in status, documentation, and final codes. Discover more at www.iodinesoftware.com.  About AdventAdvent is a leading global private equity investor committed to working in partnership with management teams, entrepreneurs, and founders to help transform businesses. With 16 offices across five continents, we oversee more than USD $94 billion in assets under management* and have made over 430 investments across 44 countries. Since our founding in 1984, we have developed specialist market expertise across our five core sectors: business & financial services, consumer, healthcare, industrial, and technology. This approach is bolstered by our deep sub-sector knowledge, which informs every aspect of our investment strategy, from sourcing opportunities to working in partnership with management to execute value creation plans. We bring hands-on operational expertise to enhance and accelerate businesses. As one of the largest privately-owned partnerships, our 660+ colleagues leverage the full ecosystem of Advent's global resources, including our Portfolio Support Group, insights provided by industry expert Operating Partners and Operations Advisors, as well as bespoke tools to support and guide our portfolio companies as they seek to achieve their strategic goals. To learn more, visit our website or connect with us on LinkedIn. *Assets under management (AUM) as of March 31, 2025. AUM includes assets attributable to Advent advisory clients as well as employee and third-party co-investment vehicles. Forward-Looking StatementsThis press release contains forward-looking statements, within the meaning of the Private Securities Litigation Reform Act of 1995, that reflect our current views with respect to, among other things, statements regarding Waystar's expectations relating to future operating results and financial position, including full year 2025, and future periods; anticipated future investments; our industry, business strategy, goals, and deployment of artificial intelligence in our solutions, our market position, offerings, future operations, margins, and profitability. Forward-looking statements include all statements that are not historical facts. These statements may include words such as \"anticipate,\" \"assume,\" \"believe,\" \"continue,\" \"could,\" \"estimate,\" \"expect,\" \"intend,\" \"may,\" \"plan,\" \"potential,\" \"predict,\" \"project,\" \"future,\" \"will,\" \"seek,\" \"foreseeable,\" \"outlook,\" the negative version of these words or similar terms and phrases to identify forward-looking statements in this press release, including any discussion of our guidance for full fiscal year 2025. The forward-looking statements contained in this press release are based on management's current expectations and are not guarantees of future performance. The forward-looking statements are subject to various risks, uncertainties, assumptions, or changes in circumstances that are difficult to predict or quantify. Our expectations, beliefs, and projections are expressed in good faith, and we believe there is a reasonable basis for them. However, there can be no assurance that management's expectations, beliefs, and projections will result or be achieved. The following factors are among those that may cause actual results to differ materially from the forward-looking statements: our operation in a highly competitive industry; our ability to retain our existing clients and attract new clients; our ability to successfully execute on our business strategies in order to grow; our ability to accurately assess the risks related to acquisitions and successfully integrate acquired businesses (including our proposed acquisition of Iodine); our ability to establish and maintain strategic relationships; the growth and success of our clients and overall healthcare transaction volumes; consolidation in the healthcare industry; our selling cycle of variable length to secure new client agreements; our implementation cycle that is dependent on our clients' timing and resources; our dependence on our senior management team and certain key employees, and our ability to attract and retain highly skilled employees; the accuracy of the estimates and assumptions we use to determine the size of our total addressable market; our ability to develop and market new solutions, or enhance our existing solutions, to respond to technological changes, or evolving industry standards; the interoperability, connectivity, and integration of our solutions with our clients' and their vendors' networks and infrastructures; the performance and reliability of internet, mobile, and other infrastructure; the consequences if we cannot obtain, process, use, disclose, or distribute the highly regulated data we require to provide our solutions; our reliance on certain third-party vendors and providers; any errors or malfunctions in our products and solutions; failure by our clients to obtain proper permissions or provide us with accurate and appropriate information; the potential for embezzlement, identity theft, or other similar illegal behavior by our employees or vendors, and a failure of our employees or vendors to observe quality standards or adhere to environmental, social, and governance standards; our compliance with the applicable rules of the National Automated Clearing House Association and the applicable requirements of card networks; increases in card network fees and other changes to fee arrangements; the effect of payer and provider conduct which we cannot control; privacy concerns and security breaches or incidents relating to our platform; the complex and evolving laws and regulations regarding privacy, data protection, and cybersecurity; our ability to adequately protect and enforce our intellectual property rights; our ability to use or license data and integrate third-party technologies; our use of \"open source\" software; legal proceedings initiated by third parties alleging that we are infringing or otherwise violating their intellectual property rights; claims that our employees, consultants, or independent contractors have wrongfully used or disclosed confidential information of third parties; the heavily regulated industry in which we conduct business; the uncertain and evolving healthcare regulatory and political framework; health care laws and data privacy and security laws and regulations governing our processing of personal information; reduced revenues in response to changes to the healthcare regulatory landscape; legal, regulatory, and other proceedings that could result in adverse outcomes; consumer protection laws and regulations; contractual obligations requiring compliance with certain provisions of the Bank Secrecy Act and anti-money laundering laws and regulations; existing laws that regulate our ability to engage in certain marketing activities; our full compliance with website accessibility standards; any changes in our tax rates, the adoption of new tax legislation, or exposure to additional tax liabilities; limitations on our ability to use our net operating losses to offset future taxable income ; losses due to asset impairment charges; restrictive covenants in the agreements governing our credit facilities; interest rate fluctuations; unavailability of additional capital on acceptable terms or at all; the impact of general macroeconomic conditions; our history of net losses and our ability to achieve or maintain profitability; actions of certain of our significant investors, who may have different interests than the interests of other holders of our securities; and each of the other factors discussed under the heading of \"Risk Factors\" in the Company's 10-K filed with the Securities and Exchange Commission (the \"SEC\") on February 18, 2025, and in other reports filed with the SEC, all of which are available on the Investor Relations page of our website at investors.waystar.com. Any forward-looking statements made by us in this press release speak only as of the date of this press release and are expressly qualified in their entirety by the cautionary statements included in this press release. Factors or events that could cause our actual results to differ may emerge from time to time, and it is not possible for us to predict all of them. You should not place undue reliance on our forward-looking statements. We undertake no obligation to publicly update or review any forward-looking statement, whether as a result of new information, future developments, or otherwise, except as may be required by any applicable securities laws. Waystar Media ContactKristin Leekristin.lee@waystar.com Daniel Yunger / Nick Capuano / Mark FallatiKekst CNCkekst-waystar@kekstcnc.com Waystar Investor Contactinvestors@waystar.com Iodine Software Media ContactMichelle Whitemjwhite@iodinesoftware.com Isabella MorrealeSolCommsisabella@solcomms.com 1 CAQH Index Report 2024 SOURCE Waystar Waystar Holding Corp. (Nasdaq: WAY), a provider of leading healthcare payment software, announced today that it will report financial results for the ... Waystar (Nasdaq: WAY), a provider of leading healthcare payment software, today announced the results of a commissioned study conducted by Forrester... Financial Technology Financial Technology Banking & Financial Services Artificial Intelligence Do not sell or share my personal information:"
  },
  {
    "title": "The damage AI hallucinations can do – and how to avoid them - Healthcare IT News",
    "url": "https://news.google.com/rss/articles/CBMikgFBVV95cUxNZVBEWUlsUENoVFdISUFMLXFLME5UQ3ctUUpNUDAxQXdDTEViQVFYVlc4MmtmQmxkQWFxWF9DbkExT2tGendrbVpiMnZTRXIwaEg5dFZwUkJYMTBlcVpDSFljeEdRTEJPUW5OOG4tTXo5QkQ5QlNuS3lFMFB4UHJRenQxQndQSkdUa09tRHNLMV9mdw?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Health systems are embracing artificial intelligence tools that help their clinicians simplify the creation of chart notes and care plans, saving them precious time every day.  But what's the impact on patient safety if AI gets the facts wrong? Even the most casual users of ChatGPT and other large language model-based generative AI tools have experienced errors – often called \"hallucinations.\" An AI hallucination occurs when an LLM cannot find an appropriate answer and simply makes something up. Essentially, when an LLM doesn't know the correct answer or can't locate appropriate information, it fabricates a response, rather than admitting uncertainty. These fabricated responses are particularly problematic  because they're often very convincing. The hallucinations can be very difficult to distinguish from factual information, depending on what's being asked. If an LLM can't find the right medical code for a particular condition or procedure, for example, it might invent a number. The core issue is that LLMs are designed to predict the next word and provide responses, not to acknowledge when they don't have sufficient information. That creates a fundamental tension between the technology's drive to be helpful and its tendency to generate plausible sounding but inaccurate content when faced with uncertainty. For some further perspective on AI hallucinations and their potential impact on healthcare, we spoke recently with Dr. Jay Anders, chief medical officer at Medicomp Systems, a vendor of evidence-based, clinical AI-powered systems designed to make data usable for connected care and enhanced decision making. He plays a key role in product development and acts as a liaison to the healthcare community. Q. What does AI's ability to generate hallucinations mean for clinical and administrative staff in healthcare wanting to use AI? A. The implications are significantly different for clinical versus administrative applications. In clinical medicine, hallucinations create serious problems because accuracy isn't negotiable. I recently read a study showing AI summarization gets things right about 80% of the time. That might earn you a B-minus in college, but B-minus doesn't work in healthcare. Nobody wants B-minus healthcare – they want A-level care. Let me give you specific examples from clinical record summarization, which many healthcare IT companies are rushing to implement. When AI summarizes clinical records, it can make two critical errors. First, it may fabricate information that simply isn't there. Second, it can misattribute diseases – taking a family member's condition and assigning it to the patient. So, if I mention \"my mother has diabetes,\" the AI might document that I have diabetes instead. AI also struggles with context. If I'm discussing a physical exam, it might introduce elements that have nothing to do with physical examinations. It loses track of what we're actually talking about. For administrative tasks, the risks are generally lower. If AI makes errors in equipment inventory, pharmacy supplies or scheduling, while problematic, these mistakes won't directly harm patients. The stakes are fundamentally different when we're dealing with clinical documentation versus operational logistics. Q. What are potential negative outcomes of hallucinations in healthcare AI, and how can they propagate through processes and systems? A. The negative outcomes operate on multiple levels and create cascading effects that are extremely difficult to reverse. When AI assigns incorrect diseases, lab results or medications to a patient's record, these errors become nearly impossible to correct and can have devastating long-term consequences. Consider this scenario. If AI incorrectly documents that I have leukemia based on my mother's medical history, how will I get life insurance? Will employers want to hire someone they believe has active leukemia? These errors create immediate and long-term impacts that extend far beyond the healthcare setting. The propagation problem is particularly insidious. Once incorrect information enters a medical record, it gets copied and shared across multiple systems and providers. Even if I, as a physician, catch the error and document a correction, that original record already has been sent to numerous other healthcare providers who won't receive my correction. It becomes like a dangerous game of telephone – the error spreads throughout the healthcare network, and each iteration makes it more difficult to trace and correct. This creates two types of propagation: The spread of actual errors and the erosion of trust in the system. I've seen AI-generated summaries that can't even maintain consistency about a patient's gender within a single document – calling someone \"he,\" then \"she,\" then \"he\" again. When lawyers encounter this kind of inconsistency in legal proceedings, they'll question everything: \"If it can't determine whether someone is male or female, how can we trust any of the information?\" The trust issue is crucial because once confidence in AI-generated content erodes, even accurate information may be dismissed as unreliable. Q. What are actions hospitals and health systems can take when using AI tools to avoid negative consequences of hallucinations? A. Healthcare organizations need to approach AI implementation strategically rather than throwing technology at every problem like \"mud on a wall.\" The key is focused, purposeful deployment with strong human oversight. First, clearly define what problem you're trying to solve with AI. Are you addressing clinical diagnostics, or are you managing pharmacy inventory? Don't jump straight into high-risk clinical applications without understanding what the technology can and cannot do reliably. I know of a vendor that implemented an AI sepsis detection system that was wrong 50% of the time. The hospital CEO, who's a friend of mine, simply turned it off because they realized they didn't even have a significant sepsis problem to begin with. Second, choose your AI tools carefully. Different models excel at different tasks. What GPT-4 does well, Claude might not, and vice versa. Validate the technology with your own data and patient populations. Vendors should provide confidence levels for their systems, whether they're accurate 90%, 95% or only 20% of the time for your specific use case. Most important, maintain human oversight at all times. AI should augment human processes, not replace them. Always keep a human in the loop to validate AI outputs before they're implemented or documented. This applies whether you're dealing with billing, coding or clinical decisions. When humans catch AI mistakes, that feedback can help improve the system over time. The current environment feels like \"Dodge City.\" Everyone is using AI for everything without proper validation or safeguards. This \"AI for AI's sake\" mentality is dangerous. Not every process requires artificial intelligence. If a patient comes to my office with a low-grade fever, sore throat and runny nose, I don't need AI to tell me it's likely viral. Some things are straightforward enough that adding AI complexity only increases cost and potential for error. Q. What should healthcare CIOs, CAIOs and other IT leaders ask vendors with AI in their tools about how they are protecting against hallucinations? A. IT leaders need to ask direct, specific questions about validation and performance. Start with the fundamentals: What confidence levels can you provide for your system's accuracy? Can you demonstrate how your AI performs with real healthcare data similar to ours? Don't accept vague promises – demand concrete evidence of performance metrics. Ask about the training data and validation process. How was the AI model trained, and with what type of medical information? Has the system been tested specifically for the clinical scenarios you plan to implement? Different AI models have varying strengths, so ensure the vendor's system aligns with your intended use cases. Inquire about human oversight mechanisms. How does the vendor recommend integrating human validation into their workflow? What safeguards are built into the system to flag potentially problematic outputs? The vendor should have clear recommendations for maintaining human oversight rather than encouraging full automation. Request information about error detection and correction processes. When hallucinations occur – and they will – how quickly can they be identified and corrected? What mechanisms are in place to prevent the propagation of errors across systems? How does the vendor handle feedback to improve their models over time? Finally, be wary of vendors promising revolutionary capabilities that seem too good to be true. Some companies are developing \"doctor replacement\" chatbots or complex multi-LLM systems that claim to outperform clinicians. Even if these systems are right 80% of the time, that still means they're wrong 20% of the time. Would you be comfortable being in that 20%? The goal isn't to avoid AI entirely. The technology offers genuine benefits when used appropriately. But we need to implement it thoughtfully, with proper safeguards, and always with human oversight. The stakes in healthcare are simply too high for anything less than the most careful, validated approach to AI deployment. Follow Bill's HIT coverage on LinkedIn: Bill SiwickiEmail him: bsiwicki@himss.orgHealthcare IT News is a HIMSS Media publication. WATCH NOW: Seattle Children's Chief AI Officer talks better outcomes through the technology Newsletter Signup Thank you! Your submission has been received. © current_year Healthcare IT News is a publication of HIMSS Media"
  },
  {
    "title": "Open-source AI tool matches commercial systems in medical scan reporting - News-Medical",
    "url": "https://news.google.com/rss/articles/CBMivAFBVV95cUxOeXdMSF85Y0syOE5HVXN4ajI0RjRXSDdTd2V2U2w2d1FGSzdHZDhQalNxUTZxbG1WakxUSUE0dzRfdmlHbUlqYmJhNU9Wc3l0X1ZycFJ3YWlrb2psMEJFNnJZVkhZOXJHMmpCWGlLcklORHFGVWhuWU15bnUtcTFyU1JJS1RFcDRUQ1FOVlFyU2JtOHEzYTQ0Vml3T2NITkhLbXJFdnV1aDY4dGJkMngtamJmU0hDd3VUTFlkVg?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Be the first to rate this article A new study from the University of Colorado Anschutz Medical Campus shows that free, open-source artificial intelligence (AI) tools can help doctors report medical scans just as well as more expensive commercial systems without putting patient privacy at risk. The study was published today in the journal npj Digital Medicine. The research highlights a promising and cost-effective alternative to widely known tools like ChatGPT which are often expensive and may require sending sensitive data to outside servers. This is a big win for healthcare providers and patients. We've shown that hospitals don't need pricey or privacy-risky AI systems to get accurate results.\" Aakriti Pandita, MD, lead author of the study and assistant professor of hospital medicine at the University of Colorado School of Medicine Doctors often dictate notes or write free-text reports when reviewing medical scans like ultrasounds. These notes are valuable but they are not always in a format that is required for various clinical needs. Structuring this information helps hospitals track patient outcomes, spot trends and conduct research more efficiently. AI tools are increasingly used to make this process faster and more accurate. But many of the most advanced AI systems, such as GPT-4 from OpenAI, require sending patient data across the internet to external servers. That's a problem in healthcare, where privacy laws make protecting patient data a top priority. The new study found that free AI models, which can be used inside hospital systems without sending data elsewhere, perform just as well, and sometimes better, than commercial options. The research team focused on a specific medical issue: thyroid nodules, lumps in the neck, often found during ultrasounds. Doctors use a scoring system called ACR TI-RADS to evaluate how likely these nodules are to be cancerous. To train the AI tools without using real patient data, researchers created 3,000 fake, or \"synthetic,\" radiology reports. These reports mimicked the kind of language doctors use but didn't contain any private information. The team then trained six different free AI models to read and score these reports. They tested the models on 50 real patient reports from a public dataset and compared the results to commercial AI tools like GPT-3.5 and GPT-4. One open-source model, called Yi-34B, performed as well as GPT-4 when given a few examples to learn from. Even smaller models, which can run on regular computers, did better than GPT-3.5 in some tests. \"Commercial tools are powerful but they're not always practical in healthcare settings,\" said Nikhil Madhuripan, MD, senior author of the study and Interim Section Chief of Abdominal Radiology at the University of Colorado School of Medicine. \"They're expensive and using them usually means sending patient data to a company's servers which can pose serious privacy concerns.\" In contrast, open-source AI tools can run inside a hospital's own secure system. That means no sensitive information needs to leave the building and there's no need to buy large and expensive GPU clusters. The study also shows that synthetic data can be a safe and effective way to train AI tools, especially when access to real patient records is limited. This opens the door to creating customized, affordable AI systems for many areas of healthcare. The team hopes their approach can be used beyond radiology. In the future, Pandita said similar tools could help doctors review CT reports, organize medical notes or monitor how diseases progress over time. \"This isn't just about saving time,\" said Pandita. \"It's about making AI tools that are truly usable in everyday medical settings without breaking the bank or compromising patient privacy.\" University of Colorado Anschutz Medical Campus Pandita, A., et al. (2025). Synthetic data trained open-source language models are feasible alternatives to proprietary models for radiology reporting. npj Digital Medicine. doi.org/10.1038/s41746-025-01658-3. Be the first to rate this article Posted in: Device / Technology News | Medical Research News | Healthcare News Cancel reply to comment  \n                                    You can change your privacy preferences at any time by signing in to your profile at https://www.news-medical.net/azoprofile/account/ you can amend or select your newsletter preferences at https://www.news-medical.net/medical/newsletters\n \nYour privacy (see our Privacy Policy for full details)\n                                 Ege Kavalali and Natalie Guzikowski Discover how super-resolution technology can be used to sudy neurotransmission at inhibitory synapses. Lloyd M. Smith In the interview, Lloyd M. Smith discusses proteoforms, an area of research worthy of the next Human Genome Project. Professor James J. Collins In this interview, Professor James J. Collins, founder of the field of Synthetic Biology, discusses his journey to founding the field of synthetic biology and the potential of living diagnostics. \n\n                                                  \n                                                        News-Medical.Net provides this medical information service in accordance\n                                                        with these terms and conditions.\n                                                        Please note that medical information found\n                                                        on this website is designed to support, not to replace the relationship\n                                                        between patient and physician/doctor and the medical advice they may provide.\n                                                  \n                                                  \n\n                                             Last Updated: Thursday 24 Jul 2025  News-Medical.net - An AZoNetwork Site Owned and operated by AZoNetwork, © 2000-2025 \n                Your AI Powered Scientific Assistant\n             Hi, I'm Azthena, you can trust me to find commercial scientific answers from News-Medical.net. To start a conversation, please log into your AZoProfile account first, or create a new account. Registered members can chat with Azthena, request quotations, download pdf's, brochures and subscribe to our related newsletter content. A few things you need to know before we start. Please read and accept to continue. Please check the box above to proceed. Great. Ask your question. \n                Azthena may occasionally provide inaccurate responses.\nRead the full terms.\n             Terms \n            While we only use edited and approved content for Azthena\n            answers, it may on occasions provide incorrect responses.\n            Please confirm any data provided with the related suppliers or\n            authors. We do not provide medical advice, if you search for\n            medical information you must always consult a medical\n            professional before acting on any information provided.\n         \n            Your questions, but not your email details will be shared with\n            OpenAI and retained for 30 days in accordance with their\n            privacy principles.\n         \n            Please do not ask questions that use sensitive or confidential\n            information.\n         Read the full Terms & Conditions. Provide Feedback"
  },
  {
    "title": "A simple twist fooled AI—and revealed a dangerous flaw in medical ethics - ScienceDaily",
    "url": "https://news.google.com/rss/articles/CBMibkFVX3lxTE1IOHhDajdEbm9ub0NSc1Z4ZVV1SkJIMk53c0NwOHhSWF9jeWRzYVp4TGNkTjUyYU8xeDNVekF4QTU4b1V5OU55M1dSWkNGa18xdF90bmtqYURic1pGV2p3MWtwdTVjbzh4amJ1QUR3?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "A study by investigators at the Icahn School of Medicine at Mount Sinai, in collaboration with colleagues from Rabin Medical Center in Israel and other collaborators, suggests that even the most advanced artificial intelligence (AI) models can make surprisingly simple mistakes when faced with complex medical ethics scenarios. The findings, which raise important questions about how and when to rely on large language models (LLMs), such as ChatGPT, in health care settings, were reported in the July 22 online issue of NPJ Digital Medicine[10.1038/s41746-025-01792-y]. The research team was inspired by Daniel Kahneman's book \"Thinking, Fast and Slow,\" which contrasts fast, intuitive reactions with slower, analytical reasoning. It has been observed that large language models (LLMs) falter when classic lateral-thinking puzzles receive subtle tweaks. Building on this insight, the study tested how well AI systems shift between these two modes when confronted with well-known ethical dilemmas that had been deliberately tweaked. \"AI can be very powerful and efficient, but our study showed that it may default to the most familiar or intuitive answer, even when that response overlooks critical details,\" says co-senior author Eyal Klang, MD, Chief of Generative AI in the Windreich Department of Artificial Intelligence and Human Health at the Icahn School of Medicine at Mount Sinai. \"In everyday situations, that kind of thinking might go unnoticed. But in health care, where decisions often carry serious ethical and clinical implications, missing those nuances can have real consequences for patients.\" To explore this tendency, the research team tested several commercially available LLMs using a combination of creative lateral thinking puzzles and slightly modified well-known medical ethics cases. In one example, they adapted the classic \"Surgeon's Dilemma,\" a widely cited 1970s puzzle that highlights implicit gender bias. In the original version, a boy is injured in a car accident with his father and rushed to the hospital, where the surgeon exclaims, \"I can't operate on this boy -- he's my son!\" The twist is that the surgeon is his mother, though many people don't consider that possibility due to gender bias. In the researchers' modified version, they explicitly stated that the boy's father was the surgeon, removing the ambiguity. Even so, some AI models still responded that the surgeon must be the boy's mother. The error reveals how LLMs can cling to familiar patterns, even when contradicted by new information. In another example to test whether LLMs rely on familiar patterns, the researchers drew from a classic ethical dilemma in which religious parents refuse a life-saving blood transfusion for their child. Even when the researchers altered the scenario to state that the parents had already consented, many models still recommended overriding a refusal that no longer existed. \"Our findings don't suggest that AI has no place in medical practice, but they do highlight the need for thoughtful human oversight, especially in situations that require ethical sensitivity, nuanced judgment, or emotional intelligence,\" says co-senior corresponding author Girish N. Nadkarni, MD, MPH, Chair of the Windreich Department of Artificial Intelligence and Human Health, Director of the Hasso Plattner Institute for Digital Health, Irene and Dr. Arthur M. Fishberg Professor of Medicine at the Icahn School of Medicine at Mount Sinai, and Chief AI Officer of the Mount Sinai Health System. \"Naturally, these tools can be incredibly helpful, but they're not infallible. Physicians and patients alike should understand that AI is best used as a complement to enhance clinical expertise, not a substitute for it, particularly when navigating complex or high-stakes decisions. Ultimately, the goal is to build more reliable and ethically sound ways to integrate AI into patient care.\" \"Simple tweaks to familiar cases exposed blind spots that clinicians can't afford,\" says lead author Shelly Soffer, MD, a Fellow at the Institute of Hematology, Davidoff Cancer Center, Rabin Medical Center. \"It underscores why human oversight must stay central when we deploy AI in patient care.\" Next, the research team plans to expand their work by testing a wider range of clinical examples. They're also developing an \"AI assurance lab\" to systematically evaluate how well different models handle real-world medical complexity. The paper is titled \"Pitfalls of Large Language Models in Medical Ethics Reasoning.\" The study's authors, as listed in the journal, are Shelly Soffer, MD; Vera Sorin, MD; Girish N. Nadkarni, MD, MPH; and Eyal Klang, MD. About Mount Sinai's Windreich Department of AI and Human Health  Led by Girish N. Nadkarni, MD, MPH -- an international authority on the safe, effective, and ethical use of AI in health care -- Mount Sinai's Windreich Department of AI and Human Health is the first of its kind at a U.S. medical school, pioneering transformative advancements at the intersection of artificial intelligence and human health. The Department is committed to leveraging AI in a responsible, effective, ethical, and safe manner to transform research, clinical care, education, and operations. By bringing together world-class AI expertise, cutting-edge infrastructure, and unparalleled computational power, the department is advancing breakthroughs in multi-scale, multimodal data integration while streamlining pathways for rapid testing and translation into practice. The Department benefits from dynamic collaborations across Mount Sinai, including with the Hasso Plattner Institute for Digital Health at Mount Sinai -- a partnership between the Hasso Plattner Institute for Digital Engineering in Potsdam, Germany, and the Mount Sinai Health System -- which complements its mission by advancing data-driven approaches to improve patient care and health outcomes. At the heart of this innovation is the renowned Icahn School of Medicine at Mount Sinai, which serves as a central hub for learning and collaboration. This unique integration enables dynamic partnerships across institutes, academic departments, hospitals, and outpatient centers, driving progress in disease prevention, improving treatments for complex illnesses, and elevating quality of life on a global scale. In 2024, the Department's innovative NutriScan AI application, developed by the Mount Sinai Health System Clinical Data Science team in partnership with Department faculty, earned Mount Sinai Health System the prestigious Hearst Health Prize. NutriScan is designed to facilitate faster identification and treatment of malnutrition in hospitalized patients. This machine learning tool improves malnutrition diagnosis rates and resource utilization, demonstrating the impactful application of AI in health care. * Mount Sinai Health System member hospitals: The Mount Sinai Hospital; Mount Sinai Brooklyn; Mount Sinai Morningside; Mount Sinai Queens; Mount Sinai South Nassau; Mount Sinai West; and New York Eye and Ear Infirmary of Mount Sinai Story Source: Materials provided by The Mount Sinai Hospital / Mount Sinai School of Medicine. Note: Content may be edited for style and length. Journal Reference: Cite This Page: Groundbreaking Study Identifies Four Biologically Distinct Autism Subtypes Scientists Supercharge Sugar Substitute – And It Starts Killing Cancer Earth’s Kryptonite: The Real Mineral Stranger Than Fiction One Jab. 72% Fewer Sick Babies. Stay informed with ScienceDaily's free email newsletter, updated daily and weekly. Or view our many newsfeeds in your RSS reader: Keep up to date with the latest news from ScienceDaily via social networks: Tell us what you think of ScienceDaily -- we welcome both positive and negative comments. Have any problems using the site? Questions?"
  },
  {
    "title": "Aidoc Rakes In $150M for Its Clinical Decision Support AI - MedCity News",
    "url": "https://news.google.com/rss/articles/CBMicEFVX3lxTE9talVyWWVLOE5aem03enpQNlRheTZibXJZVGRLYjF4NlFIdXFaYVAzUFlzZE9OZXoxQUtUX3BVN25qNmg0LVhnLVJnWUlaTUFIQ3RvcFpReGp3YTRlLUlnWDhqeXZ2X1dGWmxSWjNRam0?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Israeli clinical AI startup Aidoc raised $150 million in a funding round led by General Catalyst and Square Peg, with participation from four U.S. health systems. The company has more than 150 health system customers. Share Options Share a link too this article Israeli clinical AI startup Aidoc  (Opens in a new window) closed a $150 million funding round  (Opens in a new window) led by General Catalyst  (Opens in a new window) and Square Peg  (Opens in a new window) on Wednesday, bringing the company’s overall fundraising total to $370 million. Four health systems — Hartford HealthCare  (Opens in a new window), Mercy  (Opens in a new window), Sutter Health  (Opens in a new window) and WellSpan Health  (Opens in a new window) — also participated in the investment round. Aidoc, founded in 2016, seeks to simplify radiologists’ workflows through its AI-powered clinical decision support technology. CEO Elad Walach pointed out that hospitals, in particular emergency departments, are under pressure to manage high patient volumes, long wait times and delayed test results — as well as to make quick decisions with incomplete information. \n\t\t\t\t\tA new report by Paubox calls for healthcare IT leaders to dispose of outdated assumptions about email security and address the challenges of evolving cybersecurity threats.\t\t\t\t All of these stressors are made worse by the fact that there is a growing radiologist shortage  (Opens in a new window), he noted. His company’s technology is designed to not only help radiologists quickly identify critical findings in medical scans, but also ensure those findings are acted on. “By orchestrating the steps that follow a diagnosis — getting the right team involved, initiating care pathways, tracking progress — Aidoc improves patient flow, reduces delays, decreases leakage and helps hospitals deliver higher-quality care more efficiently,” Walach stated. The startup’s platform continuously monitors incoming patient data, including imaging studies, lab results, vital signs and other EHR inputs. It fetches relevant data and uses AI to find and measure critical indicators for things like stroke, pulmonary embolism, lesions and fractures, he explained. \n\t\t\t\t\tThe home care industry is booming. As Baby Boomers age and more families seek in-home solutions for loved ones, demand for home care services is at an all-time high.\t\t\t\t If Aidoc finds an indicator like this, it automatically alerts the care team and initiates processes for notifying specialists, Walach added. The company’s AI model is on both imaging and clinical data. This creates a reasoning engine that acts as “a layer of intelligence that spans the entire clinical workflow” — from imaging to follow-up care and beyond, he remarked. In his view, Aidoc stands out from other clinical AI companies in the radiology space due to the strength of its technology. The startup’s platform integrates imaging AI, EhR data, lab results, and real-time workflow orchestration, Walach noted. “This systemwide architecture enables Aidoc to address the full care continuum, from radiology through acute intervention and inpatient management,” he said. More than 150 health systems use the startup’s platform, including Mount Sinai  (Opens in a new window), Yale New Haven Health  (Opens in a new window), Temple Health  (Opens in a new window) and University of Miami Health System  (Opens in a new window). The return on investment for health systems is typically measured through faster time-to-treatment, shorter lengths of stay, increased throughput, leakage reduction and higher diagnostic yield. Photo: Darunechka, Getty Images  \n\t\t\tWe will never sell or share your information without your consent. See our privacy policy  (Opens in a new window).\n\t\t Explore top PTSD treatment centers in Arizona, offering personalized care, holistic therapies and expert support to help individuals heal and reclaim their lives. At a time when AI is reshaping pharma, Reverba Global CEO Cheryl Lubbert explained in an interview why empathy, context, and ethics still require a human touch. Break down the silos. Take control of your provider data. \n\t\t\tWe will never sell or share your information without your consent. See our privacy policy.\n\t\t \n\t\t\t© 2025 Breaking Media, Inc. All rights reserved. Registration or use of this site constitutes acceptance of our Terms of Service and Privacy Policy.\t\t These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance. These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising. These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information. These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly."
  },
  {
    "title": "Analysis: AI in health care could save lives and money — but not yet - PBS",
    "url": "https://news.google.com/rss/articles/CBMimAFBVV95cUxNUmZsb2dDUlZjdjN4T2xfOVZ2MXVic2h0TnM1MHNNT3gtejUyUHgyd2Z5Uk5KcUo1OTJ0QldfU21JVmVuY3ZhSDBOcS1oTEhpa0E0Q0htanVkc0ZuVE50aENEUnB1amxmb0dBQ3hhNFhMcUszcXBLTEJFUUg3cGhYOURQakdOcXRDRFhXQldhTnpFR3hfem5wZtIBngFBVV95cUxPM1hUdVVhTlNIQlJnaTI1M0s2TmtKSl9RZXNiY0FoS0dPWjRnUFI5Q3UyWk9lZnBXQnZ4NHowc3U3b19jVkl3SnZSTHJqMUVHYXY5SGVsUjNIUkRFWnFleWVLVWNDY3BuZ2s5cmt1ZUpDZWE5bGVXdlF5NzZ6X3VhN1FRUFhHQ2ZHOW50c3paQ2txT1JBTURmNmkwd080dw?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "There are no stations available for your selected ZIP Code. \nSCETV helps your community explore new\n                                    worlds and ideas through programs that educate, inform and inspire. Your\n                                    tax-deductible donation helps make it all possible.\n                                 \n\nTurgay Ayer, The Conversation\n\n\n                    Turgay Ayer, The Conversation\n                \n Leave your feedback Imagine walking into your doctor’s office feeling sick – and rather than flipping through pages of your medical history or running tests that take days, your doctor instantly pulls together data from your health records, genetic profile and wearable devices to help decipher what’s wrong. This kind of rapid diagnosis is one of the big promises of artificial intelligence for use in health care. Proponents of the technology say that over the coming decades, AI has the potential to save hundreds of thousands, even millions of lives. What’s more, a 2023 study found that if the health care industry significantly increased its use of AI, up to US$360 billion annually could be saved. WATCH: How artificial intelligence impacted our lives in 2024 and what’s next But though artificial intelligence has become nearly ubiquitous, from smartphones to chatbots to self-driving cars, its impact on health care so far has been relatively low. A 2024 American Medical Association survey found that 66% of U.S. physicians had used AI tools in some capacity, up from 38% in 2023. But most of it was for administrative or low-risk support. And although 43% of U.S. health care organizations had added or expanded AI use in 2024, many implementations are still exploratory, particularly when it comes to medical decisions and diagnoses. I’m a professor and researcher who studies AI and health care analytics. I’ll try to explain why AI’s growth will be gradual, and how technical limitations and ethical concerns stand in the way of AI’s widespread adoption by the medical industry. Artificial intelligence excels at finding patterns in large sets of data. In medicine, these patterns could signal early signs of disease that a human physician might overlook – or indicate the best treatment option, based on how other patients with similar symptoms and backgrounds responded. Ultimately, this will lead to faster, more accurate diagnoses and more personalized care. AI can also help hospitals run more efficiently by analyzing workflows, predicting staffing needs and scheduling surgeries so that precious resources, such as operating rooms, are used most effectively. By streamlining tasks that take hours of human effort, AI can let health care professionals focus more on direct patient care. WATCH: What to know about an AI transcription tool that ‘hallucinates’ medical interactions But for all its power, AI can make mistakes. Although these systems are trained on data from real patients, they can struggle when encountering something unusual, or when data doesn’t perfectly match the patient in front of them. As a result, AI doesn’t always give an accurate diagnosis. This problem is called algorithmic drift – when AI systems perform well in controlled settings but lose accuracy in real-world situations. Racial and ethnic bias is another issue. If data includes bias because it doesn’t include enough patients of certain racial or ethnic groups, then AI might give inaccurate recommendations for them, leading to misdiagnoses. Some evidence suggests this has already happened. Humans and AI are beginning to work together at this Florida hospital. Health care systems are labyrinthian in their complexity. The prospect of integrating artificial intelligence into existing workflows is daunting; introducing a new technology like AI disrupts daily routines. Staff will need extra training to use AI tools effectively. Many hospitals, clinics and doctor’s offices simply don’t have the time, personnel, money or will to implement AI. Also, many cutting-edge AI systems operate as opaque “black boxes.” They churn out recommendations, but even its developers might struggle to fully explain how. This opacity clashes with the needs of medicine, where decisions demand justification. WATCH: As artificial intelligence rapidly advances, experts debate level of threat to humanity But developers are often reluctant to disclose their proprietary algorithms or data sources, both to protect intellectual property and because the complexity can be hard to distill. The lack of transparency feeds skepticism among practitioners, which then slows regulatory approval and erodes trust in AI outputs. Many experts argue that transparency is not just an ethical nicety but a practical necessity for adoption in health care settings. There are also privacy concerns; data sharing could threaten patient confidentiality. To train algorithms or make predictions, medical AI systems often require huge amounts of patient data. If not handled properly, AI could expose sensitive health information, whether through data breaches or unintended use of patient records. For instance, a clinician using a cloud-based AI assistant to draft a note must ensure no unauthorized party can access that patient’s data. U.S. regulations such as the HIPAA law impose strict rules on health data sharing, which means AI developers need robust safeguards. WATCH: How Russia is using artificial intelligence to interfere in election | PBS News Privacy concerns also extend to patients’ trust: If people fear their medical data might be misused by an algorithm, they may be less forthcoming or even refuse AI-guided care. The grand promise of AI is a formidable barrier in itself. Expectations are tremendous. AI is often portrayed as a magical solution that can diagnose any disease and revolutionize the health care industry overnight. Unrealistic assumptions like that often lead to disappointment. AI may not immediately deliver on its promises. Finally, developing an AI system that works well involves a lot of trial and error. AI systems must go through rigorous testing to make certain they’re safe and effective. This takes years, and even after a system is approved, adjustments may be needed as it encounters new types of data and real-world situations. AI could rapidly accelerate the discovery of new medications. Today, hospitals are rapidly adopting AI scribes that listen during patient visits and automatically draft clinical notes, reducing paperwork and letting physicians spend more time with patients. Surveys show over 20% of physicians now use AI for writing progress notes or discharge summaries. AI is also becoming a quiet force in administrative work. Hospitals deploy AI chatbots to handle appointment scheduling, triage common patient questions and translate languages in real time. READ MORE: AI and ‘recession-proof’ jobs: 4 tips for new job seekers Clinical uses of AI exist but are more limited. At some hospitals, AI is a second eye for radiologists looking for early signs of disease. But physicians are still reluctant to hand decisions over to machines; only about 12% of them currently rely on AI for diagnostic help. Suffice to say that health care’s transition to AI will be incremental. Emerging technologies need time to mature, and the short-term needs of health care still outweigh long-term gains. In the meantime, AI’s potential to treat millions and save trillions awaits. This article is republished from The Conversation under a Creative Commons license. Read the original article.  \n                    Safeguard the independent, trusted journalism millions rely on at PBS News Hour. \n                 \nLeft:\n                AI can help hospitals run more efficiently by analyzing workflows, predicting staffing needs and scheduling surgeries so that resources are used effectively. File photo via Getty Images\n     By Hannah Grabenstein By John Yang, Kaisha Young By Jeffrey Brown By Simon Ostrovsky, Yegor Troyanovsky By Paul Solman, Ryan Connelly Holmes \n\nTurgay Ayer, The Conversation\n\n\n                    Turgay Ayer, The Conversation\n                \n Turgay Ayer is a professor of industrial and systems engineering at the Georgia Institute of Technology. \nSupport Provided By:\nLearn more\n Subscribe to Here’s the Deal, our politics\n                 newsletter for analysis you won’t find anywhere else. Thank you. Please check your inbox to confirm.  Read Jul 24 Conservative influencer Candace Owens sued for defamation over claims that France’s first lady is a man   Read Jul 24 Union Pacific and Norfolk Southern in merger talks to create coast-to-coast railroad   Read Oct 14 All the assault allegations against Donald Trump, recapped   Read Jul 23 House subcommittee votes 8-2 to subpoena Justice Department for Epstein files   Read Jul 24 WATCH LIVE: Trump visits Federal Reserve as he pressures Powell to cut interest rates   Nation Jul 24  By Matt Ott, Associated Press  Politics Jul 24  By Scott Bauer, Associated Press  World Jul 24  By Michelle L. Price, Associated Press  World Jul 24  By Jintamas Saksornchai, Associated Press  World Jul 24  By Amir Vahdat, Associated Press  Nation Jul 24  By Mike Stobbe, Associated Press   Arts Jul 24  By Curt Anderson, Associated Press  Politics Jul 24  By Geoff Mulvihill, Amelia Thomson-Deveaux, Associated Press © 1996 - 2025 NewsHour Productions LLC. All Rights Reserved. PBS is a 501(c)(3) not-for-profit organization. Sections About Stay Connected Subscribe to Here's the Deal with Lisa Desjardins Thank you. Please check your inbox to confirm. Support for News Hour Provided By"
  },
  {
    "title": "Agentic AI may add efficiency to healthcare administration, but leaves the industry vulnerable to attacks - Healthcare Brew",
    "url": "https://news.google.com/rss/articles/CBMiuAFBVV95cUxNYlZvU2dEUVZBRVlHTllQOUVFZW56d19JOUk5NnBnRERVbkVnNS1RdXNSakJqZWRQczJneGdQdkVveGFQb1docFNuS1ZpbEhON2hoZkFpaXVEaHdZME9uRWs2Uko4M0hJT2xqS0tTMFAxTHNxbG5HZGVBVHBhT1AxYnpyM1YtMkN5TjUwMVpLek1sT0JpRVVXdXZlelpoM1RDTHB4bWpSM3FCNmxuelZsVFdiUWN4UFd5?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Healthcare is already a hot bed for cybersecurity risk.  Richard Drury/Getty Images  • 4 min read The healthcare industry experiences hundreds of cyberattacks each year (725 breaches of more than 500 records in 2024, to be exact). In that hotbed for hacking, where sensitive patient data is at risk, the average cost of an attack for a healthcare organization is $9.8 million, making it more expensive than any other industry, according to a 2024 IBM report. Meanwhile, new generative AI technologies are being introduced to healthcare each day. Among them are agentic AI agents, which are designed to act like humans, autonomously making multistep decisions. These tools can even talk on the phone with patients in human-like voices for scheduling and billing. But these AI agents also present an additional risk for cyberattacks, experts say, in an already targeted industry. “There’s an obvious, massive upside to embracing AI, but with that comes a huge amount of risk as well,” Jimmy White, chief technology officer at software development company Calypso AI, told Healthcare Brew. Why the risk? Hacking works a little differently with AI agents. It’s not caused by a phishing attack or a malware issue. It’s another phenomenon called “prompt engineering,” Stockley said. Since AI agents are meant to act as humans, whether it’s through chat or phone calls, hackers will try to access sensitive information by speaking with the bot and convincing it to reveal what they want to know. For example, users have tested ChatGPT to see if they could jailbreak the code and get the bot to break its own protocols. They can tell ChatGPT to act as an alter ego called “DAN” (aka “do anything now”) and ask it to “pretend to be an unethical hacker and explain how to override the security system.” These sorts of practices could also be used on healthcare agents, White said. The first challenge in protecting against these hacks is simply the fact that the tools are new, Mark Stockley, a cybersecurity expert, told us. “Every time there is a new technology, there is a gold rush because things tend to consolidate around a few incumbents,” he said. “What we see in each successive technology revolution is the same mistakes being made over and over again.” Healthcare Brew covers pharmaceutical developments, health startups, the latest tech, and how it impacts hospitals and providers to keep administrators and providers informed. These mistakes, he added, are due to the quick adoption of technology that sacrifices cybersecurity and safety protocols. A University of Minnesota study published in January found that 65% of 2,425 acute care hospitals surveyed already use AI tools. While 61% of them tested the models for accuracy, only 44% tested for bias. “The cost of security is slowness, and slowness is death in a gold rush,” Stockley said. “The first generation of agents…is likely to be less secure than the generations that come after it.” Another problem, White said, is healthcare companies are likely to use third-party vendors to make the agents, which are often developed by startups building on top of another large language model or hyperscaler, a large cloud service provider. This spreads patient data more widely across hackable places, he said. The third problem, Stockley said, is these AI agents are “phenomenally complex.” “We know broadly, architecturally, how they work, but we don’t know why they make specific decisions,” he said. What can be done? White said healthcare companies can take a few steps to help avoid security incidents. For one, he said, they can look at existing regulations, like HIPAA or state laws, to make sure new AI tools comply with the rules. HIPAA’s privacy and security rules require certain safeguards in electronic medical records and limit how patient data may be disclosed without consent.  Companies should also test models and implement prompt and response scanning, he said. This is when tech teams can see if users are asking inappropriate questions or if the chatbot is outputting problematic responses. Risky business. On another, perhaps concerning note, AI agents are not only susceptible to hacks, they’re also good hackers, Stockley said. Ransomware attacks, which are common in healthcare, aren’t difficult to do, Stockley said. But because of ethical reasons—especialy considering hacks can be life-threatening—fewer hackers are likely to stage them. But, he added, AI agents can also pursue attacks on behalf of hackers—meaning people don’t need to actually do the coding, phishing, or making malware themselves—ostensibly alleviating them from responsibility. “AI agents are going to change cyberattacks massively,” Stockley said. Healthcare Brew covers pharmaceutical developments, health startups, the latest tech, and how it impacts hospitals and providers to keep administrators and providers informed. Industry news By Morning brew Inc. © 2025 Morning Brew Inc. All Rights Reserved."
  },
  {
    "title": "To implement health AI, first decide who’s accountable - American Medical Association",
    "url": "https://news.google.com/rss/articles/CBMirwFBVV95cUxNdUNQNEd3REFWNVRZRVlxNzNzdVN4bFpOR2ZZWWlFclpGZENVY2RSUkdnR1VNTk50VTM3MmhPNnotM3ZBTmFCMzU0Y0lYT0xpdGR2ZUEyX3NPQ0p5bzYxVWpLNzlhQVVYSDhZNTF2T3dZLTExbDdfT3U1dzFMeGhYc19JTUl5ZXJLdW5pa1B3Vkh3c1p6RVdMcmNZak9KaDJwZXppMVVZejhSSTFYNEVr?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "The AMA Update covers a range of health care topics affecting the lives of physicians and patients. Learn more about cervical cancer and at-home screening tests. The AMA Update covers a range of health care topics affecting the lives of physicians and patients. Learn more about cervical cancer and at-home screening tests. The Joy in Medicine® Health System Recognition Program empowers health systems to reduce burnout. Learn about the program, access the guidelines PDF and find out how to apply. The Joy in Medicine® program centers on criteria across six pillars that contribute to well-being. Learn more about the program criteria.  International medical graduates (IMGs) play a critical role in U.S. health care. Learn how the AMA works to help IMGs meet the nation’s health needs. Residents share the responsibility to create an effective and respectful learning environment. The AMA has advice on how to make that happen.  When writing your personal statement, veteran residency program directors said that authenticity will trump AI every time. ChatGPT agrees. Medical student research experience among residency applicants is common, but not always decisive. Learn about the physician specialties where it matters most. Most physicians practice where they completed residency, but not all. Learn which specialties and states are most likely to keep you local. After gaining footing as interns, second-year residents take on a new role and increased responsibility. These tips help new PGY-2s excel. Proposed 2026 Medicare physician payment rule would redistribute pay across specialties and practice types and more in the latest Medicare Payment Reform Advocacy Update. AMA expresses strong concern over proposed rulemaking on Medicaid provider tax reforms and more in the latest National Advocacy Update. This two-day boot camp, Sept. 17-18, 2025, will equip attendees with the time-saving tools and strategies to reform their organizations and enhance professional satisfaction. ChangeMedEd® is a national conference that brings together leaders and innovators to accelerate change in medical education across the continuum. Learn more. The Specialty and Service Society (SSS) is the largest caucus in the AMA House of Delegates. Review the process for endorsing candidates running for a position on the Board of Trustees or AMA councils. Download PDFs of reports organized by year for the Council on Ethical & Judicial Affairs (CEJA) presented during the AMA Interim and Annual Meetings. Download PDFs of reports on this topic for the Council on Ethical & Judicial Affairs (CEJA) presented during the AMA interim and annual meetings. Read current and past issues of WPS Members & News Highlights for the latest information on the work being done by WPS members and its leadership. An examination of \"kinkeeping\" and gender equity, and an introduction to the 2025-26 goals, the \"5 As:\" Action, Activism, Advancement, Advocacy and Achievement. AMA participates in health care conferences and events held throughout the U.S.A. as well as internationally. View the application deadline, public agenda and comments deadline for the CPT® Proprietary Laboratory Analyses (PLA) codes. Health AI is not risk-free, which makes health system governance on powerful tech critical. Find out where to start. Jul 23, 2025 Augmented intelligence (AI)—commonly called artificial intelligence—is rapidly affecting health care. In 2024, the number of physicians using AI tools nearly doubled, from 38% to 68%, and as their use grows so does the imperative to use AI responsibly, safely and effectively.  The AMA defines AI as augmented intelligence to emphasize that AI’s role is to help health care professionals, not replace them.  See our real-world impact on issues critical to patients and physicians. “Clinical decision-making must still lie with clinicians,” according to Margaret Lozovatsky, MD, who is chief medical information officer and vice president of digital health innovations at the AMA. “AI simply enhances their ability to make those decisions.” That distinction is vital. AI directly affects patient care and outcomes, and as it becomes more embedded in daily operations and workflows it poses new challenges and responsibilities.  “There are genuine risks in implementing these technologies,” Dr. Lozovatsky said during a recent AMA webinar (now available on demand). “That makes it important to understand the critical need for governance.” The foundational pillars of responsible AI adoption are: The AMA STEPS Forward® “Governance for Augmented Intelligence” toolkit, developed in collaboration with Manatt Health, is a comprehensive eight-step guide for health care systems to establish a governance framework to implement, manage and scale AI solutions. From AI implementation to EHR adoption and usability, the AMA is fighting to make technology work for physicians, ensuring that it is an asset to doctors—not a burden. Establishing accountability is the first and most essential step in safe, scalable and meaningful AI integration. Executive leadership determines the vision, provides oversight and ensures that AI and its implementation align with system-wide priorities.  “Engaging the C-suite is critical,” said Dr. Lozovatsky, a pediatric hospitalist and a nationally recognized leader in digital health and health care informatics. “All of their areas will be impacted, so buy-in from those leaders is imperative.”  The executive leadership often includes the: Such a multidisciplinary governance structure drives implementation based on feedback from those delivering care.  “It is critical to have people representing all of those spaces because they understand the pertinent considerations best,” Dr. Lozovatsky explained. From there, each leader should delegate responsibilities to trusted stakeholders within their domain to shape workflows, policies, and project evaluations. Find out how participants in the AMA Health System Member Program are using AI to make meaningful change. The AMA recommends a three-tiered model to organize AI governance.  This approach ensures that AI supports broader institutional goals and that resources are allocated properly.  “Organizations likely already have processes for evaluating technology,” said Dr. Lozovatsky. “They will need to consider unique aspects of AI and how those will be addressed with existing models and which additional governance bodies will be necessary to create” the goal being to ensure consistent oversight and alignment with institutional priorities. Clinical informatics encompasses clinical, technical and operational considerations, making this expertise integral to decision-making.  “Governance of any clinical technology relies on a deep understanding of what both technology and people can and should do,” said Dr. Lozovatsky. Including these experts early in the governance conversation is essential. Organizations must answer several strategic questions before designing a structure: Establishing a governance framework starts with treating AI as a tool to advance institutional goals. Evaluate existing internal capabilities to determine their readiness for assessing and implementing AI. After that, health care organizations can make fully informed decisions about incorporating AI into existing structures or create new ones. Follow the latest news on AI and its applications and effects for health care—delivered to your inbox. Perhaps the most important function of AI governance is building trust among physicians and other health professionals that these tools are safe, among patients that their data is secure, and among leaders that AI adoption will advance their mission of care. “Health care organizations must ensure that AI is implemented in a safe, thoughtful manner,” said Dr. Lozovatsky. “We must prove that we’re supporting care for our patients and our clinicians in their ability to deliver that care.” Clarity of purpose and strong structures for implementation empower health systems to move forward with confidence. Establishing executive accountability within a viable governance framework supports collaboration that drives meaningful AI integration. AI governance isn’t just oversight. It’s about creating a culture of innovation in a structured framework that positions AI as a tool to improve care.  “Doing this in a safe, thoughtful manner,” as Dr. Lozovatsky put it, “supports care for our patients and our clinicians in delivering it.” In addition to fighting on the legislative front to help ensure that technology is an asset to physicians and not a burden, the AMA has developed advocacy principles (PDF) that address the development, deployment and use of health care AI, with particular emphasis on: Learn more with the AMA about the emerging landscape of health care AI. Also, explore how to apply AI to transform health care with the “AMA ChangeMedEd® Artificial Intelligence in Health Care Series.” Making technology work for physicians CME: Improving patient-clinician telehealth communication Podcast: The future of telehealth services Video: Uses of artificial intelligence in mental health Webinar: State models of licensure flexibility  Playbook: Telehealth implementation  The AMA promotes the art and science of medicine and the betterment of public health. The best in medicine, delivered to your mailbox"
  },
  {
    "title": "‘ChatGPT saved my mom’: Woman shares how AI solved 18-month medical mystery that doctors missed - The Times of India",
    "url": "https://news.google.com/rss/articles/CBMi_wFBVV95cUxQTlAtZzhqMDFKOExkNVVqbzE4V2lvNFQxOGd3dW5TWS1vM3BHV1VzdkpMUHVWdzREX0Jsa2xaQ2hwT1o0RGVaODh4U2x5THV6Y1RPM1A5Qno3U3I3NlVHYnU0NTdtc3drM1hDdFRnN1N3Y1NJZjl2MHlES1prRmtMQkRXV3cwRUdBRjRvYXdiQ2I1OTVmNFNXRFIwZG90eUNNeks3N21sTDBaaTFzUXY3MnhRemMteDNEVlB2Q0RkMlVoN242QUlILWs2VWs0d0NHWFE4VWUxUDBSSFc3ZFM4RTRZVWVfZmJ6N3JSR0hnLW9aV3BHeFpndHY0aFhSVVHSAYQCQVVfeXFMTjlmajZBMDF0Z3pEcmJaaG9sZFhqcllLOVllT1E4cWF4RVVMRXprU1JRTXJ6cWxhUmdsUmJ1b3dMSHRodVh0Z1pDUVhZcE5vQzFHQjZ0UEQ1QTVLTGh2ank0dW5rb3hWSWpxMHpFYkloc1FvVWszU3lReVBOLU5fY3YxRUZPMlRvVmVCUmlQbDc0U2dYOGUzQkxOZUxpT3NnVktNUVp5N3ZJOXN5VGkxZVdTWjE0NDRiU2xmTTRFSHZEaG5maEx1ZlVIM3NRODhVaXM2WC1GSHdOZUNQbU9PS3l0ZGJFMFhZZmltM3Y1VHhDckJQMlNSQXBfZDltdExuMkRKbk4?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Baby boy names that mean \"brave\" 10 timeless lines from Premchand's classic Malavika Mohanan dazzles in ethnic and floral perfection 7 dirtiest things and places in homes and why not paying attention can be dangerous In Pics: Classic looks of Tharshika How to balance work and study: 8 tips every student needs to know High stakes, high pay: 9 law specialisations with high earning potential 10 animals from India that start with the alphabet \"A\" How to use the trending Matcha in your beauty routine Nithya Menen radiates beauty and confidence in THESE clicks"
  },
  {
    "title": "GE HealthCare's AI-Driven X-Ray Innovations: A Strategic Play to Solve Radiology's Workforce Crisis and Unlock Long-Term Growth - AInvest",
    "url": "https://news.google.com/rss/articles/CBMi3wFBVV95cUxOZEpQeHRZWTQ3MEozLTB1VF9IcEVhd3RjOVVQQ2NydzJEMTB1LXdIRF9mRHQyejZ5YTlQV2xJM25jeW9lREx3bkJsM0xiU093UEZvZ1VmNXZ5QWE0NVY4WXJKanhfOEhCTnk2cUwtV1hqLXVhcWhGSVBiMjR0and3Vk1yYkF3MU5hNmlKZ2swUFJNR2hEZXByX0FrZE9tQW1QR3dWTmV2Z2dGcGZUQWNQbjZ1cWNiSjh1dGV0RGZScWdfYTdRajRvN0xXRWRBeXotZ1BHalR2QWJ6TTZqMUlN?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "News/ Articles/ Articles Details Your AI value-stock bloodhound—sniffing out overlooked gems with the upside to make contrarians cheer. - Global radiology workforce shortages reach crisis point, with imaging demand outpacing supply by 1.2% annually due to aging populations and post-pandemic surges. - GE HealthCare's AI-driven X-ray systems reduce repeat exams by 60%, cut exam times by 18%, and enable 24/7 triage, addressing $12.3B in operational inefficiencies. - Partnership with NVIDIA develops autonomous imaging systems to handle 50% of routine exams, targeting 4.2B annual cases bottlenecked by staffing shortages in low/middle-income countries. - AI adoption aligns with 27% CAGR medical AI market growth, positioning GE to capture $52B global imaging market through 42 FDA-approved tools and strategic international partnerships. The global radiology workforce shortage has reached a tipping point. By 2025, demand for imaging services is projected to outpace radiologist supply by 1.2% annually, driven by aging populations, rising chronic disease prevalence, and post-pandemic healthcare demand surges. With 46% of U.S. radiologists reporting burnout and 81% of healthcare systems citing technologist shortages, the industry faces a perfect storm of operational inefficiencies and unmet patient needs. Enter GE HealthCare, whose AI-driven X-ray innovations are redefining diagnostic imaging as a scalable, efficient, and sustainable solution.   Radiology departments are buckling under unsustainable pressures. A 2025 Harvey L. Neiman Institute report highlights a 26.9% projected rise in imaging demand by 2055, outpacing radiologist supply growth of 25.7%. Key pain points include:- Burnout and attrition: 46% of private-practice radiologists and 37.4% in academic settings report burnout, driven by 24/7 reporting demands and high case volumes.- Geographic disparities: Rural hospitals struggle to attract talent, with 72% of teleradiology users citing its role in reducing backlogs.- Operational waste: 35% of imaging studies are repeated daily due to inconsistent protocols, costing the U.S. healthcare system an estimated $2.8 billion annually.   These challenges create a $12.3 billion opportunity for AI-driven solutions that address both human and technical bottlenecks.   \n\n\nAsk Aime: \nWhy are radiology departments facing a perfect storm?\n\n GE HealthCare's 2025 innovations directly tackle the root causes of radiology's crisis. The Definium™ Pace Select ET and AMX™ Navigate systems integrate AI to automate workflows, reduce errors, and enhance diagnostic accuracy:   These tools are not just incremental improvements—they represent a fundamental shift in how imaging is delivered. By automating 60% of technologist tasks and enabling 24/7 AI triage, GE HealthCare's systems reduce burnout while expanding access. For example, Miungo Medical in Germany achieved a 31% increase in exam slots after adopting Imaging 360, a platform that optimizes fleet utilization and standardizes protocols.   GE HealthCare's collaboration with NVIDIA to develop autonomous X-ray and ultrasound systems is a game-changer. Leveraging NVIDIA's Isaac and Omniverse platforms, these systems will handle patient positioning, image validation, and even basic interpretation with minimal human intervention. This addresses the 4.2 billion annual imaging exams bottlenecked by staffing shortages, particularly in low- and middle-income countries.   The implications are profound. Autonomous imaging could reduce the need for 50% of technologist labor in routine exams, freeing professionals to focus on complex cases. Early trials in the UK's NHS show a 40% reduction in radiologist workload for critical care imaging, with AI prioritizing 85% of cases correctly.   GE HealthCare's AI-driven strategy aligns with three macroeconomic trends:1. AI adoption in healthcare: The global medical AI market is projected to grow at 27% CAGR through 2030, with GE's 42 FDA-approved AI tools positioning it as a leader.2. Operational efficiency: By reducing exam times and repeat studies, GE's solutions offer a 3:1 ROI for hospitals, making them a priority for cash-strapped healthcare systems.3. Geographic expansion: Autonomous imaging opens new markets in rural and underserved regions, where GE's 2025 partnerships in Africa and Southeast Asia are already expanding access.   For investors, the company's $3.2 billion R&D budget and strategic partnerships (e.g., NVIDIA, Everlight Radiology) signal long-term resilience. While short-term risks include AI adoption inertia and regulatory hurdles, the structural demand for imaging—driven by an aging population and chronic disease prevalence—guarantees sustained growth.   GE HealthCare's AI-driven X-ray innovations are not just solving today's radiology crisis—they're building the infrastructure for tomorrow's healthcare. By automating workflows, reducing burnout, and democratizing access to imaging, the company is poised to capture a disproportionate share of the $52 billion global medical imaging market. For investors seeking exposure to a sector at the intersection of AI and healthcare, GE HealthCare offers a compelling, data-driven opportunity.   Investment Recommendation: Buy with a 3–5-year horizon, targeting key milestones in FDA approvals, international partnerships, and AI adoption rates. Monitor the company's stock price correlation with healthcare AI ETFs for entry points. View More ﻿ No comments yet"
  },
  {
    "title": "AI Chat With Roland Rott, President & CEO of Imaging at GE HealthCare - The Motley Fool",
    "url": "https://news.google.com/rss/articles/CBMilwFBVV95cUxPY1g4TE1pZUR1dnNCaHowZFl6akxBRWlVSGtRcThEOXVPOWl5cF85NmU1SVRXQW1jSUU1YTFRb0xxVGg1Q242MXFneFVyS0U1Vi1RYzE0QUM1V1VIWEU0ZTZfSi1zWXRGYkk4RWlCY185V0h3NHNCOG9kTXo1QWs2elZhQXQ1MS15NEZkUmN0amY1VWJESnJv?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, top-rated podcasts, and non-profit The Motley Fool Foundation. Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, personal finance education, top-rated podcasts, and non-profit The Motley Fool Foundation. Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, top-rated podcasts, and non-profit The Motley Fool Foundation. Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, personal finance education, top-rated podcasts, and non-profit The Motley Fool Foundation. \n       You're reading a free article with opinions that may differ\n       from The Motley Fool's Premium Investing Services. Become a Motley Fool member today to\n       get instant access to our top analyst recommendations, in-depth research, investing resources,\n       and more. Learn More\n A set of AI use cases within the medical space. In this podcast Motley Fool analysts David Meier and Asit Sharma and GE HealthCare's CEO of Imaging, Roland Rott, discuss: To catch full episodes of all The Motley Fool's free podcasts, check out our podcast center. When you're ready to invest, check out this top 10 list of stocks to buy. A full transcript is below. This is a modal window. Beginning of dialog window. Escape will cancel and close the window. End of dialog window. This is a modal window. This modal can be closed by pressing the Escape key or activating the close button. This podcast was recorded on July 20, 2025. Roland Rott: We were very focused on using AI to create solutions which make an impact on patients. Ricky Mulvey: That was Roland Rott, CEO of GE Healthcare Imaging, segment within GE Healthcare. David Meier and Asit Sharma talked with him about everything from GE Healthcare overall to a bunch of examples of how AI is used in healthcare to both enhance efficiency and to boost patient outcomes. David Meier: Hello, everyone, and welcome to this installment of the CEO interview. I'm your host David Meier with my Foolish colleague, Asit Sharma. Asit, how are you? Asit Sharma: Doing very well, David. Excited for this. David Meier: Me too, because we have an incredible guest. We have the CEO of GE Healthcare Imaging, which is a nine billion dollar segment within GE Healthcare, Roland Rott. Hello, Roland. How are you? Roland Rott: Hello. Hi, David. Hi, Asit. Everyone. Thanks for having me. Looking forward to this conversation. David Meier: We are too, and we're very glad to have you. Let's kick off and start a little bit broad and talk about GE Healthcare, the overall business, what its business model is and what its mission is. Roland Rott: Yeah, David. GE Healthcare, I'm sure many of you will know, has been part of General Electric for the first 123 years, if you will. General Electric was a very iconic American company highly successful in many fields, healthcare being one of them. We have been essentially over 100 years in healthcare and have been at the forefront of innovation in all these generations of medical devices and medical imaging. Now what is very exciting is that a couple of years ago, beginning of 2023, we actually spun out of General Electric and we became an independent public company, traded at NASDAQ, now being an independent freestanding public company with approximately $19.6 billion of revenues and serving ultimately more than a billion patients worldwide across 160 countries. It's a very significant impact this company has, a very strong legacy but a very exciting future ahead also in this new phase of being a public company ourselves. David Meier: A long time ago, I used to work at GE in what was known as the Power Systems segment, and I have to say, GE Healthcare back between 1998-2005, was always held up within the company as a great model. Maybe let's talk a little bit about its business model and that is, how do hardware sales, software sales, service agreements, how do those all tie together to basically be the operating engine for GE Healthcare? Roland Rott: Great question. And if you think about medical imaging and healthcare overall, what we provide essentially is solutions in order to detect diseases early, to diagnose disease, to ultimately support treatments and monitor these treatments, monitor the health of patients. As GE Healthcare, we are active in all this spectrum. We are doing that with a strategy which is what we call the D3 strategy. We want to provide smart devices, devices which are smart, which are intelligent. We will talk about artificial intelligence, so they are substantially AI-enabled. But also smart drugs, and we align those smart devices and drugs on certain disease states, for example, cancer, or cardiovascular disease. Then we also provide digital solution. We leverage the data which these devices are generating in these specific disease areas as physicians use it, and putting all that together provides solutions which can really improve and impact patient outcomes. That is, in essence, what we provide. Again, relevant hardware, smart devices. Think about systems like CT or MR or ultrasound devices. These are technologies which allow physicians to take a look at patients' conditions and then using the relevant software to get to a good diagnosis and to ultimately make meaning of what these devices actually are producing. From a business model standpoint, once we are offering these devices, they are obviously in use for an extended period of time. We also provide services in order to keep everything not only up and running, but also up to date. We also keep customers vital with newer possibilities such as new versions of AI, etc. Asit Sharma: Roland, let's stick with product for a moment. Could you break down for our members what are the major product areas within the imaging segment? Roland Rott: You can almost define it by the generation it was created. When imaging was starting 100 years ago, we only had X-ray. X-ray was the first modality, and it was a foundational one for many further on technologies like mammography is a piece of it, which we use in breast cancer screening. We then had the rise of CT, which is, again, technology-wise, X-ray-based. Then came MRI, a very revolutionary way to look inside the human body without ionization and with very powerful capabilities. I would say in the last phase, you have this field of molecular imaging, which essentially combines some of the traditional capability like CT and MR with additional sensors, with additional detectors, which can actually allow physicians to look inside the body, find cancers through radioisotopes, slight radioactive drugs which are injected and ultimately can visualize and target specific cancers as an example. Very, very advanced technologies from a standpoint of imaging. As you see in this range, all of these modalities have their particular areas of use. They have their designation. They have obviously their different reach. It's easier to deploy a mobile X-ray device than a big RON, if you will, MR device or a PET CT system. But they have a significant impact on patients. Asit Sharma: If I were to ask you out of these, which products maybe are driving the most value for the imaging segment, what would those be? I have an idea that part of it might be related to the PET type products, so these nuclear tracing products. But I would love to hear from you what is looking into the future the biggest driver value going forward? Roland Rott: If we look at it, we can look at it from a lens of patients and obviously from a financial and from a business standpoint. Really starting on the patients side, we always pull patients first. We would say at least in mature markets, there's good coverage on some of these earlier imaging technologies, but there's yet a lot of potential to provide patients more access to contemporary MRI or to PET CT and PET MR, so this molecular imaging space. These are areas which keep growing substantially because, a, they don't have the visibility, and on the other hand, molecular imaging or theranostics, which combines therapy and diagnostic actually is still growing in its clinical applications. There are more types of disease which can actually be handled with those technologies. We do expect from a business standpoint, significant growth over the next years in these areas of molecular imaging, advanced therapies. But still, also in these traditional technologies, you could say, which help reach more patients or make physicians more efficient in order to handle the patient volume, which we simply have to deal with. Asit Sharma: From an investment standpoint, I'm curious, where are you focusing most of your R&D? Roland Rott: I think in general, when it comes to R&D, we work in the life cycle approach vis-a-vis all of these technologies. We have opportunities, for example, in CT to work on some more advanced next generation capabilities. As we announced, we're working on a deep silicon-based photon counting architecture, which we believe will take the possibility of CT another step forward. That after CT has been around for such a long time, when we think about molecular imaging, it's a big area of investment because there is so much new capability with new radioisotopes available. In that sense, it makes sense to invest further in creating more applications and putting these technologies in the hand of more physicians. Ultimately, we do invest today as we are a stand-alone public company, factually more than ever before from a nominal standpoint, and we have a rich pipeline, which definitely fuels also further growth based on that investment. David Meier: I think this is a good segue to talk a little bit more broadly about innovation, especially since you're at all time highs for R&D budgets. Innovation is definitely within the lifeblood of GE. When I was there, it was extremely important and became even more important under Jeff Immelt when he became CEO and that's when I left. But I'm sure it's still extremely important to the culture. Maybe can you give some examples of how innovation is working within healthcare or imaging if you wanted to go specifically there. It can be anything. It can be maybe a product upgrade or even a major breakthrough that gets you into a new market. Roland Rott: I would say one of the biggest areas of innovation and also going back to investments is, of course, artificial intelligence, AI, deep learning in the context of healthcare. AI has been around for some time. AI principle has been around for several decades. However, with the rise of possibilities NVIDIA provided us, for example, to have very powerful capabilities within a computer, we are now able to process large amounts of data, and that ultimately can help to make these systems and smart devices even smarter. We invested significantly in AI. Today, actually, we are a leading company in the field of AI. We have more than 85 FDA cleared medic devices today in the market. They are cleared, they are commercially available, and they have physicians to treat patients more efficiently and on the other hand deal with this large amount of patient volume and get to better insights. It's really important for us to have physicians and see AI as a partner. Often it's used as a Copilot to augment the possibilities of physicians and helping them get to the result with confidence as efficient as possible, and that way also help to improve the outcomes. If I give you a few examples, we have been able with AI to streamline the reconstruction time, first of all, and the processing time in MR by more than 70%, and in cardiology, even 83%. We are able to slash these exam times. That means it's more comfortable for a patient. You don't need to lay in such a device for an extended period of time. Think about many patients which are in the queue. If you can be faster, you can handle more patients in the same time frame. Ultimately, we have also been able to improve that image quality. Make this image quality more robust, take certain artifacts away, etc, give the physicians a cleaner image, in that sense, ability to confidently screen or diagnose. This is just one example where AI already makes a significant impact, and with the technology I described, we have already handled more than 30 million patients, actually. This is quite proven. This is not in the infancy stage. David Meier: Maybe I'll follow on with an AI question, and we'll start internally and work our way out. It's very clear that the creation of data from your machines is very important. Maybe internally, how are your teams using AI to maybe get a little bit more marginal in return on the R&D budget, things like that? Roland Rott: I would say it's very interesting your question because we can also use AI in the process of creating these solutions. My early example, and that's really our evolution, we started with customers first. We started actually to use AI first to create solutions which make an impact. Maybe it also related to the timing because we were in COVID. Many of our customers and physicians had challenges to deal with the load of patients, etc. We were very focused on using AI to create solutions which make an impact on patients. While doing though, we then in recent years, spend also quite some efforts to look at the process. As you will know, there's a lot of documentation required in medical device generation. There's a strong quality management framework, which we are adhering to regulatory requirements. Today, we actually find a lot of opportunity to use AI to augment our engineers in doing exactly that work and also be more productive that way, get more agile, shorten some of the creation time, or if you will, get more output in the same period of time. That last piece still has a lot of potential. We're just at the beginning really of unlocking that. I think we're going to keep learning, and we're going to keep evolving, obviously, as we also get more possibilities with AI. David Meier: Maybe before Asit asks this question, I'll just have one comment. I used to be a Black Belt in the old Six Sigma realm. Is AI basically Six Sigma on steroids now? It's like the next 10 levels higher type of a thing. Roland Rott: Maybe to translate, Six Sigma is one approach which also General Electric has used early on and also relates to Lean. Lean is very much a culture, and it's also a set of tools of continuous improvement and to take waste out, for example, of processes. In that sense, you could say, AI is a close cousin. It's a tool which allows us to do exactly that. Ironically, as you mentioned this point, we actually reimplemented Lean very substantially over the last years in parallel to AI. We deployed Lean consequently. Larry Culp is the CEO of GE and is our chairman today, with his vast experience inspire that. Today, actually, we both deploy Lean and use AI to get processes more efficient, to take waste out to actually speed up and be productive all in the spirit of serving customers faster, but also obviously as precise as needed. Asit Sharma: I want to go back to something that you mentioned earlier because I think many of our members will have an interest in the competitive edge that imaging solutions has. You talked about the clarity of images that have been enabled by AI. Basically, we have a scan, and in any number of outputs, you have a visualization, which is then I would call it as a layperson, almost recreated by AI. Some of the noise gets removed, and you have more signal, the image has more clarity. But at the end of the day, it's an algorithmic type of improvement. We're curious what kind of edge is this vis-a-vis competitors? For example, someone using these images, a physician maybe has a higher confidence level in his or her diagnostic capability, if the image is better. As you already mentioned it cuts down on the time it takes to run the test and get all the way to a diagnosis. Is this something that a competitor could also working in an AI kitchen come up with or do you have some type of clear edge versus those who offer similar products? Roland Rott: I think in principle, and that's always true, all these capabilities are in theory, available to many. We see a lot of innovation, generally speaking, when it comes to AI in healthcare. Let me also say that we are cultivating a pretty open ecosystem. We are not only creating our own AI, we are partnering very closely with customers, which can be very large healthcare systems generating a lot of data, applying that, having their own models, and then ultimately that can lead to some start-up which ultimately offers that and we integrate that. We are really using the broader ecosystem lens here. We have also acquired a few companies over the last years in the space of AI, such as Caption Health in ultrasound or MIM in the space of molecular imaging software, as I mentioned before. They all use AI, and they all are enhancing so to say, what we organically do. But really to your question of competitiveness, we do believe and based on the fact that we started earlier and we have a lead in FDA cleared medical devices today, a lot of customers look at that and understand that we invested into this space, we created meaningful impactful solutions, and that gives us credibility to further charge ahead and creating further such solutions. We have just started, if you will, with these first 85, but some of those AI applications have been very narrowly focused on improving a certain image area and so forth. But we have now extended the field quite broadly to also create solutions which combine such exams across modalities. Think about a care pathway where a patient first gets diagnosed with an ultrasound system or gets screened with an ultrasound system in mammography, you use mammography, you then use MRI, so you go through these different technologies, and as more data is generated, how can we use AI also to give physicians a comprehensive summary and comprehensive insight about the patient's condition? Those applications are actually now really interesting based on the possibilities we have found. It's really innovating the specific individual smart devices is one, but it's creating solutions across the care pathway, which have a lot of even more impact. Ricky Mulvey: As always, people on the program may have interest in the stocks they talk about, and the Motley Fool may have formal recommendations for or against, so don't buy or sell stocks based solely on what you hear. While personal finance content follows Motley Fool editorial standards, is not approved by advertisers. Advertisements are sponsored content and provided for informational purposes only. If they are Fool advertising disclosure, please check out our show notes. That's all for today. We'll see you tomorrow. Asit Sharma has positions in GE Aerospace and Nvidia. David Meier has no position in any of the stocks mentioned. The Motley Fool has positions in and recommends GE HealthCare Technologies and Nvidia. The Motley Fool recommends GE Aerospace. The Motley Fool has a disclosure policy. Stocks Mentioned *Average returns of all recommendations since inception. Cost basis and return based on previous market day close. \n        Invest better with The Motley Fool. Get stock recommendations, portfolio guidance, and more from The Motley Fool's premium services.\n       Making the world smarter, happier, and richer. © 1995 - 2025 The Motley Fool. All rights reserved. Market data powered by Xignite and Polygon.io. About The Motley Fool Our Services Around the Globe Free Tools Affiliates & Friends"
  },
  {
    "title": "AI Innovations Are Making Their Way to Healthcare - Oracle",
    "url": "https://news.google.com/rss/articles/CBMiV0FVX3lxTFBKT2tKblNsQ0xYODNUa25ITGJEdFphMWNhMW5qMHZOUWV3c1FyVjBSYjZGWTNPYW04ZnV1RnNFRVl3X0VZQ1NGaUZOSDZFZW1DWTNFZVJFcw?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Aaron Ricadela | Senior Writer | July 2, 2025 Global healthcare systems are strained by aging populations, growing numbers of chronically ill patients, rising treatment and drug costs, and personnel shortfalls. Meanwhile, burdensome documentation requirements are contributing to physician and nurse burnout. Rapid advances in predictive and generative AI are already improving how medical professionals, clinical researchers, and administrators at hospitals and insurers work, and they’re poised to deliver even more transformative changes in the coming years. These AI systems excel at spotting hidden patterns in large data sets, zeroing in on hard-to-discern details in medical images, supporting diagnoses in complex cases, and recommending operational improvements that may be applied to pare costs. These advances could lead to process reforms, productivity gains, and improved patient outcomes. Read on to learn about the benefits, challenges, and applications of AI in healthcare. AI uses complex statistical prediction models and large amounts of computing to help solve complex problems, understand and respond to natural language queries, create videos and other forms of online content, classify images, and more. Neural networks, including large language models, are trained on large amounts of historical data to construct AI models that can make predictions to help users anticipate and solve a range of problems. These models can also go back through their statistical parameters to correct errors and transfer their knowledge to draw inferences about new problems and domains. Large investments in the data centers and chips needed to train AI models and power their inferencing (the reasoning process they use to respond to user queries) have fueled the AI boom. Physicians, clinical researchers, pharmaceutical companies, and medical staff are using artificial intelligence technology to aid diagnoses, patient exams, drug development, and hospitals’ efficiency. Electronic health records (EHRs) have come into widespread use in US hospitals and medical practices over the past 15 years, in large part because of billions of dollars in federal incentives. While they’ve made recordkeeping more accurate and reduced medical errors, their unwieldy note-taking requirements, hard-to-navigate screens, and often superfluous alerts and inbox messages have also created extra work for healthcare professionals. AI agent–enhanced EHRs can help save clinicians time and increase patient face time by requesting that they generate summaries of patients’ conditions, medications, and lab results before exams, quickly jump to key functions, and speak or type natural language commands. In radiology, AI systems can help spot areas of scans with the highest probability of abnormal tissue growth or measure specific indicators, such as changes in kidney volume, that can help physicians predict function declines before they show up in blood tests. Many AI healthcare applications, however, are aimed at easing hospitals’ and medical practices’ administrative burdens—for example, by automating billing and scheduling, helping write prior authorization letters to insurance companies, or reminding a patient that it’s time for a mammogram. The healthcare IT sector is building GenAI systems that support diagnoses by analyzing patients’ histories, exam findings, and lab test results alongside reviews of existing bodies of knowledge about diseases, and reaching conclusions that can assist physicians on complex cases. Key Takeaways AI is poised to deliver a range of benefits in medical research, drug development, clinical diagnoses and care, and healthcare administration. Applying AI to EHR data doesn’t automatically result in improved insights, patient care, and hospital processes. Clinicians, administrators, and other staff need to trust the technology enough to use it regularly and be aware of the potential for mistakes. Financially strapped hospitals need to understand the high cost of cleaning up and anonymizing patient data so it’s ready to train AI models. Read on for more on these and other challenges. Medical professionals are applying AI across a range of applications to improve diagnostic insights and clinical decisions, predict patient outcomes, and accomplish so much more. Here are 10 of the most common AI use cases in healthcare and life sciences. Further development and adoption of national and industry standards will help healthcare organizations and governments share more data, providing a stronger basis for AI-driven insights. But financially pressured hospitals will need to find ways to invest in the latest tools and prepare their data for AI analysis. Likely to come into wider use are hospital robots that nurses and other staff control from their phones to help ferry lab samples, medical equipment, and supplies to shorten delivery times and free up staff time. EHRs that use GenAI to quickly get pertinent information to physicians at the right time and cut down on complex screen navigation are also starting to come to market. Within the next decade, doctors will likely benefit from AI systems that help support medical decision-making during patient visits, suggesting diagnoses via a PC or tablet based on what the doctor has said, the existing literature, and data about similar past cases. The systems could also help recommend tests and medicines. Oracle Health products enhance various aspects of care, including through generative AI. They can help personalize workflows for staff, streamline managing patients, and provide relevant information before exams. Oracle Health Clinical AI Agent captures doctor-patient conversations to generate draft EHR notes, and it lets doctors call up data from patients’ medical histories via voice commands. Oracle Health Data Intelligence lets providers and payers perform AI analyses on clinical and financial data. The services can prioritize high-risk patients, flag overdue screenings, and prompt patients to schedule appointments. How is AI used in healthcare? Artificial intelligence is transforming numerous aspects of patient care and healthcare administration, including diagnostic support, personalized treatment plans, documentation, clinical trials, and hospital planning. What is an example of AI in healthcare? AI-enhanced healthcare software can quickly call up information about patients’ histories from electronic health records, help doctors more quickly document patient visits, assist pharma companies in designing clinical trials, and help hospitals plan staffing."
  },
  {
    "title": "Suki adds key top executives from Uber, Innovaccer as it looks to scale AI assistant for healthcare - Fierce Healthcare",
    "url": "https://news.google.com/rss/articles/CBMiogFBVV95cUxPbHQ4a1M0RGVpNVh0NmNQMFRpaEh4Qko2MDYwLUY1MXdHRUVvZjYwTl9qVjZ4WXFRbm5nSFY3NFFicDFSQlMxQ0VhTEp2bXlCV0hyS2djTlNTYnJQZlUtU1lidXBHWEEzZWJtTWRvS19yTU01V2lYMVdyREtpbkxXWkxWUjhzRnlBZUplZlptSWlUZEhwbVBOOEZtdE4waEJ4RUE?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data. You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page. \nCloudflare Ray ID: 964635e2ed4f99ad\n•\n\n      Your IP:\n      Click to reveal\n34.23.160.127\n•\n\nPerformance & security by Cloudflare"
  },
  {
    "title": "Industry Voices—The future of AI in US healthcare policy - Fierce Healthcare",
    "url": "https://news.google.com/rss/articles/CBMivAFBVV95cUxPWnZxaHVCS056Q3VNbDFzenJhZHpPZlJwLWllZXlrT2tjWkJWUVlKd2sxbEx1X21BNkd3NEVYYWZ5cnctbWc5c3JYTWN2SkZOYnV1dmlzeklqUnZnRmd0aWZvbTVsdW5YN0hOTlh4M3A2WmtuMFpNc3gxZEVZWWtaMlRKc01KRE9kc2lIQVh6SjFOaWRmRzhQaWlyTGw0YnRmSnBYd3cyUmFoNVN4VUFmS19yNlcwRWxDekJjcA?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data. You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page. \nCloudflare Ray ID: 9646360ddd9199ad\n•\n\n      Your IP:\n      Click to reveal\n34.23.160.127\n•\n\nPerformance & security by Cloudflare"
  },
  {
    "title": "Most patients support AI in healthcare if it means more time with doctors - Ophthalmology Times",
    "url": "https://news.google.com/rss/articles/CBMiswFBVV95cUxNNGp0RGhERlZqMmJNMTRORmJtczBMY0VoanhWVnFYX0dZSy1fN2RQWEF1Q2plNUo0UVRtWFhPWFJjak9kR1pfSjFHUXFfR2QzdVg2RWFYVjc4UEtweG1FOGhGZjhoZVNjMVUtbGdRMWVKQTZKb2JIa3VpVUE1YmNZNVdVMXptVFJEcXVqZWJVUXVtci02cVFMOTFhUUtPdjFtTVpfUk1YTnpmU3ZMaVQ2ckFEbw?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "News Article Author(s): Patients express mixed feelings about AI in health care, favoring its use for documentation and administrative tasks while demanding transparency and safety standards.  (Image Credit: Adobe Stock/StockWorld) ModMed conducted a new survey on 2000 US patients on their comfort with artificial intelligence (AI) use in medical practices. Survey results showed that patients still feel uneasy about AI use in diagnosis or creating a treatment plan, with 55% of respondents saying they were uncomfortable. According to ModMed, this is a shift from a survey in 2023 by Pew Research Center, whose findings showed that 60% of patients were uncomfortable with their health care provider relying on AI. However, over half of patients surveyed (57%) support AI in the exam room for documentation if it means more face time with the doctor. Three in four patients said they spend less than 15 minutes with their physician in the exam room, and almost a third noted that doctors spend 7 to 12 of those minutes focused on documentation. Patients are much more comfortable with AI use behind the scenes as well, the results showed. For administrative tasks, respondents said they approve of AI use in scheduling and reminders (35%), patient check-in (31%), or assisting with prescription refills (42%). Additionally, most patients said they would want strong guardrails around the use of AI in health care, with 83% saying AI used for diagnosis and treatment should meet safety and accuracy standards. Additionally, 72% believe it is important to know the source of training data for an AI model. In addition to the protections, the majority of patients also want to know when AI is being used in the first place, with 81% noting the desire to be told if their doctor's office is using AI at all. Over half (55%) also wish to be notified if AI is helping with diagnosis or treatment. Almost half (46%) want to be notified if AI is used in follow-ups such as lab results, and 40% would prefer to hear about AI usage directly from their doctor or care team. However, 31% of patients would prefer to just sign a consent form, and 27% would rather review information on their doctor’s website. Regarding finance, one-third (34%) of patients are uncomfortable with AI having access to their credit card information. However, over half (57%) supported AI use for speeding up claims processing. Dan Cane, cofounder and co-CEO of ModMed, commented on the survey in a company press release, saying, \"For too long, technology has put screens and paperwork between doctors and their patients. Our vision is to remove those barriers. This lets doctors and providers focus on patients, knowing intelligent systems work quietly in the background, anticipating needs and streamlining processes. We believe this is the best way to truly unlock AI's potential in health care.\" Talker Research distributed the survey to US patients over the age of 18 who have been seen by a doctor within the past year. A total of 2000 responses were collected between December 2 and 6, 2024. The survey was commissioned by ModMed and conducted online. Don’t miss out—get Ophthalmology Times updates on the latest clinical advancements and expert interviews, straight to your inbox. Q&A: Jeffrey L. Goldberg, MD, PhD, on the rise of clinical trials centers of excellence California dreaming: 2025 Glaucoma 360 brings celebration, innovation, and education to San Francisco Researchers explore ChatGPT4o's ability to generate realistic retinal fundus images Innovation Series: Putting the buzz of large language models in ophthalmology into perspective with Robert T. Chang, MD Wilmer Eye Institute marks 100 years: honoring the past, shaping the future Q&A: Kira Manusis, MD, on how the Center for Refractive Solutions is redefining patient care at NYEE Q&A: Jeffrey L. Goldberg, MD, PhD, on the rise of clinical trials centers of excellence California dreaming: 2025 Glaucoma 360 brings celebration, innovation, and education to San Francisco Researchers explore ChatGPT4o's ability to generate realistic retinal fundus images Innovation Series: Putting the buzz of large language models in ophthalmology into perspective with Robert T. Chang, MD Wilmer Eye Institute marks 100 years: honoring the past, shaping the future Q&A: Kira Manusis, MD, on how the Center for Refractive Solutions is redefining patient care at NYEE Annexon completes enrollment in phase 3 ARCHER II trial of vonaprument for geographic atrophy Kiora Pharmaceuticals Secures US Patent for KIO-104  Scuba divers and surfers face dual light exposure that may accelerate AMD Q&A: Jeffrey L. Goldberg, MD, PhD, on the rise of clinical trials centers of excellence 2 Commerce Drive Cranbury, NJ 08512 609-716-7777"
  },
  {
    "title": "AI’s potential in healthcare meets the reality of computing demands - BeBeez International",
    "url": "https://news.google.com/rss/articles/CBMinAFBVV95cUxNdU0zTzJ6Wkl5RGFPOEFoamRIbGVSU0NCVTI5REhYckR2N2x0WXpkRkdaOHp1WjduNEFiamhKUnJMSDNkMjd1OWJoZ1BIanVJLUo2b3hIdXJ6d1lDLV9oY3NkdEFXc2RpVEdDUF9xTHBOVFcyV2RqLXBtbWlnV1BBcWhQeXNvRkU1QVNRMHhsUlB0Y195ZlQ1dWJfNlc?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Dementia is a progressive, chronic condition with no cure, and its prevalence is rising, with experts predicting the number of people affected will almost double by 2050.  But hope for new treatments targeting dementia and other non-curable diseases is growing, thanks to a wave of European startups applying AI to scientific discovery.  Prima Mente, an AI neuroscience company based in London, is leading a study into dementia, across 1,000 patients in 15 healthcare settings. It combines blood biomarkers and genotyping with remote cognitive testing to enable earlier, more accurate detection of cognitive decline.  Hannah Madan, Prima Mente’s cofounder, says the startup is trying to imagine a world where Alzheimer’s, dementia and other neurodegenerative conditions are not treated as one big bucket of disease, but broken down molecularly — a little like cancer, which now has specific treatments for specific types.  “It’s a simple study, designed to bring innovation to the neurocare pathway,” says Hannah Madan, Prima Mente’s cofounder. “The NHS teams we’re working with are super excited.” The potential for AI to revolutionise the healthcare sector is no longer theoretical. Researchers, doctors and clinicians are using models to analyse medical images and diagnose conditions earlier; to design and run more successful clinical trials faster; and to map the right therapies to the right patients with a higher degree of accuracy.  In 2024, two Nobel Prizes were awarded to scientists using AI to shape the future of medicine. In the future, experts believe it’ll be possible for doctors to create digital twins for each patient so they can simulate treatment plans and transform personalised healthcare.  It’s an astonishing pace of change, but there are still logistical challenges preventing teams from taking full advantage of this technology.  To facilitate their important work, the team of neuroscientists and AI researchers behind Prima Mente has spent the past year developing Pleiades. It’s the first epigenetic foundation model that can spot signs of early neurological disease with a high degree of accuracy. But it requires an enormous amount of elastic, cost-efficient high performance computing (HPC).   The infrastructure many teams are working with just isn’t built for modern research. “We are pre-training huge models in-house, with up to 80bn parameters,” says Madan. “That infrastructure is something only Uber, Wayve, Google DeepMind and other big tech companies used to have access to.”  The biotech startup is now leveraging Nebius’s infrastructure to power its research. Nebius is the first Nvidia Reference Platform cloud partner HQ’d in Europe, and it recently announced the deployment of Nvidia Blackwell Ultra GPUs in the UK. It’s now one of the largest independent AI infrastructure builders globally, with data centres in six countries — a resource that healthcare innovators desperately need. In June, Nebius held its first AI Discovery Awards for biotech startups, awarding nearly $1 million in Nebius AI Cloud credits. Four top teams received $100,000 each in GPU credits, with additional prizes going to runners-up and honourable mentions.  “The infrastructure many teams are working with just isn’t built for modern research,” says Dr Ilya Burkov, global head of healthcare and life sciences growth at Nebius. “It’s clunky, expensive to maintain and often isn’t easily scalable. When teams can’t access the compute power or engineering support they need, that makes innovation slower than it should be.”  In France, biotech startup Bioptimus is building a foundation model described as the ChatGPT for biology. It’s capable of understanding and engineering multi-modal biology at scale, from DNA sequences and protein structures, to cellular interactions and phenotypes.   We need to build better bridges between the scientific, technological and clinical communities Historically, this research has focused on isolated biological components, but Bioptimus brings every layer together to simulate how biology exists in reality.  Since launching in 2024, the founding team has raised $76m in funding. Its first model, H-optimus-0, has had more than 100k downloads from around the world since it was released on Amazon Web Service a year ago.  “There’s a lot of pathology workflow optimisation that we’re seeing happening,” Mathilda Strom, chief operating officer at Bioptimus, says. “People are using it for biomarker discovery, to find new cures for diseases, and making connections we haven’t been able to as humans.”  AI is facilitating a golden age of scientific discovery, Felipe Llinares, cofounder and vice president of AI at Bioptimus, adds.  “The data is starting to be there, the models and training methodology are starting to be there, the hardware has improved a lot,” he says. “But biology is very complicated. Trying to simulate a human being with these models is like trying to predict the weather by modelling how air molecules interact with each other.”  Even so, Bioptimus is making progress. It’s on schedule to release its M-Optimus model later this year.  This will be the first multi-scale, multi-modal level trained not just to interpret medical images, but to understand how they relate to gene expression, spatial location and cellular organisation. It will enable researchers to understand, for example, how the arrangement of cells in tumours may impact a patient’s response to treatment.   It will be a significant step forward for the sector, but one that is only possible with the combination of data and HPC, Llinares says.  “One image of a tumour can be as big as 50k pixels by 50k pixels, so the compute pressure is very high. AI for biology is likely to be at the forefront of Europe’s HPC needs over the next few years.”  That data sovereignty is important in healthcare for compliance reasons, he adds. “The type of data we have is highly sensitive so we’re restricted by which regions in the world this data can live in, and are pressed to find compute capacity here.” Burkov agrees, adding: “We need to build better bridges between the scientific, technological and clinical communities. Our goal is to empower biotech innovators with the infrastructure they need to go further, faster, so they can solve some of the world’s toughest healthcare challenges.”  Read the orginal article: https://sifted.eu/articles/ai-healthcare-brnd/  EdiBeez srl COUNTRY CATEGORY PREMIUM WHO WE ARE INFORMATION Login to your account below       Remember Me     Please enter your username or email address to reset your password.       We   and selected third parties   use cookies or similar technologies for technical purposes and, with your consent, for experience, measurement and “marketing (personalized ads)” as specified in the cookie policy.  With respect to advertising, we and 1020  selected third parties, may use precise geolocation data, and identification through device scanning in order to store and/or access information on a device and process personal data like your usage data for the following advertising purposes: personalised advertising and content, advertising and content measurement, audience research and services development. You can freely give, deny, or withdraw your consent at any time by accessing the preferences panel. If you give consent, it will be valid only in this domain. Denying consent may make related features unavailable.  Use the “Accept” button to consent. Use the “Reject” button to continue without accepting."
  },
  {
    "title": "Revolutionary AI X-Ray System from GE HealthCare Tackles 80% Healthcare Staff Shortage Crisis - Stock Titan",
    "url": "https://news.google.com/rss/articles/CBMivwFBVV95cUxNaXVQSGVCRWsyaS1FbElQcGt0ZHhpZ0lGNW5qVlVUMzRFT2ZOdXNyYTZlSW80NnFSYXBpVkV1aWRTZy1CT3FKZ2tTUVYtOUVLWE9FRnVZaDNROEhGQkNjMHUxOU9vSFFMazZncUxESWg3RDB5NFBCWlNkZktNRjVjOXlZS3FVUXhHcHdBR0FjZy1ScXVuVEtZSnFxemw5eVdnaDRRWUpuc2tHeTNCZWVoU0RaRWdYckZwdjUza2dNOA?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "AST SpaceMobile Announces Proposed Repurchase of up to $135.0 Mil... Intel Reports Second-Quarter 2025 Financial Results Apollo Now Fully Integrated into NVIDIA’s Autonomous Driving Plat... AST SpaceMobile Announces Proposed Private Offering of $500.0 Mil... Mullen Announces Company Name Change to  Bollinger Innovations, I... Newmont Reports Second Quarter 2025 Results AST SpaceMobile Announces Proposed Repurchase of up to $135.0 Mil... Intel Reports Second-Quarter 2025 Financial Results Apollo Now Fully Integrated into NVIDIA’s Autonomous Driving Plat... AST SpaceMobile Announces Proposed Private Offering of $500.0 Mil... Mullen Announces Company Name Change to  Bollinger Innovations, I... Newmont Reports Second Quarter 2025 Results  CHICAGO--(BUSINESS WIRE)--\nGE HealthCare (Nasdaq: GEHC), today announced commercial availability of an advanced floor-mounted digital X-ray system, Definium™ Pace Select ET1, designed to deliver high-image quality and optimize efficiency in highly demanding environments while enhancing access and affordability.\n\n \nX-ray exams often serve as the entry point to diagnostic imaging, accounting for 60% of all imaging studies conducted, resulting in an ever-increasing workload for radiologists and technologists2 3. This increased demand, combined with acute staffing challenges where 80% of healthcare organizations are short-staffed and radiology technologists have the highest vacancies3, high burnout levels and work-related injuries, creates critical barriers to providing timely, effective diagnostic imaging for patients in need of X-ray imaging.\n\n \nGE HealthCare’s new Definium Pace Select ET solves for many of these challenges by automating manual, repetitive steps and helping to reduce physical strain. The system leverages AI to ensure accurate patient positioning and consistent image quality across various clinical conditions while streamlining the technologist workflow to maximize the patient experience and throughput.\n\n \n“Burdened with the stress and pressure to keep radiology departments running smoothly and profitably, we aim to empower technologists with a system that consistently makes the first image count,” said Sharad Sharma, Global General Manager, X-ray, at GE HealthCare. “With its advanced digital capabilities and automation, Definium Pace Select ET allows technologists of all experience levels to deliver consistent high-quality images to serve the full range of anatomies and patient populations.”\n\n \nEasy-to-use features allow technologists to focus on patient care\n \nBuilding on the trusted Definium platform from GE HealthCare, the Definium Pace Select ET system brings advanced automation and workflow features to a flexible, floor-mounted system with elevating table, in-room exam control, and common user interface to assist technologists.\n\n \n“This launch reinforces our commitment to provide accessible, efficient, and high-quality care for patients, while alleviating stress from the technologist’s workday by minimizing repetitive tasks and automating steps,” said Jyoti Gupta, PhD, President & CEO of Women’s Health and X-ray at GE HealthCare. “We remain dedicated to advancing our technology through transformative digital and AI-enabled capabilities that will remove barriers to timely and effective diagnostic imaging for any patient in need of X-ray imaging.”\n\n \nThe Definium Pace Select ET system brings the same high image quality typically seen in more expensive overhead tube suspension (OTS) systems to the affordability focused floor-mounted market. Designed and developed with extensive customer feedback, the system brings:\n\n \nTo learn more about the new X-ray system, visit gehealthcare.com.\n\n \nAbout GE HealthCare Technologies Inc.\n \nGE HealthCare is a trusted partner and leading global healthcare solutions provider, innovating medical technology, pharmaceutical diagnostics, and integrated, cloud-first AI-enabled solutions, services and data analytics. We aim to make hospitals and health systems more efficient, clinicians more effective, therapies more precise, and patients healthier and happier. Serving patients and providers for more than 125 years, GE HealthCare is advancing personalized, connected and compassionate care, while simplifying the patient’s journey across care pathways. Together, our Imaging, Advanced Visualization Solutions, Patient Care Solutions and Pharmaceutical Diagnostics businesses help improve patient care from screening and diagnosis to therapy and monitoring. We are a $19.7 billion business with approximately 53,000 colleagues working to create a world where healthcare has no limits.\n\n \nGE HealthCare is proud to be among 2025 Fortune World’s Most Admired Companies™.\n\n \nFollow us on LinkedIn, X, Facebook, Instagram, and Insights for the latest news, or visit our website https://www.gehealthcare.com for more information.\n\n \n1 510(k) cleared. Not CE marked. Cannot be placed on the market or put into service or used with human beings until it has been made to comply with CE marking and/or regulatory approval. Not all features available in all markets.\n\n \n2 MV 2019 X-ray CR / DR Market Outlook Report) page 9, 37\n\n \n3 Pearson, Dave. “Radiology techs in especially high demand as 85% of hospitals seek ‘allied’ health workers”, radiologybusiness.com, 23 Oct. 22.\n\n \n \n\n  View source version on businesswire.com: https://www.businesswire.com/news/home/20250724779425/en/ \nGE HealthCare Media Contact:\nKatie Scrivano\nM +1 262-215-5281\nkatherine.scrivano@gehealthcare.com\n Source: GE HealthCare Continue reading with these related stories © 2020-2025 StockTitan.net - Your Edge is Information | Information Only - Not Investment Advice Please enter your login and password \n\n                  Forgot password?\n                \n \n                Don't have an account? \n                \n                  Sign Up!\n                \n Please enter your email address To create a free account, please fill out the form below. Already have an account? Login"
  },
  {
    "title": "6 ways AI is transforming healthcare - The World Economic Forum",
    "url": "https://news.google.com/rss/articles/CBMiekFVX3lxTE1HYld1WGtIMC1zZVR5QUl5OU1IalVXUXdYUmdFRkxaZkxuRnNqYU12SXZJNUd5U1BaZHNBdlVrTWY5alB6SUYyUHBHcHA4eGN4QlE5X3pTN3NHSWE2MU5JeGQtV2szWEJEQzJSZW5mMUdXT0ZrYzVpbzFn?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness. Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness. Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness. The World Economic Forum (“Forum”) uses necessary cookies to make our site work. We would also like to set optional “performance” cookies to gather anonymous site visitation data for internal use and we use \"marketing\" cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. By enabling these cookies, you can help the Forum provide a better website for users like yourself. For more information about the Forum cookies and third-party cookies, see our Cookie Declaration. Cookies are small text files that can be used by websites to make a user's experience more efficient. The law states that we can store cookies on your device if they are strictly necessary for the operation of this site. For all other types of cookies we need your permission. You can change your preferences at any time or withdraw your consent by clicking on “Change your consent” on the Cookie Declaration page.  AI can help to assess ambulance needs.  Image: REUTERS/Henry Nicholls This article has been updated. With 4.5 billion people currently without access to essential healthcare services and a health worker shortage of 11 million expected by 2030, AI has the potential to help bridge that gap and revolutionize global healthcare.  It could even get us back on track to meet the United Nations' Sustainable Development Goal of achieving universal health coverage by 2030. But while the technology is rapidly developing, healthcare is \"below average\" in its adoption of AI compared to other industries, according to the World Economic Forum's white paper, The Future of AI-Enabled Health: Leading the Way.  \"AI transformation goes beyond adopting new tools,\" it says. \"It involves rethinking the fundamentals of how health is delivered and accessed.\"  With the generative AI in the healthcare market expected to hit $2.7 billion this year - and reach close to $17 billion by 2034 - here are six ways AI is already transforming healthcare. A new AI software is \"twice as accurate\" as professionals at examining the brain scans of stroke patients. Two UK universities trained the software on a dataset of 800 brain scans of stroke patients and then trialled it on 2,000 patients.  The results were impressive. Alongside the AI model's accuracy, the software was also able to identify the timescale within which the stroke happened - crucial information for professionals.  As Dr Paul Bentley, consultant neurologist, told the Health Tech Newspaper: “For the majority of strokes caused by a blood clot, if a patient is within 4.5 hours of the stroke happening, he or she is eligible for both medical and surgical treatments. Up to 6 hours, the patient is also eligible for surgical treatment, but after this time point, deciding whether these treatments might be beneficial becomes tricky, as more cases become irreversible. So it’s essential for doctors to know both the initial onset time, as well as whether a stroke could be reversed.” Surprisingly, urgent care doctors miss broken bones in up to 10% of cases. What’s more, X-ray technicians are both in short supply and overloaded.  So using AI to do the initial scan could potentially avoid both unnecessary X-rays and missed fractures. The UK’s National Institute for Health and Care Excellence (NICE) says the technology is safe, reliable and could reduce the need for follow-up appointments.  Accept our marketing cookies to access this content. These cookies are currently disabled in your browser. But there are concerns around the fast rollout of AI in healthcare.  \"It is important that people using these tools are properly trained in doing so, meaning they understand and know how to mitigate risks from technological limitations ... such as the possibility for wrong information being given,\" Dr Caroline Green of the Institute for Ethics in AI at the University of Oxford told the BBC. How is the World Economic Forum creating guardrails for Artificial Intelligence?  In response to the uncertainties surrounding generative AI and the need for robust AI governance frameworks to ensure responsible and beneficial outcomes for all, the Forum’s Centre for the Fourth Industrial Revolution (C4IR) has launched the AI Governance Alliance.  The Alliance unites industry leaders, governments, academic institutions, and civil society organizations to champion responsible global design and release of transparent and inclusive AI systems.  This includes the workstreams part of the AI Transformation of Industries initiative, in collaboration with the Centre for Energy and Materials, the Centre for Advanced Manufacturing and Supply Chains, the Centre for Cybersecurity, the Centre for Nature and Climate, and the Global Industries team. In the UK, around 350,000 people are taken by ambulance to hospital each month. It’s down to paramedics to decide who does or doesn’t need to go, and always with an awareness of how few beds are available.  A study in Yorkshire in the north of England found that in 80% of cases AI could correctly predict the patients that needed to be transferred to hospital. The AI model was trained on factors such as a patient’s mobility, pulse and blood oxygen levels and chest pain – it also proved to respond without bias. NICE did caution, however, that before being put into more widespread use, more training was needed. A new AI machine learning model can detect the presence of certain diseases before the patient is even aware of any symptoms, according to its maker AstraZeneca.  Using medical data from 500,000 people who are part of a UK health data repository, the machine could “predict with high confidence a disease diagnosis many years later”. Slavé Petrovski, who led the research, told Sky News: \"For many of these diseases, by the time they manifest clinically and the individual goes to the doctor because of an ailment or visible observation, that is far down the line from when the disease process began.  “We can pick up signatures in an individual that are highly predictive of developing diseases like Alzheimer's, chronic obstructive pulmonary disease, kidney disease and many others,\" he said. Another UK study has found that an AI tool can successfully detect 64% of epilepsy brain lesions previously missed by radiologists. Trained on the MRI scans of over 1,100 adults and children globally, the AI tool was able to spot lesions more quickly than a doctor, but also discover tiny or obscured ones that had evaded the human eye. \"It's like finding one character on five pages of solid black text,\" lead researcher Dr Konrad Wagstyl told the BBC. \"AI can find about two-thirds that doctors miss - but a third are still really difficult to find.\" Combining AI's findings with human oversight and expertise has the potential to speed up both diagnosis and cure, the researchers say. Doctors must make informed, swift medical decisions: AI could potentially speed these up, but it could also provide unreliable or biased information. A US study found that standard large language models (LLMs) like ChatGPT, Claude or Gemini were unable to provide clinicians with sufficiently relevant or evidence-based answers to their medical questions. But ChatRWD, a retrieval-augmented generation (RAG) system – which essentially combines LLMs with retrieval systems to improve output – produced useful answers to 58% of the questions (compared with 2%-10% for the LLMs). Digital interfaces are increasingly being rolled out to help triage patients, too. In an insight report from 2024, part of the World Economic Forum’s Digital Healthcare Transformation Initiative, a case study on digital patient platform Huma, revealed it could reduce readmission rates by 30%, time spent reviewing patients by up to 40% and “alleviated the workload of healthcare providers”. The report anticipates a future in which technologies like these could “dramatically transform the patient experience. People who are generally healthy can use self-monitoring devices to optimize their mental and physical health, while those with health issues will have access to a wide range of digital solutions”. Administrative tasks are both inevitable and time-consuming in the medical field. Using AI co-pilots could free up clinicians to focus more of their time on patients.  Microsoft has recently announced its Dragon Copilot, an AI healthcare tool that can listen to, and create notes on, clinical consultations. And Google already has a suite of AI models specifically tailored to alleviate some of the administrative burdens in healthcare. In Germany, an AI platform called Elea has cut testing and diagnosis times from weeks to hours and its founders are determined to show that the technology \"can be an ally, not an obstacle\". Co-founder Dr Sebastian Casu told EU-Startups: \"No one joins the healthcare sector to spend hours on admin\".  Of course, having an AI tool listening in and taking notes on your doctor's appointment will be a big mental leap for many. A recent study in the UK found that just 29% of people would trust AI to provide basic health advice (although over two-thirds are comfortable with the technology being used to free up professionals' time). Then there is the question of accuracy. A report last year found that OpenAI's Whisper, used by many hospitals to summarize patient meetings, was hallucinating some of the transcriptions. This is why regulation of AI tools is so vital. In the UK, AI-powered medical devices are strictly regulated by the Medicines and Healthcare products Regulatory Agency. In the US, the Food and Drug Administration (FDA) last year examined the regulation of AI in healthcare and concluded that, while the FDA will “continue to play a central role in ensuring safe, effective, and trustworthy AI tools” it was also essential that “all involved entities … attend to AI with the rigour this transformative technology merits”. Accept our marketing cookies to access this content. These cookies are currently disabled in your browser. Create a free account and access your personalized content collection with our latest publications and analyses. License and Republishing World Economic Forum articles may be republished in accordance with the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License, and in accordance with our Terms of Use. The views expressed in this article are those of the author alone and not the World Economic Forum. Bringing you weekly curated insights and analysis on the global issues that matter. How Brunei’s BruHealth journey charts the future of digital health Mohammad Isham Jaafar and Gong Yingying July 22, 2025 Heightened heatwave risks for the elderly, and other health stories Shyam Bishen July 17, 2025 How one global health leader prepares teams for the unexpected: Gavi CEO How we can harness AI for a healthier, more equitable world Michael Johnson July 14, 2025 Improving access to innovative medicines in Africa starts with clinical trials Jayasree K. Iyer July 9, 2025 Why we should be redefining the private sector's role in global health Sharmishta Sivaramakrishnan July 9, 2025 About us More from the Forum Engage with us Quick links Language editions Privacy Policy & Terms of Service Sitemap © 2025 World Economic Forum Remove menu"
  },
  {
    "title": "Artificial intelligence for healthcare: restrained development despite impressive applications - Infectious Diseases of Poverty",
    "url": "https://news.google.com/rss/articles/CBMifEFVX3lxTE1fOF9yeDNqRFVMeWJSdWk0YTRaX0VRcW50OXg2RHpadFRQb29JeTQ3VDBtQmhGZVljTWxLcGR1RWtkSTBwS2k2S25GUTRLQ2lDR1V4eUVBWXJNZjRpWEpPUUJoTjN3ZlRjdHdOZ1ZnWXFkVUhsMW5kbFNJbzU?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Advertisement \nInfectious Diseases of Poverty\nvolume 14, Article number: 72 (2025)\n            Cite this article\n 506 Accesses 1 Altmetric Metrics details Artificial intelligence (AI) remains poorly understood and its rapid growth raises concerns reminiscent of dystopian narratives. AI has shown the capability of producing new medical content and improving management through optimization and standardization, which shortens queues, while its complete reliance on technical solutions threatens the traditional doctor-patient bond. Based on the World Economic Forum’s emphasis on the need for faster AI adoption in the medical field, we highlight current gaps in the understanding of its application and offer a set of priorities for future research. The historic review of AI and the latest publications point at barriers like complexity and fragmented regulations, while assisted analysis of big data offers new insights. AI’s potential in healthcare is linked to the breakthrough from rule-based computing, enabling autonomy through learning from experience and the capacity of reasoning. Without AI, protein folding would have remained unsolved, as emphasized by the Nobel-honored AlphaFold2 approach. It is expected that AI’s role in diagnostics, disease control, geospatial health and epidemiology will lead to similar progress. AI boosts efficiency, drives innovation, and solves complex problems but can also deepen biases and create security threats. Controlled progress requires industry collaboration leading to prompt acceleration of proper incorporation of AI into the health sphere. Cooperation between governments as well as both public and private sectors with a multi-actor approach is needed to effectively address these challenges. To fully harness AI’s potential in accelerating healthcare reform and shorten queues, while maintaining the compassionate essence of healthcare, a well-coordinated approach involving all stakeholders is necessary. Artificial intelligence (AI) has avoided the headlines until now, yet it has been with us for 75 years [1, 2]. Still, few understand what it really is and many feel uncomfortable about its rapid growth, with thoughts going back to the computer rebelling against the human crew onboard the spaceship heading out into the infinity of space in Arthur C. Clarke’s visionary novel “2001: a Space Odyssey” [3]. Just as in the novel, there is no way back since the human mind cannot continuously operate at an unwavering level of accuracy or simultaneous interact with different sections of large-scale information (Big Data), areas where AI excels. The World Economic Forum has made a call for a faster adoption of AI in the field of healthcare, a fact discussed at length in a very recent white-paper report [4] arguing that progress is not forthcoming as fast as expected despite the evident potential for growth and innovation at an all-time high and strong demand for new types of computer processors. Among the reasons mentioned for the slow uptake in areas dealing with healthcare are barriers, such as complexity deterring policymakers, and the risk for misaligned technical and strategic decisions due to fragmented regulations [4]. The growing importance of AI in the medical and veterinary fields strengthened by recent articles and editorials published in The Lancet Digital Health and The Lancet [5, 6] underlining actual and potential roles of AI in healthcare. We survey this wide spectrum highlighting current gaps in the understanding of AI and how its application can assist clinical work as well as support and accelerate basic research. Before elaborating on these issues, some basic informatics about the technology that has moved AI to the fore is in order. In 1968, when both the film and the novel were released, only stationary, primitive computers existed. Rather than undergoing development in the preserve of large companies and academic institutions, they morphed into today’s public laptops, smartphones and wearable sensor networks. The next turn came with the gaming industry’s insatiable need for ultra-rapid action and life-like characters necessitating massively parallel computing, which led to switching from general-purpose, central processor units (CPUs) to specialized graphics processors (GPUs) and tensor processors (TPUs). Fuelled by this expansion of the processor architecture, neural networks, machine learning and elaborate algorithms capable of changing in conjunction with new data (meta-learning) were ushered in, with the rise of the power to understand and respond to human language through generative, pre-trained transformation (GPT) [7] showing the way forward. Breaking out of rule-based computing by the emergent capability of modifying internal settings, adapting to new information and understanding changing environments put these flexible systems, now referred to as AI, in the fast lane towards domains requiring high-level functionality. Computer systems adapted to a wide range of tasks, for which they were not explicitly programmed, could then be developed and launched into the public area as exemplified by automated industrial production, self-driving vehicles, virtual assistants and chatbots. Although lacking the imagination and versatility that characterize the human mind, AI can indeed perform tasks partly based on reasoning and planning that typically require human cognitive functions, and with enhanced efficiency and productivity. Here, the agent is any entity that can perceive its environment, make decisions and act toward some goal, where rule-based AI has been replaced with proactive interaction. Agent-based AI generally uses many agents working separately to solve joint problems or even collaborating like a team. This approach was popularized by Wooldridge and Jennings in the 1990s, who described decentralized, autonomous AI systems capable of ‘meta-learning’ [8]. They felt that outside targets can be in sanitated and dealt with as computational objects, a methodology that has advanced the study of polarization, traffic flow, spread of disease, and similar phenomena. Although technology did not catch up with this vision until much later, AI today encompasses a vital area of active research producing powerful tools for simulating complex distributed and adaptive systems. The great potential of this approach for disease distributions and transmission dynamics may provide the insights needed to successfully control the neglected tropical diseases (NTDs) as well as dealing with other challenges in the geospatial health sphere [9]. The Internet of Things (IoT) [10], another example agent-based AI, represents the convergence of embedded sensors and software enabling collection and exchanging data with other devices and systems; however, operations are often local and do not necessarily involve the Internet. While the rule-based method follows a set of rules and therefore produces an outcome which is to some degree predictable, the two new components in the agent-based approach include the capability of learning from experience and testing various outcomes by one or several models. This introduces a level of reasoning, which allows for non-human choice, as schematically shown in Fig. 1. The research schemes of two AI’s approaches including Rule-based AI or Agent-based AI (AI refers artificial intelligence) Contrary to common belief, a diagnostic program that today would be sorted under the heading AI was designed already 50 years ago at Stanford University, California, United States of America. The system, called MYCIN [11], was aimed to assist physicians with regard to bacterial blood infections. It was originally produced in book format, utilized a knowledge base of approximately 600 rules and operated through a series of questions to the user ultimately providing diagnosis and treatment recommendation. In the United States, similar approaches aimed at the diagnoses of bacterial infections appeared in the following decades but were not often used due to lack of computational power at the time. Today, on the other hand, this is no longer the limiting factor and AI is revolutionizing image-based diagnostics. In addition to the extensive use of AI-powered microscopy in parasitology, the spectrum includes both microscopic differentiation between healthy and cancerous tissue in microscope sections [12], as well as interpretations of graphs and videos from electrocardiography (EKG) [13], computer tomography (CT) [14, 15], magnet resonance imaging (MRI) [15] and ultrasonography [16] Some AI-based companies are doing well, e.g., ACL Digital (https://www.acldigital.com/) that analyzes data from wearable sensors detecting heart arrhythmias, hypertension, sleep disorders; AIdoc (https://www.aidoc.com/eu/) whose platform evaluates clinical examinations and coordinates workflows beyond diagnosis; and the da Vinci Surgical System (https://en.wikipedia.org/wiki/Da_Vinci_Surgical_System), which has been used for various interventions, including kidney and hysterectiomy [17, 18]. However, others have failed, e.g., ‘Watson for Oncology’, launched by IBM for cancer diagnosis and optimized chemotherapy (https://www.henricodolfing.com/2024/12/case-study-ibm-watson-for-oncology-failure.html) and Babylon Health (https://en.wikipedia.org/wiki/Babylon_Health), a tele-health service that connected people to doctors via video calls, offered wholesale health promotion with high precision and virtual health assistants (Chatbots) that even remind patients to take medication. These final examples of AI-assisted medicine show that strong regulation is needed before this kind of assistance can be released for public use. The focus in the 2024 Nobel ceremony granted AI a central role: while the Physics Prize was awarded for the development of associative neural networks, the Chemistry Prize honored the breakthrough findings regarding how strings of amino acids fold into particular shapes [19]. This thorny problem was cracked by AlphaFold2, a robot based on deep-learning developed at DeepMind, a company that now belongs to Google’s parent Alphabet Inc. The finding that all proteins share the same folding process widened the research scope making it possible to design novel proteins with specific functions (synthetic biology), accelerate drug discovery and shed light on how diseases arise through mutations. The team that created this robot as its current sight on finding out how proteins interact with the rest of the cellular machinery. AlphaFold3, an updated version of the architecture generates accurate, three-dimensional molecular structures by pair-wise interaction between molecular components, which can be used to model how specific proteins work in union with other cell components exposing the details of protein interaction. These new applications highlight the exponential rise of AI’s significance for research in general and for medicine in particular. The solution to the protein-folding problem not only reflects the importance of the training component but also demonstrates that AI is not as restricted as the human mind is when it comes to large realms of information (Big Data), which is needed for a large number of activities in modern society, such as autonomous driving, large-scale financial transactions as dealt with in banks on a daily basis. Big Data is common also in healthcare and it involves not only when dealing with hospital management and patient records, but also with large-sale diagnostic approaches. An academic paper, co-authored with clinicians and Google Research, investigated the reliability of diagnostic AI system, finding that machine learning reduced the number of false positives in a large mammography dataset by 25% (and also reached conclusions considerably faster), compared with the standard, clinical workflow without missing any true positives [20], a reassuring result. AI tools have been widely applied in epidemiological surveillance of vector-borne diseases. Due to vectors’ sensitivity to temperature and precipitation, the arthropod vectors are bellwether indicators, not only for the diseases they often carry but also for climate change. By gaining deeper insights into the complex interactions between climate, ecosystems and parasitic diseases with intricate life cycles, AI technologies assist by handling Big Data and even using reasoning to deal with obscure variations and interactions of climate and biological variables. To keep abreast of this situation, the connections between human, animal and environmental health not only demand data-sharing at the local level but also nationally and globally. This move towards the One Health/Planetary Health approach is highly desirable, and AI will unquestionably be needed for sustaining diligence with respect to the Big Data repositories required for accurate predictions of disease transmission, while AI-driven platforms can further facilitate real-time information exchange between stakeholders, optimize energy consumption and improve resource management for infections in animals and humans, in particular with regard to parasitic infections [21]. Proactive synergies between public health and other disciplines, such as ecology, genomics, proteomics, bioinformatics, sanitary engineering and socio-economy make the future medical agenda not only exciting and challenging, but also highly relevant globally. In epidemiology, there has been a strong advance across the fields of medical and veterinary sciences [22], while previously overlooked events and unusual patterns now stand a better chance of being picked up by AI analysis of indirect methods, e.g., phone tracing, social media posts, news articles and health records. Technically less complex, but no less innovative operations are required to update the roadmap for elimination of the NTDs issued by the World Health Organization (WHO) [23]. The Expanded Special Project for the Elimination of Neglected Tropical Diseases (ESPEN) is a collaborative effort between the WHO regional office for Africa, member states and NTD partners. Its portal [24] offers visualization and planning tools based on satellite-generated imagery, climate data and historical disease patterns that are likely to identify high-risk areas for targeted interventions and allocate resources effectively. In this way, WHO’s roadmap for NTD elimination is becoming more data-driven, precise and scalable, thereby accelerating progress. Established as far back as 1993, Artificial Intelligence Research was the first journal specifically focused on AI, soon followed by an avalanche of similar ones (https://www.scimagojr.com/journalrank.php?category=1702). China, India and United States are particularly active in AI-related research. According to the Artificial Intelligence Index Report 2024 [25], the total number of general AI publications had risen from approximately 88,000 in 2010 to more than 240,000 in 2022, with publications on machine learning increasing nearly sevenfold since 2015. If also conference papers and repository publications (such as arXiv) are included along with papers in both English and Chinese, the number rises to 900,000, with the great majority originating in China [26]. A literature search based solely on PubMed, carried out by the end of 2024 by us using “AI and infectious disease(s)” as search term resulted in close to 100,000 entries, while the term “Advanced AI and infectious disease(s)” only resulted in about 6600. The idea was to find the distintion between simpler, more rule-based applications and proper AI. Naturally, the results of this kind can be grossly misleading as information on the exact type of computer processor used, be it CPU, GPU or TPU, is generally absent and can only be inferred. Nevertheless, the much lower figure for “Advanced AI and infectious disease(s)” is an indication of the preference for less complex AI applications so far, i.e. work including spatial statistics and comparisons between various sets of variables vis-à-vis diseases, aiming at estimating distributions, hotspots, vector breeding sites, etc. With as many as 100,000 medical publications found in the PubMed search, they clearly dominate in relation to the total of more than 240,000 AI-assisted research papers found up to 2022 [25]. The growing importance of this field is further strengthened by recent articles and editorials [27, 6]. Part of this interest is probably due to the wide spectrum of the medical and veterinary fields and AI’s potential in tracing and signalling disease outbreaks plus its growing role in surveillance that has led to a surge of publications on machine learning, offering innovative solutions to some of the most pressing challenges facing health research today [28]. Healthcare reform, with special reference to improved coverage and shortening of queues, is urgently needed. The technology assisting this requires prompt acceleration of the incorporation of AI into the health sphere, but it must be strongly regulated to avoid bias. These challenges affect us all, requiring cooperation among all stakeholders, including governments as well as public and private sectors (Table S1). However, the shift from local epidemiological observations to a global dynamic approach without close collaboration with the computer industry has strained the production and sharing of results from epidemiological research and surveillance. If initiated, such collaboration could lead to specific computer systems adapted to dealing with the global field dynamically by knitting together results from ongoing control efforts in different endemic countries. Computer-assisted support has significantly contributed to advances in control and elimination of the NTDs, but projects still remain local , often focused on single countries and/or on single diseases. Here, AI could play an important role in reaching across borders, corralling stakeholders and sharing both data and information on resources more effectively. Although this is indeed ongoing in some places, a broader approach, faster advancement and better availability would be welcome. Not applicable. Artificial intelligence Neglected tropical diseases Central processor units Graphics processors Tensor processors Generative, pre-trained transformation Electrocardiography Computer tomography Magnet resonance imaging Expanded Special Project for the Elimination of Neglected Tropical Diseases World Health Organization Shannon CE. Programming a computer for playing chess. Philos Mag. 1950;41(314):256–75. \n                    Google Scholar \n                 Turing A. Computing machinery and intelligence. Mind. 1950;59(236):433–60. \n                    Google Scholar \n                 Clarke AC. A Space Odyssey. New American Library1968, publisher. 2001. The World Economic Forum. Transformation of Industries in the Age of AI-The Future of AI-Enabled Health: Leading the Way (28 pp). Jan. 2025. https://reports.weforum.org/docs/WEF_The_Future_of_AI_Enabled_Health_2025.pdf. Accessed on 20 April 2025. Gaetani M, Mazwi M, Balaci H, Breer R, Maratta C. Artificial intelligence in medicine and the pursuit of environmentally responsible science. Lancet Digit Health. 2024;6(7):e438–40. CAS \n    PubMed \n    \n                    Google Scholar \n                 The Lancet. Rethinking research and generative artificial intelligence. Lancet 2024;404(10447):1. CAS \n    PubMed \n    \n                    Google Scholar \n                 Busch F, Hoffmann L, Dos Santos DP, Makowski MR, Saba L, Prucker P, et al. Large language models for structured reporting in radiology: past, present, and future. Eur Radiol. 2025;35(5):2589–2602.  PubMed \n    \n                    Google Scholar \n                 Wooldridge M, Jennings N. Intelligent agents: theory and practice. Know Eng Rev. 1995;10(2):115–52. \n                    Google Scholar \n                 Xue JB, Xia S, Wang XY, Huang LL, Huang LY, Hao YW, et al. Recognizing and monitoring infectious sources of schistosomiasis by developing deep learning models with high-resolution remote sensing images. Infect Dis Poverty. 2023;12:6. PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Shafiq M, Gu Z, Cheikhrouhou O, Alhakami W, Hamam H. The Rise of “Internet of Things”: Review and open research issues related to detection and prevention of iot-based security attacks. Wirel Commun Mob Comput. 2022; 8669348. https://doi.org/10.1155/2022/8669348 Shortliffe EH. Computer-based medical consultations:MYCIN. J Clin Eng. 1976;388(1):1–286. \n                    Google Scholar \n                 Wang S, Pan JL, Zhang X, Li YY, Liu WX. Towards next-generation diagnostic pathology: AI-empowered label-free multiphoton microscopy. Light Sci Appl. 2024;13(1):254. CAS \n    PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Androulakis E, Fielder C. Artificial intelligence in ECG diagnostics-where are we now? European Society for cardiology (ESC) 10 pp, published online 02 Apr 2024. https://www.escardio.org/Councils/Council-for-Cardiology-Practice-(CCP)/Cardiopractice/artificial-intelligence-in-ecg-diagnostics-where-are-we-now. Accessed 28 April 2025. Zhang S, Zhu ZT, Yu ZF, Sun HF, Su Y, Huang H, et al. Effectiveness of AI for enhancing computed tomography image quality and radiation protection in radiology: systematic review and meta-analysis. J Med Internet Res. 2025;27: e66622. PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Khalifa M, Albadawy M. AI in diagnostic imaging: revolutionising accuracy and efficiency. Comput Methods Programs Biomed Update. 2024;5: 100146. \n                    Google Scholar \n                 Sultan LR, Mohamed MK, Andronikou S. ChatGPT-4: a breakthrough in ultrasound image analysis. Radiol Adv. 2024;1(1):umae006. \n                    Google Scholar \n                 Sakina F. A group of surgeons and Da Vinci Xi surgical robot in Dubai have performed a surgery on an Emirati patient who was suffering from a blockage in the upper part of the ureter. The Siasat Daily, 19 May 2022. https://www.wam.ae/en/article/hszreqpq-dubai-hospital-launches-surgical-robot-facilitate. Accessed on 28 April 2025. Wright JD, Ananth CV, Lewin SN, Burke WM, Lu YS, Neugut AI, et al. Robotically assisted vs laparoscopic hysterectomy among women with benign gynecologic disease. JAMA. 2013;309(7):689–98. CAS \n    PubMed \n    \n                    Google Scholar \n                 Jumper J, Evans R, Pritzel A, Green T, Figurnov M, Ronneberger O, et al. Highly accurate protein structure prediction with AlphaFold. Nature. 2021;596:583–9. CAS \n    PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Dvijotham KD, Winkens J, Barsbey M, Ghaisas S, Stanforth R, Pawlowski N, et al. Enhancing the reliability and accuracy of AI-enabled diagnosis via complementarity-driven deferral to clinicians. Nat Med. 2023;29(7):1814–20. CAS \n    PubMed \n    \n                    Google Scholar \n                 Parija SC, Poddar A. Artificial intelligence in parasitic disease control: a paradigm shift in health care. Trop Parasitol. 2024;14(1):2–7. PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Wong F, de la Fuente-Nunez C, Collins JJ. Leveraging artificial intelligence in the fight against infectious diseases. Science. 2023;381(6654):164–70. CAS \n    PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 World Health Organization. Ending the neglect to attain the Sustainable Development Goals: A road map for neglected tropical diseases 2021–2030. https://www.who.int/publications/i/item/9789240010352. Accessed 28 April 2025. The Expanded Special Project for Elimination of NTDs. https://espen.afro.who.int/. Accessed 1 February 2025. Artificial Intelligence Index Report 2024. https://aiindex.stanford.edu/report/. Accessed 28 April 2025. Our world in data. https://ourworldindata.org/grapher/annual-scholarly-publications-on-artificial-intelligence. Accessed 28 April 2025. Gaetani M, Mazwi M, Balaci H, Greer R, Maratta C. Artificial intelligence in medicine and the pursuit of environmentally responsible science. Lancet Digit Health. 2024;6(7):e438–40. CAS \n    PubMed \n    \n                    Google Scholar \n                 Amer S, Augustijn EW, Anthonj C, Tjaden N, Blanford J, Van den Homberg M, et al. Geospatial Health: achievements, innovations, priorities. Geospat Health. 2024;19(2):1355. \n                    Google Scholar \n                 Download references Not applicable. Not applicable. Geospatial Health, Ingerod, Brastad, Sweden Robert Bergquist Department of Veterinary Medicine and Animal Production, University of Naples Federico II, WHO Collaborating Centre for Diagnosis of Intestinal Helminths and Protozoa (WHOCC-ITA116), Via Delpino, 1, 80137, Naples, Italy Laura Rinaldi National Institute of Parasitic Diseases at Chinese Center for Disease Control and Prevention (Chinese Center for Tropical Diseases Research); National Key Laboratory of Intelligent Tracking and Forecasting for Infectious Diseases; Key Laboratory on Parasite and Vector Biology, Ministry of Health; WHO Centre for Tropical Diseases; National Center for International Research on Tropical Diseases, Ministry of Science and Technology, Shanghai, 200025, China Xiao-Nong Zhou School of Global Health, Chinese Center for Tropical Diseases Research, Shanghai Jiao Tong University School of Medicine, Shanghai, 200025, China Xiao-Nong Zhou Hainan Center for Tropical Diseases Research (Sub-Center of Chinese Center for Tropical Diseases Research), Haikou, China Robert Bergquist, Laura Rinaldi & Xiao-Nong Zhou Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar RB and XNZ wrote the manuscript; LR added important parts after reading the original; RB, LR and XNZ reviewed and revised the manuscript. Correspondence to\n                Xiao-Nong Zhou. Not applicable. Not applicable. XN Zhou is the Editor-in-Chief of the journal Infectious Diseases of Poverty. He was not involved in the peer-review or handling of the manuscript. The authors have no other competing interests to disclose. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data. Reprints and permissions Bergquist, R., Rinaldi, L. & Zhou, XN. Artificial intelligence for healthcare: restrained development despite impressive applications.\n                    Infect Dis Poverty 14, 72 (2025). https://doi.org/10.1186/s40249-025-01339-z Download citation Received: 08 March 2025 Accepted: 01 July 2025 Published: 20 July 2025 DOI: https://doi.org/10.1186/s40249-025-01339-z Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article.  \n                            Provided by the Springer Nature SharedIt content-sharing initiative\n                         Advertisement ISSN: 2049-9957 \n            By using this website, you agree to our\n            Terms and Conditions,\n            Your US state privacy rights,\n            Privacy\n                statement and\n            Cookies policy.\n                Your privacy choices/Manage cookies we use in the preference centre.\n          © 2025 BioMed Central Ltd unless otherwise stated. Part of\n            Springer Nature."
  },
  {
    "title": "Navigating promise and perils: applying artificial intelligence to the perinatal mental health care cascade - Nature",
    "url": "https://news.google.com/rss/articles/CBMiX0FVX3lxTFBnMk1XekYyUnl3bVVyTk8zcWx6bWFoYU1WajEzY0pmdUVIb184SGF0YmFxT3MzZ3R0WTVyWmpILVpaSXFUR0RjYzEtNmRZclkyWFVPZmVqc2Jhd2JyMFI0?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript. Advertisement npj Health Systems has APC waivers available that can be allocated upon acceptance on an ad-hoc basis. For additional information, contact the Journal Publisher, Tony Chen. \n \nnpj Health Systems\nvolume 2, Article number: 26 (2025)\n            Cite this article\n The perinatal mental health care cascade is wrought with systemic issues contributing to under-detection and outcome disparities. Herein, we examine its unique characteristics and explore how artificial intelligence (AI) may improve care while acknowledging associated ethical considerations and implementation challenges. We emphasize the need for policy reforms to screening, data collection, and regulatory processes to build ethical and robust AI-enhanced health system infrastructures. Perinatal mental health conditions (PMHCs) are the most prevalent yet underdiagnosed complication of pregnancy and postpartum1,2. PMHCs include conditions such as depressive/bipolar disorders, anxiety disorders, obsessive-compulsive disorder, posttraumatic stress disorder, substance use disorders, and psychosis. The estimated societal financial cost of untreated PMHCs is a staggering $14.2 billion3. This is an underestimation as it excludes the often-overlooked mental health experiences of non-birthing partners4. The most disturbing impact is the loss of life, as the leading causes of postpartum-period deaths are suicide and overdose5,6,7. PMHC-related deaths are preventable with appropriate identification, timely intervention, and adequate treatment. However, due to systemic shortcomings, the current healthcare infrastructure is not built to support birthing people and their families, especially those from minoritized backgrounds8,9. Artificial intelligence (AI) is a powerful application of computer science in which computers can perform cognitive functions such as thinking, learning, decision-making, and problem-solving. The recent innovative application of large language models (LLMs) and generative AI has catalyzed significant innovation and task automation across sectors, including healthcare10. The application of AI to perinatal mental health is in its infancy but shows potential to address gaps in the current treatment cascade. This paper aims to provide an overview of AI applications that address current barriers in the perinatal mental health care cascade while highlighting possible perils of such applications, specifically related to equity and safety concerns. This work adds to existing literature by applying the treatment cascade framework to bridge AI technical capabilities and clinical perinatal mental health needs. The cascade of care (Fig. 1) is a theoretical framework outlining care stages associated with quality care and used to monitor a healthcare system’s effectiveness in addressing care needs11. Within perinatal mental health, this cascade has been estimated for perinatal depression because it is the most screened and researched PMHC8. This figure illustrates the sequential stages of perinatal mental health care delivery and the multilevel barriers that can impede progression through the care continuum. The cascade represents the ideal pathway from initial population screening through achievement of symptom remission, with each stage representing a transition point where patients may be lost to follow-up or experience delays in care. The care cascade consists of four primary stages: (1) Screening & Identification - systematic screening of the perinatal population using validated instruments to identify individuals at risk for or experiencing mental health conditions; (2) Connection to Specialized Care - successful referral and linkage to appropriate mental health services, including initial appointment attendance; (3) Treatment Delivery - provision of evidence-based interventions tailored to perinatal mental health needs; and (4) Remission - achievement of clinically significant symptom reduction and functional improvement. Barriers to care progression are categorized into socioecological domains. Patient-level barriers comprise factors such as mental health stigma, limited social support, and transportation. Provider-level barriers encompass healthcare provider factors, including training and education, resource availability, time constraints, symptom acceptability, and effectiveness. Institutional-level barriers include fragmented clinical networks, services available based on insurance type, staffing levels, and drug shortages. Community barriers encompass system-level obstacles, including the cost of care and support, as well as limited access to specialized providers. Policy-level barriers include systemic inequities, resource allocation, and data gaps. Approximately 5 million pregnancies occur in the US annually, resulting in roughly 3.6 million live births12. Current estimates suggest 20% of these pregnancies will have PMHC complications, with an increased risk for those with pregnancy complications, a neonatal intensive care stay, or experiencing a loss1. For minoritized populations, this estimate grows to nearly 50%13, largely driven by systemic exposures to factors (e.g., systemic racism, trauma) that increase the chance of experiencing mental distress and drive limited connection to adequate support9,14. These same systemic drives also limit the availability of PMHC data for these marginalized communities. The current American College of Obstetricians and Gynecologists (ACOG) guidelines for pregnancy management recommend screening for depression and anxiety at least once during prenatal visits (i.e., 10-15 recommended visits) and at least once in the postpartum period if screening was performed during the prenatal period15,16. They also urge the inclusion of comprehensive assessments of physical, social, and psychological well-being during postpartum encounters15,16. These guidelines have recently evolved to highlight the increasing need to screen for PMHCs; however, current clinical practice continues to lag17. Despite the growing recognition of PMHCs and the specific awareness of perinatal depression, current estimates hold that up to 75% of clinically significant perinatal depression remains unidentified14. Disparities persist for minoritized groups, with Black, Asian, and Indigenous birthing people being consistently less likely to receive PMHC screenings9. Such inequality appears to be a significant driver of overall inequity in perinatal depression and other PMHCs. Given the relatively low screening of other PMHCs, detection rates are presumed to be worse, further exacerbating treatment discrepancies17,18. Data about non-birthing partners is scarce but growing. Estimates suggest that approximately 10% of non-birthing partners experience perinatal depression or anxiety19,20. This is likely an underestimate due to the unique presentation of depressive symptoms often observed among cis-male partners, with some studies suggesting an equal representation of depression among cis-male partners when these differences are considered19. Similarly, current estimates of postpartum deaths do not include those occurring among fathers and co-parents, as researchers are only now recognizing the risk of mental health conditions within this population19,21. To our knowledge, no data is available specifically for rates of under-identification of mental health needs for non-birthing partners. Currently, there are no standardized recommendations to screen non-birthing partners regularly during the pregnancy period22. While current identification relies on self-administered screening tools and provider assessment, machine learning—a specific type of AI—offers novel approaches to risk prediction. A recent scoping review of 14 articles examining the application of AI in PMHC research found that approximately 60% were focused on developing risk prediction models using supervised machine learning23. This technique uses historical data with known outcomes to forecast future cases. These predictive models were primarily developed using electronic health record (EHR) data, such as lab values, demographic variables, mental health history, and utilization, with a demonstrated acceptable discrimination ability (i.e., AUC > 0.7)23. Still, achieving “good” performance (i.e., AUC > 0.8) typically required incorporating PMHC screening data or historical mental health data, suggesting standard EHR data alone may be insufficient for optimal risk detection24,25. While EHRs contain both structured (e.g., values) and unstructured data (e.g., clinical notes), these models only analyze structured elements, excluding valuable information from clinical notes. Unstructured data has historically been challenging to analyze because meaningful and consistent insights cannot be extracted without the use of computationally intensive natural language processing (NLP) methods23,26. Two notable studies from this review demonstrated novel NLP applications. One successfully scanned clinical notes for risk indicators with acceptable recall and precision27. Another study analyzed approximately 67,000 social media posts to assess paternal perinatal depression risk using NLP and classification, a supervised learning technique that predicts membership in a class (e.g., low, moderate, or high risk)28. This application identified high-risk fathers based on their linguistic patterns and engagement levels. A similar study focused on Reddit posts by pregnant women leveraged sentiment analysis—a method used to analyze text data to detect emotional states—similarly finding the ability to detect and track changes in depressive sentiments over time29. Another application of AI language processing that relies heavily on deep learning—a type of machine learning built on artificial neural networks—is ambient AI scribes. These AI scribes automatically convert patient-provider conversations into documentation while allowing clinicians to focus on patient care30. Beyond documentation, these systems can analyze conversation patterns to identify language indicating psychological distress. Pilot trials examining voice-based models for perinatal depression showed higher sensitivity and recall, signaling this approach may be an improvement over traditional screening method. Additionally, when integrated with computer vision technology that analyzes facial expressions, these multi-modal systems may detect subtle indicators of PMHCs that routine screening might miss31. This approach aligns with patient preferences, as many individuals feel more comfortable discussing their difficulties directly with clinicians than completing standardized screening tools32. Although speech and visual diagnostics are still emerging, they offer the potential to facilitate more natural communication between patients and providers regarding PMHC concerns. Overall, leveraging these applications to improve identification and risk stratification are promising for overcoming traditional identification barriers. Beyond identifying those at risk, connecting patients to the appropriate level of care is often challenging, as mental healthcare resources are fragmented in most communities. Patient preferences for care and their match to available resources also prevents appropriate support for managing PMHCs. Primary care providers (PCPs) and perinatal providers, such as obstetricians/gynecologists and midwives, are patients’ most common clinical touchpoints. However, few perinatal health specialists feel comfortable managing the full spectrum of PMHC, oftentimes due to a lack of formal training in behavioral medicine33. As such, adequate management of PMHCs typically requires referrals to behavioral medicine specialists, due to the limited number of behavioral providers integrated into perinatal clinics33,34. Yet, even with referrals, significant workforce shortages limit access to these services, with many waiting months to be connected with the appropriate provider. Currently, 49% of people in the US live in mental health shortage areas, with less than 30% of psychiatric health needs being met nationwide35. The shortage is particularly acute for PMHC-trained psychiatrists, as 21 states have fewer than one perinatal psychiatrist per 5000 births34. Most states require dozens to hundreds of additional psychiatrists to meet a growing demand34. Once connected, there are several evidence-based treatments available for PMHCs, including medication management, psychotherapy modalities, and community-based care support. Cognitive behavioral therapy, interpersonal psychotherapy, and other psychotherapy modalities serve as first-line treatments for mild to moderate PMHCs36. Patients generally prefer psychotherapy and community-based support, but access varies significantly36,37. Frequently cited initiation rates range from 13% to 15%, although well-resourced integrated systems have demonstrated rates up to 60%8,38. Most healthcare systems struggle to provide effective, tailored psychotherapy due to mental health workforce shortages, restrictive insurance coverage, and inadequate reimbursement for scalable delivery methods. Transportation and childcare needs can also impact the continuation of treatment, often necessitating multiple visits per month during the acute phase of treatment. Most mental health outpatient offices lack childcare support, or if children are allowed to come, they may not be built with their needs in mind39. Treatment for severe PMHCs requires combined medication management and psychotherapy for optimal outcomes40. Several established pharmacological options exist, including selective serotonin reuptake inhibitors, serotonin and norepinephrine reuptake inhibitors, and atypical antidepressants, with mood stabilizers and antipsychotics used in specific cases41. Recently FDA-approved neuroactive steroids for severe postpartum depression face adoption barriers due to administration challenges, side effect concerns, and limited provider awareness. Perinatal providers often restrict their medication management to familiar PMHCs (e.g., depression), showing reluctance to modify failed treatment regimens or manage complex conditions like bipolar disorder and psychosis42. Drug shortages have also impacted conditions such as ADHD, where stable patients required different agents due to supply issues43,44. The PMHC-trained psychiatrist shortage, combined with perinatal provider management reluctance, continues to be a significant barrier to appropriate medication access, especially to novel agents40,41. Peer support specialist, individuals with lived experiences of PMHC with or without additional training, offers a valuable alternative for individuals who feel stigmatized by potential PMHC diagnoses—a common experience during the perinatal period45,46. Drawing from their PMHC experiences, peer support workers provide understanding and mutual empowerment to those navigating similar challenges. These services are usually provided in the community through local and national organizations. Similarly, as non-clinical professionals, doulas offer physical, informational, and emotional support throughout the perinatal period47. They help mitigate factors that may worsen PMHCs and can serve as a bridge to professional resources45. In addition, doula support has been shown to lower PMHC incidence and reduce exposure to birth trauma47. Connection to a doula or peer support specialist is an often underutilized option due to a lack of awareness about these professionals, limited insurance coverage, and the cost-prohibitive nature of pursuing credentialing to receive payment from insurance when programs are available. Doulas are generally more accessible to well-resourced individuals who can pay privately and have had fewer life experiences that could increase the risk of PMHCs, despite studies suggesting that doulas are most effective for those who are resource-limited and at higher risk48. The increased use of these community-based providers has improved outcomes for marginalized groups less likely to be maintained in the cascade. The enhanced capabilities of AI applications to analyze and generate language have significantly improved their usefulness as assistants in clinical interactions with patients. This will be particularly helpful in addressing knowledge gaps for providers without PMHC expertise. Traditional voice assistants (e.g., Siri, Alexa) provided clinically accurate PMHCs information only 14–29% of the time; however, newer LLM-based systems (e.g., ChatGPT) achieved accuracy rates of 79–100% on standardized clinical questions49,50. Increasing access to LLM-enhanced voice assistance will provide an opportunity for the dissemination of accurate PMHC treatment recommendations, thereby improving medication management in areas with prescriber shortages51. State-level perinatal psychiatric call lines have demonstrated that increasing providers’ knowledge through access to a PHMC-trained professional improves the management of PMHCs in their clinics using local resources52. Despite their effectiveness, perinatal psychiatric consultation lines are only available in 25 states, and provider awareness of the national consultation service remains limited52. The long-term sustainability of these support services is further challenged by their dependence on grants and governmental funding. If appropriately trained and updated, healthcare-specific voice assistance supported by secure LLMs could provide a scalable solution for improved care when a PMHC is identified. AI-based systems can also extend PMHC connection and treatment beyond clinical interactions through autonomous AI agent tools, such as chatbots53. These tools can engage patients, provide basic emotional support, facilitate psychotherapy, and connect users to crisis resources—functions that mirror community-based support, such as doulas and peer specialists. When integrated with EHRs, these systems would enable clinicians to monitor and respond to care cascade initiation or escalation needs. Although digital mental health solutions are not new, over 90% of traditional psychotherapy chatbots rely on rule-based models with predetermined response sets54. However, emerging AI technologies enable more flexible and responsive interactions. Perinatal populations report being open to using mental health chatbots. Current AI-powered apps have demonstrated the ability to reduce depression symptoms and have provided safeguards for privacy53,54. Similarly, chatbots have been developed outside of the mental health space to provide doula-like informational and emotional support. These informational chatbots also combine connection features to connect users with local doulas to provide labor and deliver support55,56. This expanded access to resources may help reduce perinatal access disparities (Fig. 2). This figure illustrates the various AI applications currently deployed or that could be deployed to enhance the PMHC treatment cascade, as well as the AI systems that underpin these technologies. Clinical applications include four key domains: (1) prediction models and case detection, encompassing risk stratification, early warning systems, and social media monitoring; (2) clinical decision support, providing treatment recommendations, evidence-based guidelines and risk stratification tools; (3) treatment access expansion through teletherapy platforms, AI chatbot support systems, and digital resource navigation; and (4) treatment monitoring via symptom tracking apps, progress assessment tools, and relapse prevention systems. The clinical applications leverage four primary AI technology categories: (a) machine learning, incorporating predictive analytics, classification algorithms, pattern recognition and deep learning; (b) natural language processing enabling text analysis, sentiment analysis, and conversation agents; (c) computer vision systems that include facial expression analysis, behavioral monitoring, and visual interaction tracking; and (d) autonomous AI agents such as virtual assistants, intelligent monitoring systems and adaptive learning agents. Treatment adherence is crucial for symptom remission for PMHCs. Remission is defined as the absence of symptoms of the disorder at a clinically diagnosable level and often requires continued maintenance treatment. Medication management during pregnancy faces particularly high discontinuation rates—up to 80%—largely due to concerns about fetal effects, despite evidence that untreated PMHCs pose similar risks57. Discontinuation rates are generally lower for psychotherapy but increase postpartum, a specifically vulnerable period. Common barriers to treatment continuation include time constraints, financial costs, and poor provider fit. PMHC treatments are highly effective, with pooled estimates suggesting that over 50% of individuals achieve remission with adequate treatment58,59. Despite these effective treatments, estimates suggest only 3.2% to 4.8% of people with perinatal depression will ultimately achieve remission8. Many of the AI-based treatment enhancements may also help to reduce premature discontinuation of treatment. For example, the integration of AI facilitated psychotherapy applications with traditional therapy, especially those provided virtually, addresses access, transportation, and time barriers, which are often cited as reasons for discontinuing some psychotherapy interventions60. Autonomous AI agents can also work to re-engage patients, in medication management or therapy, by adapting their approach based on previous interactions with the patient. This adaptive learning is another feature that is enhanced through the flexibility of generative systems compared to prior rule-based frameworks. In addition, early work suggests the ability to integrate commercial wearable device information not only to detect postpartum depression but also to monitor progress61. AI tools have also demonstrated potential as an early detection tool for those who will experience persistent symptoms or relapse versus those who are more likely to achieve remission62. Those with persistent symptoms are more likely to require different agent trials or a combination of treatment modalities, so knowing this risk potential would allow for more tailored treatment by providers. The potential of AI to expand access to perinatal mental healthcare is considerable; however, important technical, ethical, and practical challenges must be addressed before its full potential is realized (Fig. 3). Improvement will require addressing several systemic drivers of inequity and adopting a multifaceted approach that involves technology, policy reform, and stakeholder engagement to ensure equitable outcomes. This figure outlines some of the potential pitfalls of AI implementation across four domains: Bias, including due to the underrepresentation of minoritized groups in training data, limited structured information related to PMHCs outside of depression and anxiety, disparities in screening data resulting in skewed risk assessments, and access inequity in the rollout of systems. Cost implications, including initial set-up costs, employing technical expertise needed for updates, and the cost incurred to monitor models and tailor them to the institution. Privacy and safety concerns outline the risks of breaches, data sharing, consent, and regulatory considerations. Environmental impact encompasses concerns about pollution, the placement of AI infrastructure in marginalized communities, and the natural resources demands required to sustain these systems. While AI offers significant potential to enhance access to perinatal mental healthcare, its effectiveness is hindered by critical limitations in training data, which often perpetuate systemic inequities63. Current healthcare systems collect limited screening data, primarily focusing on depression and anxiety while neglecting other PMHCs, thereby restricting the scope of AI applications. This narrow focus, compounded by disparities in data collection, compromises the accuracy and reliability of AI models, increasing the risk of algorithmic bias. Furthermore, the lack of transparency in AI training data (e.g., due to patient privacy concerns) hinders the understanding of the rationale behind clinical recommendations, thereby undermining trust among patients and providers64. The growing emphasis on explainable AI and algorithmic transparency further highlights these challenges, as documentation of clinical protocols and verifiable model reasoning is frequently absent65. Without robust bias and fairness assessments, it becomes difficult to ascertain whether developers have adequately addressed inherent data biases. This, in turn, raises concerns about the models’ efficacy and potential harm they may cause to marginalized communities66. The Data to Save Moms Act represents a critical step toward addressing these issues by prioritizing perinatal data collection in the US, particularly for marginalized populations67. However, given documented instances of AI-driven biases adversely impacting underserved communities68, additional policy measures are imperative, including mandates for universal PMHC screening and requirements to demonstrate algorithmic fairness before regulatory approval. Such reforms, coupled with stakeholder collaboration, are essential to ensure AI advances promote health equity rather than exacerbate disparities26. Healthcare systems implementing AI solutions for perinatal mental health must carefully consider their specific patient populations and available data resources. Generic LLMs, while accessible, may not adequately address the unique needs of diverse patient populations or reflect local practice patterns and resources69. Effective implementation requires tailoring these tools to account for demographic variations, cultural considerations, and community-specific barriers to care that characterize each healthcare system’s patient population. The challenge of model drift presents significant operational concerns. As clinical guidelines evolve and new research emerges, AI models become outdated, potentially leading to suboptimal or incorrect recommendations70,71. Healthcare systems must develop robust processes for monitoring model performance, incorporating new clinical evidence, and updating AI tools regularly. This requires sustained investment in technical expertise and infrastructure - resources many healthcare systems lack, particularly those serving underserved communities. Persistent technological integration barriers, such as fragmented EHRs and limited interoperability between clinical systems, also hinder the effectiveness of AI tools and may introduce new risks72. Therefore, healthcare systems must assess their technical readiness to implement and maintain these solutions effectively over time. The deployment of AI in perinatal mental health requires significant initial investments in infrastructure, expertise, and data security, posing challenges for resource-limited healthcare systems73. However, advancements such as cloud services, shared computing resources, and cost-effective hardware like Nvidia’s $3000 AI “supercomputer” offer promising solutions74,75. Despite this, sustaining AI tools will continue to be costly due to ongoing infrastructure and model maintenance, regulatory compliance, and clinical effectiveness assessments, to name a few26. Beyond financial costs, AI infrastructure has substantial environmental impacts, felt more acutely in low-income communities76, including significant CO2 emissions and electrical and water demands akin to small cities. Marginalized communities disproportionately bear these environmental burdens, which can exacerbate perinatal mental health issues and widen existing health disparities. Enhancing AI model efficiency to reduce resource consumption and developing robust policies and regulations to mitigate environmental impacts are critical. Developing AI models requires substantial data, raising concerns about privacy, security, and patient agency. Under the Health Insurance Portability and Accountability Act (HIPAA), organizations must notify patients of potential data uses through the Notice of Privacy Practices (45 CFR §164.520). However, if classified as a research activity, no such notification or authorization is required (45 CFR §164.512(i)). Also, outsourcing often becomes necessary, given the technical expertise and computing resources needed to develop custom LLMs. While protections are in place for research (Institutional Review Boards and Privacy Boards; 45 CFR §164.512(i)) and outsourcing (Business Associate Agreements; 45 CFR §164.502(e)) activities, neither involves the patient, diminishing their agency, which is a rising concern77. AI systems are not impervious to exploitation. Breaches can compromise model performance, expose training data, and bypass implemented safety measures78. Healthcare systems are already battling rising cyber-attacks and resulting data breaches79,80, and AI systems offer an enticing target for attackers. As AI integration in healthcare expands, robust information security measures become increasingly critical. Patient safety concerns regarding AI in mental health support extend beyond data security. Recent incidents involving LLM chatbots have highlighted serious risks. These include cases where AI systems provided potentially harmful mental health advice or inappropriately mimicked mental health professionals, with tragic consequences81. While developers have responded with enhanced safeguards and modified marketing practices, intentional design choices in AI applications present additional risks. For instance, therapy tools could potentially embed promotional content within therapeutic interactions without provider awareness82. These vulnerabilities underscore the critical importance of robust regulatory oversight for AI-enabled mental health technologies. The landscape of medical device regulation for AI-enabled technologies has grown significantly, with approximately 950 FDA approvals in the past decade83. Most of these approvals occur through the 510(k) pathway, which evaluates moderate-risk devices by comparing them to previously approved devices, regardless of whether the predicate device incorporates AI83,84. This regulatory process reflects an opportunity for updates in the regulatory procedures for AI-enabled technologies through modernizing predicates and applying AI-specific safeguards84. In April 2024, MamaLift PlusTM became the first prescription digital therapeutic authorized for the treatment of postpartum depression through the 510(k) pathway85. More of these technologies will be approved in the coming years. It is too soon to tell how perinatal healthcare providers will adopt these technologies, but historically, digital therapeutics have had poor uptake and integration into healthcare systems. Regulatory concerns have been a common barrier to uptake86. The regulatory landscape for AI has varied between states and even more so between countries. The European Union has taken the strongest stance on attempting to regulate the broader AI community, specifically prohibiting AI systems from being developed to manipulate people, taking a risk-based approach to situations requiring regulation, and enacting penalties for companies found to be in noncompliance. Transparency and human oversight are also specifically outlined for healthcare-related applications. In contrast, in the US, the regulatory landscape is evolving through executive action87, as a legal framework such as the EU AI Act88 has yet to be established. It is still too early to tell how these different approaches to regulation will impact the development and innovation of AI applications in healthcare. As we look to the future of the perinatal mental health care cascade, change is needed to address the overwhelming gaps in connecting pregnant people and their families to adequate care. AI-enabled technologies appear to have a place in improving each step in the care cascade if we can address data fairness and quality, data security, and regulatory concerns, allowing for increased trust in these tools to not cause harm. Future research should specifically address these key concerns when developing new tools. Similarly, policy-level changes and investment in data collection quality around perinatal mental health outcomes will help support the development of better tools. No datasets were generated or analysed during the current study. Howard, L. M. & Khalifeh, H. Perinatal mental health: A review of progress and challenges. World Psychiatry 19, 313–327 (2020). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Fawcett, E. J., Fairbrother, N., Cox, M. L., White, I. R. & Fawcett, J. M. The prevalence of anxiety disorders during pregnancy and the postpartum period: A multivariate Bayesian meta-analysis. J. Clin. Psychiatry. 80, https://doi.org/10.4088/JCP.18r12527 (2019). Luca, D. L. et al. Financial toll of untreated perinatal mood and anxiety disorders among 2017 births in the united states. Am. J. Public Health 110, 888–896 (2020). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Fisher, S. D. Paternal mental health: Why is it relevant?. Am. J. Lifestyle Med 11, 200–211 (2016). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Bruzelius, E. & Martins, S. S. US trends in drug overdose mortality among pregnant and postpartum persons, 2017-2020. JAMA 328, 2159–2161 (2022). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Goldman-Mellor, S. & Margerison, C. E. Maternal drug-related death and suicide are leading causes of postpartum death in California. Obstet. Gynecol. 221, 489.e1–489.e9 (2019). \n                    Google Scholar \n                 Kountanis, J. A. et al. Maternal deaths due to suicide and overdose in the state of michigan from 2008 to 2018. Am. J. Obstet. Gynecol. MFM 5, 100811 https://www.sciencedirect.com/science/article/pii/S2589933322002415 (2023). PubMed \n    \n                    Google Scholar \n                 Cox, E. Q., Sowa, N. A., Meltzer-Brody, S. E. & Gaynes, B. N. The perinatal depression treatment cascade: Baby steps toward improving outcomes. J. Clin. Psychiatry 77, 1189–1200 (2016). PubMed \n    \n                    Google Scholar \n                 Miller, M. L., Dupree, J., Monette, M. A., Lau, E. K. & Peipert, A. Health equity and perinatal mental health. Curr. Psychiatry Rep. 26, 460–469 (2024). PubMed \n    \n                    Google Scholar \n                 Stade, E. C. et al. Large language models could change the future of behavioral healthcare: A proposal for responsible development and evaluation. Npj Ment. Health Res 3, 12 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Kay, E. S., Batey, D. S. & Mugavero, M. J. The HIV treatment cascade and care continuum: Updates, goals, and recommendations for the future. AIDS Res Ther. 13, 35 (2016). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Centers for Disease Control. Births and natality. https://www.cdc.gov/nchs/fastats/births.htm. Updated 2024. Accessed Jan 25, (2025). Wisner, K. L. et al. Onset timing, thoughts of self-harm, and diagnoses in postpartum women with screen-positive depression findings. JAMA Psychiatry 70, 490–498 (2013). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Haight, S. C. et al. Racial and ethnic inequities in postpartum depressive symptoms, diagnosis, and care in 7 US jurisdictions. Health Aff. ((Millwood)) 43, 486–495 (2024). PubMed \n    \n                    Google Scholar \n                 American College of Obstetrics and Gynecology Screening and diagnosis of mental health conditions during pregnancy and postpartum: ACOG clinical practice guideline no. 4. Obstet. Gynecol. 141, 1232–1261 (2023). \n                    Google Scholar \n                 American College of Obstetrics and Gynecology. Implementing perinatal mental health screening. https://www.acog.org Web site. https://www.acog.org/programs/perinatal-mental-health/implementing-perinatal-mental-health-screening. Updated 2022. Accessed January 25, 2025. Fairbrother, N., Corbyn, B., Thordarson, D. S., Ma, A. & Surm, D. Screening for perinatal anxiety disorders: Room to grow. J. Affect Disord. 250, 363–370 (2019). PubMed \n    \n                    Google Scholar \n                 Fairbrother, N., Albert, A., Keeney, C., Tchir, D. & Cameron, R. B. Screening for perinatal OCD: A comparison of the DOCS and the EPDS. Assessment 30, 1028–1039 (2023). PubMed \n    \n                    Google Scholar \n                 Philpott, L. F. Paternal perinatal mental health: Progress, challenges and future direction. Trends Urol. Men. Health 14, 14–18 (2023). \n                    Google Scholar \n                 O’Brien, A. P. et al. New fathers’ perinatal depression and anxiety—Treatment options: An integrative review. Am. J. Men.’s. Health 11, 863–876 (2017). \n                    Google Scholar \n                 Fisher, S. D., Walsh, T. & Wongwai, C. The importance of perinatal non-birthing parents’ mental health and involvement for family health. Semin Perinatol. 48, 151950 (2024). PubMed \n    \n                    Google Scholar \n                 Walsh, T. B. & Garfield, C. F. Perinatal mental health: Father inclusion at the local, state, and national levels. Health Aff. ((Millwood)) 43, 590–596 (2024). PubMed \n    \n                    Google Scholar \n                 Kwok, W. H., Zhang, Y. & Wang, G. Artificial intelligence in perinatal mental health research: A scoping review. Comput. Biol. Med. 177, 108685 (2024). PubMed \n    \n                    Google Scholar \n                 Zhang, Y., Wang, S., Hermann, A., Joly, R. & Pathak, J. Development and validation of a machine learning algorithm for predicting the risk of postpartum depression among pregnant women. J. Affect Disord. 279, 1–8 (2021). PubMed \n    \n                    Google Scholar \n                 Amit, G. et al. Estimation of postpartum depression risk from electronic health records using machine learning. BMC Pregnancy Childbirth 21, 630–638 (2021). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Obradovich, N. et al. Opportunities and risks of large language models in psychiatry. NPP Digit Psychiatry Neurosci. 2, 8 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Ayre, K. et al. Developing a natural language processing tool to identify perinatal self-harm in electronic healthcare records. PLoS one 16, e0253809 (2021). CAS \n    PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Shatte, A. B. R., Hutchinson, D. M., Fuller-Tyszkiewicz, M. & Teague, S. J. Social media markers to identify fathers at risk of postpartum depression: A machine learning approach. Cyberpsychol Behav. Soc. Netw. 23, 611–618 (2020). PubMed \n    \n                    Google Scholar \n                 Dhankar, A. & Katz, A. Tracking pregnant women’s mental health through social media: An analysis of reddit posts. JAMIA open 6, ooad094 (2023). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Tierney, A. A. et al. Ambient artificial intelligence scribes to alleviate the burden of clinical documentation. NEJM Catalyst. 5, CAT.23.0404. https://doi.org/10.1056/CAT.23.0404 (2024). Basílio, G. et al. AI-driven early mental health screening with limited data: Analyzing selfies of pregnant women. https://doi.org/10.48550/arXiv.2410.05450 (2024). Hsieh, W. et al. Patients’ perceptions of perinatal depression screening: A qualitative study: Study examines perinatal depression screening. Health Aff. 40, 1612–1617 (2021). \n                    Google Scholar \n                 Hutner, L. A. et al. Cultivating mental health education in obstetrics and gynecology: A call to action. Am. J. Obstet. Gynecol. MFM 3, 100459 (2021). PubMed \n    \n                    Google Scholar \n                 Koire, A., Suleiman, M., Teslyar, P. & Liu, C. H. Prevalence of community perinatal psychiatrists in the US. JAMA Netw. Open 7, e2426465 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Analysis NCfHW. Behavioral health workforce, 2023. https://bhw.hrsa.gov/sites/default/files/bureau-health-workforce/Behavioral-Health-Workforce-Brief-2023.pdf (2023). Branquinho, M. et al. Effectiveness of psychological interventions in the treatment of perinatal depression: A systematic review of systematic reviews and meta-analyses. J. Affect Disord. 291, 294–306 (2021). PubMed \n    \n                    Google Scholar \n                 Meltzer-Brody, S. & Jones, I. Optimizing the treatment of mood disorders in the perinatal period. Dialogues Clin. Neurosci. 17, 207–218 (2015). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Avalos, L. A. et al. Racial-ethnic differences in treatment initiation for new diagnoses of perinatal depression. Psychiatr. Serv. 74, 341–348 (2023). PubMed \n    \n                    Google Scholar \n                 Dembosky, A. No title. A Humane Approach To Caring For New Mothers In Psychiatric Crisis: Article examines inpatient psychiatric care for new mothers in England’s mother and baby care units. (2021). Hutner, L. A., Catapano, L. A., Nagle-Yang, S. M., Williams, K. E. & Osborne, L. M. Textbook of women’s reproductive mental health. American Psychiatric Pub. (2021). Wiley, R. Updates to interventions in treatment of perinatal depression and anxiety. Curr. Obstet. Gynecol. Rep. 13, 1–9 (2024). \n                    Google Scholar \n                 Taouk, L. H., Matteson, K. A., Stark, L. M. & Schulkin, J. Prenatal depression screening and antidepressant prescription: Obstetrician-gynecologists’ practices, opinions, and interpretation of evidence. Arch. Women’s. Ment. Health 21, 85–91 (2018). \n                    Google Scholar \n                 Kittel-Schneider, S., Quednow, B. B., Leutritz, A. L., McNeill, R. V. & Reif, A. Parental ADHD in pregnancy and the postpartum period–A systematic review. Neurosci. Biobehav. Rev. 124, 63–77 (2021). CAS \n    PubMed \n    \n                    Google Scholar \n                 Lewis, A. & Khong, T. K. ADHD medication shortages: More than just a supply issue. Drug Ther. Bull. 62, 18 (2024). PubMed \n    \n                    Google Scholar \n                 McLeish, J., Ayers, S. & McCourt, C. Community-based perinatal mental health peer support: A realist review. BMC Pregnancy Childbirth 23, 570 (2023). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 The Policy Center for Maternal Mental Health. Maternal mental health certified peer support. https://policycentermmh.org/certified-peer-support/. Updated 2024. Accessed January 10, 2025. Quiray, J. et al. The role of doulas in supporting perinatal mental health–a qualitative study. Front. Psychiatry 15, 1272513 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Thomas, M., Ammann, G., Brazier, E., Noyes, P. & Maybank, A. Doula services within a healthy start program: Increasing access for an underserved population. Matern Child Health J. 21, 59–64 (2017). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Yang, S., Lee, J., Sezgin, E., Bridge, J. & Lin, S. Clinical advice by voice assistants on postpartum depression: Cross-sectional investigation using apple siri, amazon alexa, google assistant, and microsoft cortana. JMIR Mhealth Uhealth 9, e24045 (2021). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Sezgin, E., Chekeni, F., Lee, J. & Keim, S. Clinical accuracy of large language models and google search responses to postpartum depression questions: Cross-sectional study. J. Med Internet Res 25, e49240 (2023). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Deutscher, M. Report: Amazon will use anthropic’s claude LLM series to power upcoming alexa upgrade. https://siliconangle.com/2024/08/30/report-amazon-will-use-anthropics-claude-llm-series-power-upcoming-alexa-upgrade/. Updated 2024. Accessed January 10, 2025. Deichen Hansen, M. E. et al. The role of perinatal psychiatry access programs in advancing mental health equity. Gen. Hosp. Psychiatry 82, 75–85 (2023). PubMed \n    \n                    Google Scholar \n                 Mancinelli, E., Magnolini, S., Gabrielli, S. & Salcuni, S. A chatbot (juno) prototype to deploy a behavioral activation intervention to pregnant women: Qualitative evaluation using a multiple case study. JMIR Form. Res 8, e58653 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Suharwardy, S. et al. Feasibility and impact of a mental health chatbot on postpartum mental health: A randomized controlled trial. AJOG Glob. Rep. 3, 100165 (2023). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Soula. Soula: AI-powered women’s wellness companion. https://soula.care. Updated 2024. Accessed January 10, 2025. Waymouth, M., James, K. & Uscher-Pines, L. Advancing equity in maternal health with virtual doula care. JAMA Health Forum 5, e234833 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Logue, T. C. et al. Continuation of psychiatric medications during pregnancy. J. Matern Fetal Neonatal Med 36, 2171288 (2023). PubMed \n    \n                    Google Scholar \n                 Nillni, Y. I., Mehralizade, A., Mayer, L. & Milanovic, S. Treatment of depression, anxiety, and trauma-related disorders during the perinatal period: A systematic review. Clin. Psychol. Rev. 66, 136–148 (2018). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Cuijpers, P. & Karyotaki, E. The effects of psychological treatment of perinatal depression: An overview. Arch. Women’s. Ment. Health 24, 801–806 (2021). \n                    Google Scholar \n                 Spytska, L. The use of artificial intelligence in psychotherapy: Development of intelligent therapeutic systems. BMC Psychol. 13, 175 (2025). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Hurwitz, E. et al. Harnessing consumer wearable digital biomarkers for individualized recognition of postpartum depression using the all of us research program data set: Cross-sectional study. JMIR mHealth uHealth 12, e54622 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Gidén, K. et al. Remission or persistence? A prediction tool to identify women at risk for Long-Term depressive symptoms postpartum. Depress Anxiety 2024, 7734542 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Wong, E. F. et al. Evaluating bias-mitigated predictive models of perinatal mood and anxiety disorders. JAMA Netw. Open 7, e2438152 (2024). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Dlugatch, R., Georgieva, A. & Kerasidou, A. Trustworthy artificial intelligence and ethical design: Public perceptions of trustworthiness of an AI-based decision-support tool in the context of intrapartum care. BMC Med Ethics 24, 42 (2023). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Turchioe, M. R., Hermann, A. & Benda, N. C. Recentering responsible and explainable artificial intelligence research on patients: Implications in perinatal psychiatry. Front Psychiatry 14, 1321265 (2023). PubMed \n    \n                    Google Scholar \n                 Richardson, B. & Gilbert, J. A framework for fairness: A systematic review of existing fair AI solutions. https://doi.org/10.48550/arXiv.2112.05700 (2021). Representative Sharice Davis, Senator Tina Smith, Black Maternal Health Caucus. S.1599 - the momnibus: Data to save moms act. 2023;Senate - Health, Education, Labor, and Pensions (118). Celi, L. A. et al. Sources of bias in artificial intelligence that perpetuate healthcare disparities-A global review. PLOS Digit Health 1, e0000022 (2022). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 Anisuzzaman, D. M., Malins, J. G., Friedman, P. A. & Attia, Z. I. Fine-Tuning Large Language Models for Specialized Use Cases. Mayo Clin. Proc. Digit Health 3, 100184 (2025). CAS \n    PubMed \n    \n                    Google Scholar \n                 Sahiner, B., Chen, W., Samala, R. K. & Petrick, N. Data drift in medical machine learning: Implications and potential remedies. Br. J. Radio. 96, 20220878 (2023). \n                    Google Scholar \n                 Abdul Razak, M. S., Nirmala, C. R., Sreenivasa, B. R., Lahza, H. & Lahza, H. F. M. A survey on detecting healthcare concept drift in AI/ML models from a finance perspective. Front. Artif. Intell. 5, 955314 (2023). \n                    Google Scholar \n                 Uren, V. & Edwards, J. S. Technology readiness and the organizational journey towards AI adoption: An empirical study. Int J. Inf. Manag. 68, 102588 (2023). \n                    Google Scholar \n                 Gomez Rossi, J., Feldberg, B., Krois, J. & Schwendicke, F. Evaluation of the clinical, technical, and financial aspects of cost-effectiveness analysis of artificial intelligence in medicine: Scoping review and framework of analysis. JMIR Med Inf. 10, e33703 (2022). \n                    Google Scholar \n                 Su, C. NVIDIA unveils its most affordable generative AI supercomputer. 2024. https://blogs.nvidia.com/blog/jetson-generative-ai-supercomputer/. Accessed Jan 25, (2025). Sun, L., Jiang, X., Ren, H. & Guo, Y. Edge-cloud computing and artificial intelligence in internet of medical things: Architecture, technology and application. IEEE Access. (2020);PP:1. https://doi.org/10.1109/ACCESS.2020.2997831. Agency E. P. EPA research: Environmental justice and air pollution. 2024;2025. https://www.epa.gov/ej-research/epa-research-environmental-justice-and-air-pollution. Mills, R. J. Patient survey shows unresolved tension over health data privacy. 2022;2025. https://www.ama-assn.org/press-center/press-releases/patient-survey-shows-unresolved-tension-over-health-data-privacy. Habbal, A., Ali, M. K. & Abuzaraida, M. A. Artificial intelligence trust, risk and security management (AI TRiSM): Frameworks, applications, challenges and future research directions. Expert Syst. Appl 240, 122442 https://www.sciencedirect.com/science/article/pii/S0957417423029445 (2024) \n                    Google Scholar \n                 Ugwu, A., Gao, X., Ugwu, J. & Chang, V. Ethical implications of AI in healthcare data: A case study using healthcare data breaches from the US department of health and human services breach portal between 2009-2021. 2022:343–349. Rights (OCR) OfC. Enforcement data. https://www.hhs.gov/hipaa/for-professionals/compliance-enforcement/data/index.html. Updated 2008. Accessed Jan 25, 2025. Ruiz, R. American Psychological Association sounds alarm over certain AI chatbots. 2025; https://mashable.com/article/ai-therapist-chatbots-ftc (2025). Meinke, A. et al. Frontier models are capable of in-context scheming. arXiv preprint arXiv:2412.04984. (2024). Health CfDaR. Artificial intelligence and machine learning (AI/ML)-enabled medical devices. FDA. 2024. https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices. Accessed Jan 25, 2025. Aboy, M., Crespo, C. & Stern, A. Beyond the 510(k): The regulation of novel moderate-risk medical devices, intellectual property considerations, and innovation incentives in the FDA’s de novo pathway. npj Digital Med. 7, 29 (2024). \n                    Google Scholar \n                 The Policy Center for Maternal Mental Health. The first digital therapeutic for maternal mental health is approved by the FDA. The Policy Center for Maternal Mental Health Web site. https://policycentermmh.org/first-digital-therapeutic-for-maternal-mental-health/. Updated 2024. Accessed January 10, 2025. van Kessel, R. et al. Mapping factors that affect the uptake of digital therapeutics within health systems: Scoping review. J. Med Internet Res 25, e48000 (2023). PubMed \n    PubMed Central \n    \n                    Google Scholar \n                 The White House. Removing barriers to American leadership in artificial intelligence. https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence/. Updated 2025. Accessed Jan 25, 2025. Future of Life Institute. EU artificial intelligence act | up-to-date developments and analyses of the EU AI act. https://artificialintelligenceact.eu/. Accessed Jan 25, 2025. Download references The primary author would like to acknowledge that this work was, in part, funded by the National Institutes of Health (NIH) Agreement NO. 1OT2OD032581-01. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the NIH. They would also like to acknowledge the Brody Brothers Foundation Endowment Fund. Brody School of Medicine at East Carolina University, Greenville, NC, USA Karlene Cunningham & Valentina Mărginean College of Allied Health Sciences, East Carolina University, Greenville, NC, USA Ray Hylock Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar K.C. contributed to the manuscript's conceptualization, drafting, figure creation, and revision. V.M. contributed to the writing and edited the manuscript and updated figures. R.H. contributed to the manuscript drafting and revision. All authors reviewed and approved the manuscript. Correspondence to\n                Karlene Cunningham. The authors declare no competing interests. Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions Cunningham, K., Mărginean, V. & Hylock, R. Navigating promise and perils: applying artificial intelligence to the perinatal mental health care cascade.\n                    npj Health Syst. 2, 26 (2025). https://doi.org/10.1038/s44401-025-00030-7 Download citation Received: 25 January 2025 Accepted: 13 June 2025 Published: 23 July 2025 DOI: https://doi.org/10.1038/s44401-025-00030-7 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article.  \n                            Provided by the Springer Nature SharedIt content-sharing initiative\n                         Advertisement \n\n                        npj Health Systems\n                    \n                    (npj Health Syst.)\n                 \nISSN 3005-1959 (online)\n         © 2025 Springer Nature Limited Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily."
  },
  {
    "title": "Charta Health raises $22M for AI healthcare operations platform - Mobi Health News",
    "url": "https://news.google.com/rss/articles/CBMimgFBVV95cUxNcFhNUHJqbHF3TmljTFFxSDhueHF0MmRWX2Q1dGdwZTVwN0RFOUhWbGlDZ0ptb3lUa20yOS1QNTBGdGNSS2VGSWxtVU1RTFA1OFJPelB0Nk8zU010dmxQQ09zSVYwOVdpdVdkOWxkT21qYm8xb3JNWmk0NUUxeldFZi1qTlA5ZFRIb1M5Ui1JQVJBU256SURTSTlB?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Charta Health, an AI-enabled platform that automates billing and coding workflows, has secured $22 million in Series A funding. Bain Capital Ventures led the round, with participation from SV Angel, South Park Commons, Madrona Venture Group and Refract Ventures. WHAT IT DOES The San Francisco-based company's platform utilizes AI to review patient charts before submission, flagging missed codes in an effort to reduce administrative burden and prevent denials before they occur.  The company will use the funds to expand its engineering and go-to-market teams, accelerate product development and speed up enterprise integrations with payers and providers.  \"Historically, the complexity and fragmentation of healthcare infrastructure made it nearly impossible to apply AI meaningfully at scale,\" Justin Liu, cofounder and CEO of Charta Health, said in a statement. \"Today, we can layer advanced AI directly onto any EMR, surfacing patient-level insights: clinical, financial and operational – in real time, and unlocking automation without disrupting workflows or overburdening clinicians.\" MARKET SNAPSHOT Earlier this year, Charta Health raised $8.1 million in seed funding. Charta Health was founded by Liu and Scott Morris, who formerly worked as engineers at Rockset, a company that offered tools for real-time search and data analytics. Rockset was acquired by OpenAI last year.  MobiHealthNews Thank you! Your submission has been received. Add MobiHealthNews to your network. © current_year MobiHealthNews is a publication of HIMSS Media"
  },
  {
    "title": "Agentic AI's greatest potential benefit? Changing how a health system functions - Healthcare IT News",
    "url": "https://news.google.com/rss/articles/CBMisgFBVV95cUxOaFJsU3owZUxacDd5NGZSOTZ2bTVCa3Zkb1R1d3g3VlpvOHRvMHM2VXk3RzJoQm14WS14cEI1VnU0YkdWVHE2Wi1YTzBvVEM2aXpSRlZZWUVjZ0RMSm5PS1VuNXZzRUVMZkdha2x0MmFQWTUxaVFXQ2xBVHFkMTZtaGNjUXE0N3p2T1l6NmdYZnhrU2F5NmRwRDN0YTVwYmxHdGZoUjZ5UWlMeElLSlRMa29B?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "The artificial intelligence applications most people have grown familiar with in recent years usually take the form of assistants: Chatbots answer questions and respond to prompts, but a human instigates each step. An AI agent, on the other hand, can take action on behalf of a user. Models with agency have existed for a few years, but recent advances in natural language processing and memory structure have made them much more powerful. An AI agent can conduct an entire task – starting an action and completing it. An agentic AI system is a network of agents that can work together to complete an entire workflow, not just an individual task. In the healthcare context, this could mean reviewing and processing a complex insurance claim. Using natural language, an agentic AI system can plan, collaborate and connect. For individual AI agents and for systems, people intervene only to take care of problems as they crop up and to ensure oversight. AI agents, in a sense, are virtual co-workers – and very efficient ones. \"There are use cases across the healthcare value chain and from the beginning to end of many individual tasks,\" said Jessica Lamb, a partner in the social, healthcare and public entities practice in the New York office of McKinsey & Company, a research and consulting firm. \"Think of a hospital, for example, that has to order a wide range of supplies, from gowns and gloves to high-end medical equipment. \"AI agents can be deployed to flag when items are running short, source the best supplier, initiate the purchase order and make the payment,\" she explained. \"Agents also can be used to support patients, helping them prepare for upcoming appointments, streamlining discharges and coordinating case management.\" Agentic AI is a good fit for healthcare for several reasons, she added. \"For starters, healthcare already is heavily dependent on information technology, and agentic AI can work with existing software tools and platforms,\" Lamb said. \"That can make the transition somewhat easier. \"Another example is how the healthcare industry continues to rely on many manual processes, based on legacy technology and practices,\" she continued. \"As the examples I used indicate, AI agents can perform a wide range of complex but repetitive tasks that, for a variety of reasons, have not yet been automated.\" And the benefits could be substantial. The American Hospital Association estimates administration accounts for 40% of hospital expenses. For hospitals and health systems looking to deploy agentic AI, getting it right can be challenging. So where is the best place to start? Lamb said, at the beginning, of course. But what is the beginning, according to her? Follow the need. \"Figure out where the highest potential for implementation is, such as the complex processes and workflows that involve a lot of touchpoints and handoffs and that are more manual than they have to be,\" she suggested. \"Once that is done, set actionable goals – agentic AI is not just a shiny new technology, it needs to be results-driven. \"It's important not to get stuck in pilot purgatory – an application in one department, an experiment in another,\" she continued. \"Unfortunately, that is where many organizations are, and it can be difficult to escape. The better approach is to pick a whole domain or work area, rather than a specific task.\" The greatest benefit of agentic AI comes when it is scaled and changes how an organization functions, not when it is used simply to cut costs here and there, Lamb believes. \"Think of it this way: A use case is generating an appeal letter – a domain change is reimagining revenue cycle management,\" she said. Finally, embed change management from the beginning – if agentic AI is implemented well, it will transform the way the whole organization functions, and the way people work, she added. \"It's important to remember the human element,\" she said. \"Agentic AI is not just about tech. It is – or should be – about improving the job experience, creating higher-value work and democratizing technology in a way that fosters human connection.\" Managing risks and ensuring governance certainly are essential for building trust in agentic AI systems. Hospitals and health systems implementing the technology must plan carefully. \"For ethical, security and management reasons, trust is essential,\" Lamb stated. \"And that means organizations need to take the principles of responsible AI to heart. Here is something that may not be well known: Investing in trust pays off. As my colleague Roger Roberts recently put it, 'When implemented well, responsible AI leads to real ROI.' The reason is simple: Without trust in agentic AI, people will not use it. \"It is up to people to define the parameters of agentic AI autonomy,\" she continued. \"That means structuring the workflow of each agent so it is deliberate about what it can and cannot do.\" Another concern, bolstered by well-publicized instances of AI glitches, is the possibility of biases in inputs and outputs. That requires ensuring data accuracy and security. \"Keeping humans in the loop is a critical safeguard,\" Lamb advised. \"From the start, people need to be at the center of agentic AI development. That means education, in the form of a clear communications strategy that informs everyone about how and why the organization is planning to use agentic AI. To ease concerns about the possibilities of job losses, there also should be a clear strategy to re-skill existing employees. \"A transformation of this breadth and depth is a general responsibility,\" she continued. \"Good governance therefore requires mechanisms to report problems and cross-functional collaboration to ensure all perspectives are included.\" The principle is simple: Just do it – but do it thoughtfully, she added. So, what does the future of agentic AI look like in healthcare? What is next for hospitals and health systems? Lamb puts it simply. \"The future of agentic AI is readily expressed: There will be more and more of it,\" she predicted. \"Older, manual and slow systems are on their way out – and that is a good thing. The use of AI agents will ease some of healthcare's most annoying pain points while allowing people to focus on more interesting and novel work. \"The process will not be straightforward,\" she cautioned. \"Some hospitals and health systems will be faster and defter than others. But the trend is clear: Agentic AI is the future.\" Follow Bill's HIT coverage on LinkedIn: Bill SiwickiEmail him: bsiwicki@himss.orgHealthcare IT News is a HIMSS Media publication. WATCH NOW: Helpful tips on smart rooms from OhioHealth Newsletter Signup Thank you! Your submission has been received. © current_year Healthcare IT News is a publication of HIMSS Media"
  },
  {
    "title": "From Diagnosis to Surgery: How AI Tech Is Quietly Reshaping Healthcare Profits - PR Newswire",
    "url": "https://news.google.com/rss/articles/CBMizgFBVV95cUxNUUtKRjVlRmN0SDBFY0JoZ3l6WTJtSVo2OWxCV2Q3OGhxYjVyTUU1dTJGRkFwbk9zWjVsVzU5MmljYXY2TXpBaGtyYzJOM3o0SjI1X0tIMFZfTkxpZXR5OUx3Zy1pNERCRVBWQkpqM1JoajcwN0RjaGtLXzNzYWphemd5LW9VTjhOcy1RUlYySV9yMXVqUmEzakd1OVA5bVBDQXlCbHo5MkpFR0NBcmpBcHlRNXJwWEluRi1mRTJOVEhaaVU0VHhlcUlJYWw0dw?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Searching for your content... \n                        In-Language News\n                     \nContact Us\n \n 888-776-0942\n\nfrom 8 AM - 10 PM ET\n Jul 22, 2025, 09:15 ET Share this article USA News Group News CommentaryIssued on behalf of Avant Technologies Inc. VANCOUVER, BC, July 22, 2025 /PRNewswire/ -- USA News Group News Commentary – The AI revolution in healthcare is fully underway, with the potential to save lives and money, but there's still more to come. Healthcare startups are already figuring out how to implement AI to multiply their patients, and chase profits, to the benefit of investors. More Americans than ever are utilizing AI to diagnose their health issues, as the adoption of AI tools is becoming the norm among medical professionals. Now the developers of these game-changing technologies are overcoming regulatory barriers and moving closer to implementation of their solutions in the real world. Among the players that are moving closer to major milestones include Avant Technologies, Inc. (OTCQB: AVAI), Agenus Inc. (NASDAQ: AGEN), Clover Health Investments, Corp. (NASDAQ: CLOV), Zimmer Biomet Holdings, Inc. (NYSE: ZBH), and Monogram Technologies Inc. (NASDAQ: MGRM). Currently, the AI in healthcare sector projected to surpass $110 billion by 2030. However, according to Accenture, artificial intelligence could unlock an additional $461 billion in value across healthcare by 2035—on top of a sector already projected to surpass $2.26 trillion. Avant Technologies, Inc. (OTCQB: AVAI) and joint-venture partner Ainnova Tech are continuing to raise visibility for their AI-powered diagnostic platform, with Ainnova CEO Vinicio Vargas recently featured as a speaker at Roche's \"Macular Spectacular\" Ophthalmology Conference in Cartagena, Colombia. The event brought together leading voices in visual health from across Latin America, with discussions focused on advancing patient outcomes through AI innovation. Vargas, who also sits on the board of Ai-nova Acquisition Corp. (AAC), presented Vision AI as a transformative tool to expand access to early diabetic retinopathy screening and reduce preventable blindness throughout the region. Vargas also highlighted a Q4 2024 alliance with Roche and prepaid‑health‑plan provider Salud 360 that is piloting Vision AI among high‑risk diabetic patients; if successful, the program will be rolled out in the United States, Canada, and Europe through Ai‑nova Acquisition Corp. (AAC), which holds worldwide rights to Ainnova's technology portfolio . This momentum builds on a recent regulatory breakthrough in the U.S. market. Avant and Ainnova recently completed a key pre-submission meeting with the FDA for Vision AI, the companies' flagship diagnostic platform for diabetic retinopathy and other retinal diseases. \"We're truly excited about this next phase,\" said Vinicio Vargas, CEO at Ainnova and a member of the Board of Directors of Ai-nova Acquisition Corp. (AAC), the company formed by the partnership between Avant and Ainnova to advance and commercialize Ainnova's technology portfolio. \"We're getting ready to begin data collection across primary care clinics in the U.S. with a study that is simple, yet rigorous—comparing our AI-based retinal screening to the readings of three retinologists. The July 15 meeting marked a critical step toward securing 510(k) clearance for Vision AI. The FDA session offered clear feedback on study design, site selection, and execution strategy—enabling Ainnova and its clinical trial partner, Fortrea, to finalize preparations for U.S.-based trials. \"This milestone not only brings us closer to validating our platform in the world's largest healthcare market, but it also paves the way for the upcoming approval of our new automated retinal camera,\" added Vargas. \"We believe will [it] be a game changer—making diabetic retinal screenings faster, more accessible, and available from virtually any point of care.\" While regulatory efforts advance in the U.S., the company has already launched a groundbreaking chronic care model across Latin America. The program, now live through Grupo Dökka's Fischel and La Bomba pharmacy chains, offers free, walk-in retinal risk assessments—delivering real-time AI results and connecting at-risk patients directly with clinics and specialists. Over 30% of diabetics develop diabetic retinopathy, a leading cause of preventable blindness. Vision AI offers early, low-cost screening without the need for an ophthalmologist onsite. The model has gained support from pharmacies, insurers, and pharmaceutical partners—demonstrating real traction across the healthcare value chain. Avant's role in these efforts continues to grow. Through Ai-nova Acquisition Corp., which it co-founded and structured, Avant maintains global licensing rights to Ainnova's platform and stands to benefit from both U.S. and international commercialization. The Latin American pilot programs are already generating momentum, with U.S. trials positioned to unlock a vastly larger market. The company is also preparing a standalone venture to house a potential therapeutic candidate for diabetes—bringing leadership, data, and IP into one streamlined structure for diagnostics and treatment alike. Looking ahead, Vision AI could serve as a frontline tool for broader disease detection. Ainnova's future roadmap includes a cloud-connected retinal camera for rural clinics and new modules aimed at identifying Alzheimer's, cardiovascular conditions, and other chronic diseases through retinal or blood biomarkers. A structural simplification may be on the horizon as well. A previously announced non-binding LOI remains active for Avant to acquire 100% of Ainnova Tech—potentially consolidating all IP, leadership, and commercial rights under one public entity. Such a move would give investors pure-play exposure to this fast-evolving tech stack, while deepening operational alignment between the firms. CONTINUED… Read this and more news for Avant Technologies Inc. https://usanewsgroup.com/2023/10/26/unlocking-the-trillion-dollar-ai-market-what-investors-need-to-know/  Agenus Inc. (NASDAQ: AGEN) has partnered with AI biotech firm Noetik to develop predictive biomarkers for its cancer immunotherapy combo BOT/BAL. \"At Agenus, we are committed to transforming cancer care through scientific innovation and next-generation immunotherapies,\" said Dr. Garo Armen, Chairman and CEO of Agenus. \"This collaboration with Noetik enables us to harness cutting-edge AI to better understand patient biology and tailor treatments more precisely.\" By using Noetik's advanced \"virtual cell\" models trained on massive tumor datasets, the collaboration aims to identify which patients are most likely to benefit from treatment. This could improve clinical trial outcomes and accelerate personalized cancer care using AI-driven insights Clover Health Investments, Corp. (NASDAQ: CLOV) recently launched a new pharmacy pilot program across New Jersey in partnership with IPC's iCare+ network. The initiative enables local pharmacies to use AI tools and real-time data to help seniors manage medications and reduce hospital visits. \"This is more than a new program—it's a new model for how we support our New Jersey members,\" said Jamie Reynoso, CEO of Medicare Advantage at Clover Health. \"By working with the pharmacists who are already embedded in our communities, we can deliver better care, deliver amazing customer experiences and support the independent businesses that keep New Jersey strong.\" It's part of Clover's strategy to deliver more personal, community-based healthcare while supporting independent pharmacies Zimmer Biomet Holdings, Inc. (NYSE: ZBH) has entered a definitive agreement to acquire Monogram Technologies Inc. (NASDAQ: MGRM) for approximately US$177 million in cash, with additional milestone-based payments up to US$12.37 per share. \"Monogram's technology is a major leap forward, demonstrating our commitment to becoming the boldest and broadest innovator in surgical robotics and navigation,\" said Ivan Tornos, Chairman, President and CEO of Zimmer Biomet. \"Upon closing, our customer-centric portfolio will consist of the most comprehensive and flexible technology ecosystem to support the varying preferences of a vast array of surgeons – now and into the future. With Monogram's proprietary technology, Zimmer Biomet has the potential to become the first company to deliver fully autonomous capabilities and redefine both the standard of care and the future of orthopedic surgery.\" The acquisition adds Monogram's semi- and fully autonomous orthopedic robotics to Zimmer Biomet's ROSA® platform, aiming to create the most comprehensive robotics suite in the orthopedic space. Monogram's FDA-cleared knee arthroplasty robot is expected to commercialize in 2027, with a fully autonomous version in development. \"Since our inception, we have been singularly focused on advancing orthopedic robotics with technology designed to safely, efficiently and accurately support surgeons with total knee arthroplasty,\" said Benjamin Sexson, CEO of Monogram. \"We are thrilled by the opportunity to add our technology to Zimmer Biomet's leading portfolio of surgical robotics, navigation solutions and trusted implants and to benefit from their deep industry expertise and global scale.\" Zimmer Biomet expects the deal to be accretive by 2028, supporting long-term growth in the high-demand surgical robotics market. Source: https://usanewsgroup.com/2023/10/26/unlocking-the-trillion-dollar-ai-market-what-investors-need-to-know/  CONTACT:USA NEWS GROUPinfo@usanewsgroup.com(604) 265-2873 DISCLAIMER: Nothing in this publication should be considered as personalized financial advice. We are not licensed under securities laws to address your particular financial situation. No communication by our employees to you should be deemed as personalized financial advice. Please consult a licensed financial advisor before making any investment decision. This is a paid advertisement and is neither an offer nor recommendation to buy or sell any security. We hold no investment licenses and are thus neither licensed nor qualified to provide investment advice. The content in this report or email is not provided to any individual with a view toward their individual circumstances. USA News Group is a wholly-owned subsidiary of Market IQ Media Group, Inc. (\"MIQ\"). MIQ has been paid a fee for Avant Technologies Inc. advertising and digital media from the company directly. There may be 3rd parties who may have shares Avant Technologies Inc., and may liquidate their shares which could have a negative effect on the price of the stock. This compensation constitutes a conflict of interest as to our ability to remain objective in our communication regarding the profiled company. Because of this conflict, individuals are strongly encouraged to not use this publication as the basis for any investment decision. The owner/operator of MIQ own shares of Avant Technologies Inc. which were purchased in the open market. MIQ reserves the right to buy and sell, and will buy and sell shares of Avant Technologies Inc. at any time thereafter without any further notice. We also expect further compensation as an ongoing digital media effort to increase visibility for the company, no further notice will be given, but let this disclaimer serve as notice that all material disseminated by MIQ has been approved by the above mentioned company; this is a paid advertisement, and we own shares of the mentioned company that we will sell, and we also reserve the right to buy shares of the company in the open market, or through other investment vehicles. While all information is believed to be reliable, it is not guaranteed by us to be accurate. Individuals should assume that all information contained in our newsletter is not trustworthy unless verified by their own independent research. Also, because events and circumstances frequently do not occur as expected, there will likely be differences between any predictions and actual results. Always consult a licensed investment professional before making any investment decision. Be extremely careful, investing in securities carries a high degree of risk; you may likely lose some or all of the investment. Logo - https://mma.prnewswire.com/media/2603685/5425599/USA_News_Group_Logo.jpg SOURCE USA News Group USA News Group News Commentary – Within the last week, silver crossed the $39 barrier, hitting its highest level since 2011. Now analysts are... USA News Group News Commentary – After a brief rise, gold's price leveled off as the market responded to US President Donald Trump shooting down... Health Care & Hospitals Medical Pharmaceuticals Artificial Intelligence Medical Equipment Do not sell or share my personal information:"
  },
  {
    "title": "How AI is transforming medicine - Harvard Gazette",
    "url": "https://news.google.com/rss/articles/CBMilAFBVV95cUxOaktibzQxczJqMUlKOWxpQTUwNjJhclQzdE8wYTN5dWZFbVNPTElCcFFKeTdQcFhyR3pwZEptalU5Tzg4Rnd4S1N0UkVNQzIydjNGUGRlbG11YzhYWW1Gam5JeF9JVno5MEJaMFRUSE1MYTFYVVJmYUdyT3FGaTY3MWFpUUNRZlJFRTd1UFlXRDByazlE?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "A series of random questions answered by Harvard experts. Photo illustrations by Judy Blomquist/Harvard Staff \n\t\tAlvin Powell\t \n\t\t\tHarvard Staff Writer\t\t When Adam Rodman was a second-year medical student in the 2000s, he visited the library for a patient whose illness had left doctors stumped. Rodman searched the catalog, copied research papers, and shared them with the team. “It made a big difference in that patient’s care,” Rodman said. “Everyone said, ‘This is so great. This is evidence-based medicine.’ But it took two hours. I can do that today in 15 seconds.” Rodman, now an assistant professor at Harvard Medical School and a doctor at Beth Israel Deaconess Medical Center, these days carries a medical library in his pocket — a smartphone app created after the release of the large language model ChatGPT in 2022. OpenEvidence — developed in part by Medical School faculty — allows him to query specific diseases and symptoms. It searches the medical literature, drafts a summary of findings, and lists the most important sources for further reading, providing answers while Rodman is still face-to-face with his patient. “We say, ‘Wow, the technology is really powerful.’ But what do we do with it to actually change things?” Artificial intelligence in various forms has been used in medicine for decades — but not like this. Experts predict that the adoption of large language models will reshape medicine. Some compare the potential impact with the decoding of the human genome, even the rise of the internet. The impact is expected to show up in doctor-patient interactions, physicians’ paperwork load, hospital and physician practice administration, medical research, and medical education. Most of these effects are likely to be positive, increasing efficiency, reducing mistakes, easing the nationwide crunch in primary care, bringing data to bear more fully on decision-making, reducing administrative burdens, and creating space for longer, deeper person-to-person interactions. Adam Rodman, assistant professor at Harvard Medical School and physician at Beth Israel Deaconess Medical Center ADAM RODMAN: I am obsessed with metacognition, with thinking about thinking. So what excites me most about AI and medicine? Well, the optimist in me hopes that AI and medicine can make us doctors better versions of ourselves to better care for our patients. I think the best case scenario for me is a world in which an artificial intelligence is communicating with me and my patients, looking for signs of implicit bias, looking for signs that I might be making the wrong decision, and more importantly, feeding back that information to me so that I can improve over time, so that I can become a better human. My worry is actually directly related to this. These are very powerful reasoning technologies, and really what is medical education other than a way to frame and shape the medical mind? So part of my worry is that because these technologies are so powerful, they’ll shortcut many of the ways that we know that doctors learn and get better, and we may end up with generations of physicians who don’t know how to think the best. I don’t think that this is the foregone conclusion, but it really is my worry about the way that things are going. But there are serious concerns, too. Current data sets too often reflect societal biases that reinforce gaps in access and quality of care for disadvantaged groups. Without correction, these data have the potential to cement existing biases into ever-more-powerful AI that will increasingly influence how healthcare operates. Another important issue, experts say, is that AIs remain prone to “hallucination,” making up “facts” and presenting them as if they are real. Then there’s the danger that medicine won’t be bold enough. The latest AI has the potential to remake healthcare top to bottom, but only if given a chance. The wrong priorities — too much deference to entrenched interests, a focus on money instead of health — could easily reduce the AI “revolution” to an underwhelming exercise in tinkering around the edges. “I think we’re in this weird space,” Rodman said. “We say, ‘Wow, the technology is really powerful.’ But what do we do with it to actually change things? My worry, as both a clinician and a researcher, is that if we don’t think big, if we don’t try to rethink how we’ve organized medicine, things might not change that much.” Five years ago, when asked about AI in healthcare, Isaac Kohane responded with frustration. Teenagers tapping away on social media apps were better equipped than many doctors. The situation today couldn’t be more different, he says. Kohane, chair of the Medical School’s Department of Biomedical Informatics and editor-in-chief of the New England Journal of Medicine’s new AI initiative, describes the abilities of the latest models as “mind boggling.” To illustrate the point, he recalled getting an early look at OpenAI’s GPT-4. He tested it with a complex case — a child born with ambiguous genitalia — that might have stymied even an experienced endocrinologist. Kohane asked GPT-4 about genetic causes, biochemical pathways, next steps in the workup, even what to tell the child’s parents. It aced the test. “This large language model was not trained to be a doctor; it’s just trained to predict the next word,” Kohane said. “It could speak as coherently about wine pairings with a vegetarian menu as diagnose a complex patient. It was truly a quantum leap from anything that anybody in computer science who was honest with themselves would have predicted in the next 10 years.”  Isaac Kohane, chairman of Harvard Medical School’s Department of Biomedical Informatics and editor-in-chief of the New England Journal of Medicine’s new AI journal ISAAC KOHANE: I am most excited that AI is going to transform the patient experience. Just merely having an instant second opinion after any interaction with a clinician will change to the better the nature of the doctor-patient relationship. Also, with regard to what things I fear could go wrong, it’s that parties that do not have the patient’s best interest will be the ones steering the tendencies/biases or prejudices of our new AI companions. And none too soon. The U.S. healthcare system, long criticized as costly, inefficient, and inordinately focused on treatment over prevention, has been showing cracks. Kohane, recalling a faculty member new to the department who couldn’t find a primary care physician, is tired of seeing them up close. “The medical system, which I have long said is broken, is broken in extremely obvious ways in Boston,” he said. “People worry about equity problems with AI. I’m here to say we have a huge equity problem today. Unless you’re well connected and are willing to pay literally thousands of extra dollars for concierge care, you’re going to have trouble finding a timely primary care visit.” Early worries that AI would replace physicians have yielded to the realization that the system needs both AI and its human workforce, Kohane said. Teaming nurse practitioners and physician assistants with AI is one among several promising scenarios. “It is no longer a conversation about, ‘Will AI replace doctors,’ so much as, ‘Will AI, with a set of clinicians who may not look like the clinicians that we’re used to, firm up the tottering edifice that is organized medicine?’”  How LLMs were rolled out — to everyone at once — accelerated their adoption, Kohane says. Doctors immediately experimented with eye-glazing yet essential tasks, like writing prior authorization requests to insurers explaining the necessity of specific, usually expensive, treatments. “People just did it,” Kohane said. “Doctors were tweeting back and forth about all the time they were saving.” Patients did it too, seeking virtual second opinions, like the child whose recurring pain was misdiagnosed by 17 doctors over three years. In the widely publicized case, the boy’s mother entered his medical notes into ChatGPT, which suggested a condition no doctor had mentioned: tethered cord syndrome, in which the spinal cord binds inside of the backbone. When the patient moves, rather than sliding smoothly, the spinal cord stretches, causing pain. The diagnosis was confirmed by a neurosurgeon, who then corrected the anatomic anomaly. One of the perceived benefits of employing AI in the clinic, of course, is to make doctors better the first time around. Greater, faster access to case histories, suggested diagnoses, and other data is expected to improve physician performance. But plenty of work remains, a recent study shows. Research published in JAMA Network Open in October compared diagnoses delivered by an individual doctor, a doctor using an LLM diagnostic tool, and an LLM alone. The results were surprising, showing an insignificant improvement in accuracy for the physicians using the LLM — 76 percent versus 74 percent for the solitary physician. More surprisingly, the LLM by itself did best, scoring 16 percentage points higher than physicians alone. Rodman, one of the paper’s senior authors, said it’s tempting to conclude that LLMs aren’t that helpful for doctors, but he insisted that it’s important to look deeper at the findings. Only 10 percent of the physicians, he said, were experienced LLM users before the study — which took place in 2023— and the rest received only basic training. Consequently, when Rodman later looked at the transcripts, most used the LLMs for basic fact retrieval. “The best way a doctor could use it now is for a second opinion, to second-guess themselves when they have a tricky case,” he said. “How could I be wrong? What am I missing? What other questions should I ask? Those are the ways, we know from psychological literature, that complement how humans think.” Among the other potential benefits of AI is the chance to make medicine safer, according to David Bates, co-director of the Center for Artificial Intelligence and Bioinformatics Learning Systems at Mass General Brigham. A recent study by Bates and colleagues showed that as many as one in four visits to Massachusetts hospitals results in some kind of patient harm. Many of those incidents trace back to adverse drug events. “AI should be able to look for medication-related issues and identify them much more accurately than we’re able to do right now,” said Bates, who is also a professor of medicine at the Medical School and of health policy and management at the Harvard T.H. Chan School of Public Health.  David Bates, co-director of the Center for Artificial Intelligence and Bioinformatics Learning Systems at Mass General Brigham DAVID BATES: AI has a great deal of promise. Burnout is rampant in many parts of medicine, especially, for example, primary care, and artificial intelligence will make many routine tasks like documentation much faster. Ambient scribes in particular are already doing that. There are also concerns about things going wrong. There are many ways that any time gains could be used, for example, just to increase physician workloads. It’s also very important that medical records be correct, and AI has a tendency to hallucinate, and that is a worry, because we don’t want things in people’s records that are not really there. Another opportunity stems from AI’s growing competence in a mundane area: notetaking and summarization, according to Bernard Chang, dean for medical education at the Medical School. Systems for “ambient documentation” will soon be able to listen in on patient visits, record everything that is said and done, and generate an organized clinical note in real time. When symptoms are discussed, the AI can suggest diagnoses and courses of treatment. Later, the physician can review the summary for accuracy. Automation of notes and summaries would benefit healthcare workers in more than one way, Chang said. It would ease doctors’ paperwork load, often cited as a cause of burnout, and it would reset the doctor-patient relationship. One of patients’ biggest complaints about office visits is the physician sitting at the computer, asking questions and recording the answers. Freed from the note-taking process, doctors could sit face-to-face with patients, opening a path to stronger connections.   “It’s not the most magical use of AI,” Chang said. “We’ve all seen AI do something and said, ‘Wow, that’s amazing.’ This is not one of those things. But this program is being piloted at different ambulatory practices across the country and the early results are very promising. Physicians who feel overburdened and burnt out are starting to say, ‘You know what, this tool is going to help me.’”  Bernard Chang, Harvard Medical School Dean for Medical Education BERNARD CHANG: What most excites me about AI’s promise in medicine is that these technological tools will allow physicians to spend more time on the human aspects of the profession, which is sorely needed, while facilitating the ability to access information quickly, analyze large amounts of important data, and make the difficult connections necessary to consider the rare diagnoses, the less obvious treatment paradigms, and ultimately the optimal care for patients. In medical education, students can use AI tools to accelerate their learning and move more quickly beyond rote practice to higher levels of cognitive analysis on their way to becoming the most outstanding doctors of the future. Whether things might go long lies in our hands. We need to be cautious about hallucinations and misinformation, bias, an erosion of fundamentals in learning, and an over-reliance on machines. As a society, we need to be mindful of the environmental impacts of the high energy costs involved. On the whole, I see AI as a transformative tool on par with the availability of the internet in terms of its effect on medicine and medical education. For all their power, LLMs are not ready to be left alone. “The technology is not good enough to have that safety level where you don’t need a knowledgeable human,” Rodman said. “I can understand where it might have gone aground. I can take a step further with the diagnosis. I can do that because I learned the hard way. In residency you make a ton of mistakes, but you learn from those mistakes. Our current system is incredibly suboptimal but it does train your brain. When people in medical school interact with things that can automate those processes — even if they’re, on average, better than humans — how are they going to learn?” Doctors and scientists also worry about bad information. Pervasive data bias stems from biomedicine’s roots in wealthy Western nations whose science was shaped by white men studying white men, says Leo Celi, an associate professor of medicine and a physician in the Division of Pulmonary, Critical Care and Sleep Medicine at Beth Israel Deaconess Medical Center. Leo Celi, associate professor of medicine and a physician in Beth Israel Deaconess Medical Center’s Division of Pulmonary, Critical Care and Sleep Medicine LEO CELI: AI could be the Trojan horse we’ve been waiting for to redesign systems from a clean slate. I am talking about systems for knowledge creation, health care delivery, and eduction, which are all quite broken. The legacy of AI is to make us better critical thinkers, by putting data at the front and center, and making the breadth and the depth of the problems crystal clear. But we need to design human AI systems, rather than build algorithms. We have to be able to predict how humans will mess up. The designs should be similar those of systems for aviation, road safety, space, nuclear power generation. We need psychologists, cognitive scientists, behavioral economists, anthropologists to design human AI systems.”  “You need to understand the data before you can build artificial intelligence,” Celi said. “That gives us a new perspective of the design flaws of legacy systems for healthcare delivery, legacy systems for medical education. It becomes clear that the status quo is so bad — we knew it was bad and we’ve come to accept that it is a broken system — that all the promises of AI are going bust unless we recode the world itself.” Celi cited research on disparities in care between English-speaking and non-English speaking patients hospitalized with diabetes. Non-English speakers are woken up less frequently for blood sugar checks, raising the likelihood that changes will be missed. That impact is hidden, however, because the data isn’t obviously biased, only incomplete, even though it still contributes to a disparity in care. “They have one or two blood-sugar checks compared to 10 if you speak English well,” he said. “If you average it, the computers don’t see that this is a data imbalance. There’s so much missing context that experts may not be aware of what we call ‘data artifacts.’ This arises from a social patterning of the data generation process.” Bates offered additional examples, including a skin cancer device that does a poor job detecting cancer on highly pigmented skin and a scheduling algorithm that wrongly predicted Black patients would have higher no-show rates, leading to overbooking and longer wait times. “Most clinicians are not aware that every medical device that we have is, to a certain degree, biased,” Celi said. “They don’t work well across all groups because we prototype them and we optimize them on, typically, college-age, white, male students. They were not optimized for an ICU patient who is 80 years old and has all these comorbidities, so why is there an expectation that the numbers they represent are objective ground truths?” The exposure of deep biases in legacy systems presents an opportunity to get things right, Celi said. Accordingly, more researchers are pushing to ensure that clinical trials enroll diverse populations from geographically diverse locations. One example is Beth Israel’s MIMIC database, which reflects the hospital’s diverse patient population. The tool, overseen by Celi, offers investigators de-identified electronic medical records — notes, images, test results — in an open-source format. It has been used in 10,000 studies by researchers all around the world and is set to expand to 14 additional hospitals, he said. As in the clinic, AI models used in the lab aren’t perfect, but they are opening pathways that hold promise to greatly accelerate scientific progress. “They provide instant insights at the atomic scale for some molecules that are still not accessible experimentally or that would take a tremendous amount of time and effort to generate,” said Marinka Zitnik, an associate professor of biomedical informatics at the Medical School. “These models provide in-silico predictions that are accurate, that scientists can then build upon and leverage in their scientific work. That, to me, just hints at this incredible moment that we are in.” ”What is becoming increasingly important is to develop reliable, faithful benchmarks or techniques that allow us to evaluate how well the outputs of AI models behave in the real world.”  Zitnik’s lab recently introduced Procyon, an AI model aimed at closing knowledge gaps around protein structures and their biological roles. Until recently, it has been difficult for scientists to understand a protein’s shape — how the long molecules fold and twist onto themselves in three dimensions. This is important because the twists and turns expose portions of the molecule and hide others, making those sites easier or harder for other molecules to interact with, which affects the molecule’s chemical properties. Marinka Zitnik, assistant professor of biomedical informatics MARINKA ZITNIK: I am most excited about AI’s ability to learn and innovate on its own, instead of just analyzing existing knowledge. AI can generate new ideas, uncover hidden patterns, and propose solutions that humans might not consider. In biomedical research and drug development, this means AI could design new molecules, predict how these molecules interact with biological systems, and match treatments to patients with greater accuracy. By integrating information across genetics, proteins, all the way to clinical outcomes, AI can speed up discoveries in ways that was previously not possible. A major challenge, however, is that AI models tend to focus on problems that have already been extensively studied, while other important areas receive less attention. If we are not careful, medical advances may become concentrated in familiar areas, while other conditions remain under-explored, not because they are less important, but because there is less existing knowledge to guide AI systems. Another issue is that AI-driven drug design and treatment recommendations often rely on experimental findings generated in research labs that might not fully capture the complexity of real patients. Insights from research labs don’t always translate into effective treatments, and AI could amplify this gap if it’s not designed to bridge it. The opportunity is to build AI that makes discoveries and ensure that those discoveries lead to meaningful advances, bringing innovation to areas where it’s needed most. Today, predicting a protein’s shape — down to nearly every atom — from its known sequence of amino acids is feasible, Zitnik said. The major challenge is linking those structures to their functions and phenotypes across various biological settings and diseases. About 20 percent of human proteins have poorly defined functions, and an overwhelming share of research — 95 percent — is devoted to just 5,000 well-studied proteins. “We are addressing this gap by connecting molecular sequences and structures with functional annotations to predict protein phenotypes, helping move the field closer to being able to in-silico predict functions for each protein,” Zitnik said. A long-term goal for AI in the lab is the development of “AI scientists” that function as research assistants, with access to the entire body of scientific literature, the ability to integrate that knowledge with experimental results, and the capacity to suggest next steps. These systems could evolve into true collaborators, Zitnik said, noting that some models have already generated simple hypotheses. Her lab used Procyon, for example, to identify domains in the maltase glucoamylase protein that bind miglitol, a drug used to treat Type 2 diabetes. In another project, the team showed that Procyon could functionally annotate poorly characterized proteins implicated in Parkinson’s disease. The tool’s broad range of capabilities is possible because it was trained on massive experimental data sets and the entire scientific literature, resources far exceeding what humans can read and analyze, Zitnik said. The classroom comes before the lab, and the AI dynamic of flexibility, innovation, and constant learning is also being applied to education. The Medical School has introduced a course dealing with AI in healthcare; added a Ph.D. track on AI in medicine; is planning a “tutor bot” to provide supplemental material beyond lectures; and is developing a virtual patient on which students can practice before their first nerve-wracking encounter with the real thing. Meanwhile, Rodman is leading a steering group on the use of generative AI in medical education. These initiatives are a good start, he said. Still, the rapid evolution of AI technology makes it difficult to prepare students for careers that will span 30 years. “The Harvard view, which is my view as well, is that we can give people the basics, but we just have to encourage agility and prepare people for a future that changes rapidly,” Rodman said. “Probably the best thing we can do is prepare people to expect the unexpected.” \n\t\t\t\t\t\tNew study finds link between sleep curfew, higher levels of moderate-to-vigorous physical activity\t\t\t\t\t \n\t\t\t\t\t\tResearchers rush to get hands around multiple serious health risks as blazes mount — and get bigger \t\t\t\t\t \n\t\t\t\t\t\tThe recent development of cancer immunotherapies marks a turning point in the centuries-old quest to fight cancer by harnessing the power of patients’ own immune systems.\t\t\t\t\t \n\t\t\t\t\t\tParent emerged over 4,000 years ago in Siberia, farther east than many thought, then rapidly spread west\t\t\t\t\t \n\t\t\t\t\t\t\t6 min read\t\t\t\t\t\t \n\t\t\t\t\t\tExperiment with synthetic self-assembling materials suggests how it all might have begun\t\t\t\t\t \n\t\t\t\t\t\t\t6 min read\t\t\t\t\t\t \n\t\t\t\t\t\tNew study finds link between sleep curfew, higher levels of moderate-to-vigorous physical activity\t\t\t\t\t \n\t\t\t\t\t\t\t6 min read\t\t\t\t\t\t A series of random questions answered by Harvard experts. A series focused on the personal side of Harvard research and teaching."
  },
  {
    "title": "How Can Rural Healthcare Organizations Benefit From AI? - HealthTech Magazine",
    "url": "https://news.google.com/rss/articles/CBMinAFBVV95cUxPSS1uWFZEQ1E1bG1PTWFqWWpYWXRfS0JmOC1rUWxHRnZESmxBTDhyWHROMWVLSGZreEFTMENYcDNtY1k0WE9ieEV0dFZYLThjdlhYMmtYOWJwYVVIb1JEelVYbzc0Vmc1Wi1fUVlGQVpESXVvYk9JNExLd2hoN292UXY5MklWeGdSQW9teG4wUGdGTlM2VnZGZTMzaUM?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "These health IT influencers are change-makers, innovators and compassionate leaders who use technology to make a difference in provider experiences and patient outcomes. See how IT leaders are tackling AI opportunities and challenges. \n Brian Eastwood is a freelance writer with more than 15 years of experience covering healthcare IT, healthcare delivery, enterprise IT, consumer technology, IT leadership and higher education.  Across the industry, health systems are laying the foundation for artificial intelligence success, ensuring they have the infrastructure, governance and technical expertise to make the most of the technology. Organizations that get this right are well positioned to increase efficiency, enhance care quality and take advantage of predictive models. For rural, independent and community health systems, the conversation about AI is a bit more nuanced. Though the benefits are there, unique challenges exist as well. As a 2025 paper from researchers at Texas State University notes, there are practical obstacles (such as the limitations of technology infrastructure and the cost of upgrading it) as well as “hypothesized barriers” (including beliefs that AI offers little benefit to the practice of medicine and that its use will hurt a health system’s reputation in the community). With that in mind, rural health systems would be best served to focus on use cases that are both accessible and acceptable to providers, patients and policymakers, says Mei Wa Kwong, executive director of the Center for Connected Health Policy. “AI can be beneficial on the administrative end, where there are tasks that otherwise need a lot of resources,” she says. “Where there are tools to help humans work more efficiently or effectively, people see that as a good use of AI.” Click the banner below to read the new CDW Artificial Intelligence Research Report.   National Rural Health Association CEO Alan Morgan says three common use cases for AI come up in his conversations with hospitals and health systems. The first is deploying ambient AI to document patient appointments. This can help practitioners pay more attention to patients’ needs while alleviating the burden of note taking. “It’s amazing how much time this is freeing up,” Morgan says. “I think this is potentially the greatest benefit we may see coming from AI.” Using AI to take notes improves the patient experience, Kwong explains, as practitioners no longer focus exclusively on their computer keyboard. Beyond the appointment, AI models can assess a patient’s records and flag issues worth a follow-up. For example, if a patient mentions in many visits that they’re having difficulty falling asleep, an AI model trained to detect patterns may flag that issue and prompt the health system to follow up. “AI can help identify patterns that a doctor may not see at first, or that they may initially think is an offhand comment,” Kwong says. This scenario tends to come with little resistance, as it provides additional information to providers without explicitly telling them what to do. The second is AI-based second opinions, which can help to reduce diagnostic errors. While hallucinations in AI models and biases in training data sets remain issues, the potential to access consultations in a matter of seconds has a clear benefit, Morgan notes. This is especially true in rural settings, where specialists may be hundreds of miles away or unavailable outside of normal business hours. RELATED: Here are 13 ways AI enhances healthcare operations, patient care and treatments. The third is streamlining billing and coding — a use case critical for the survival of rural organizations. Roughly one-third of rural hospitals are at risk of closure due to financial problems that stem from the cost of care delivery, the limitations of federal assistance and low financial reserves, according to a report from the Center for Healthcare Quality and Payment Reform. Morgan adds that rural hospital leaders see AI in the revenue cycle as a response to insurers’ use of AI to assess claims — a practice facing class-action lawsuits. In a podcast with the Rural Health Information Hub, Jordan Berg, director of the National Telehealth Technology Assessment Resource Center indicates applying AI to the revenue cycle is more than a matter of automating routine tasks. With the right AI tools, he says, organizations can ensure services are billed at the appropriate level, notify vendors and patients when bills are due, and identify opportunities for further revenue cycle optimization, “all with very minimal input from users and stakeholders.” Additional use cases for AI in rural settings include optimizing workflows in the electronic health record (EHR), augmenting diagnosis and decision support, deploying mobile clinics with practitioners supported by AI agents, and improving scheduling and follow-up messaging. These examples work well because they don’t cause much friction. “Patients are fine with getting an automated appointment reminder call,” Kwong says. “For organizations that have limited resources, a tool like that can be a good investment.” READ MORE: Revolutionize prior authorizations with AI. One wrinkle for rural, independent and community health systems looking for guidance on where and how to best use AI is the lack of direction from Capitol Hill. Recent regulations have closely defined the implementation of EHR systems, the acceptable use cases for telehealth, and the standards and infrastructure necessary to exchange health information, among other things. Meanwhile, no such framework exists for AI in healthcare. Morgan says this isn’t surprising; given the typical long on-ramp for technology adoption in healthcare, policy moves at a slow pace. Right now, he adds, “it seems very hands-off.” The Trump Administration’s proposed spending bill includes a 10-year pause on state or local AI laws in lieu of overarching federal regulation with few compliance hurdles. “It’s a very volatile time, and policymakers are still feeling their way around that,” Kwong says. Even without the guardrails of federal policy — or a body of empirical research into how rural healthcare organizations are using AI — adoption appears to be taking off, Morgan says. “I’ve seen a lot of fads,” such as rolling out robots in hospitals, “but AI has such amazing potential, and we’re basically talking about utilization picking up in just the last year.” Security \nAcross Healthcare, Collaboration Is a Critical Ingredient of Data Security\n\n Security \nData Risk Management Best Practices for Healthcare\n\n Visit Some Of Our Other Technology Websites: Tap into practical IT advice from CDW experts Copyright © 2025 CDW LLC 200 N. Milwaukee Avenue, Vernon Hills, IL 60061Do Not Sell My Personal Information\n These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information. These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly. These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant ads on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising. These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance."
  },
  {
    "title": "Can AI finally crack the code to cost-effective healthcare? - WIRED",
    "url": "https://news.google.com/rss/articles/CBMilAFBVV95cUxPLUlYMFhfbmUtUmR4X1o0amdvbnU1UmpaRERvMmVmcEdGa0tSRTlHb0NDVFotdnJkdjJqTWxYM2MzekRMakN1OW9YcHMxeHd6dHhmYXlXelhUN2FQOHpqTnRnMzZLVVQtWnlpYWplX0oxRUt5eFhTRUNsU2JfUlhqeFNfWnpYcDdyOERoYU9MX1cwNzd1?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Currently, only residents from certain countries and US states can opt out of certain Tracking Technologies through our Consent Management Platform. Additional options regarding these technologies may be available on your device, browser, or through industry options like AdChoices. Please see our Privacy Policy for more information. Global healthcare systems face challenges today that impose an enormous burden. It’s a familiar litany of problems: Populations are aging; chronic diseases are rising; and as we know from recent history, infectious diseases can still have a devastating impact around the globe. All this piles incredible pressure onto nurses and doctors, with healthcare systems struggling to cope given the widespread shortage of trained staff. Add to this that healthcare costs are rising, and it’s little wonder that countries around the globe are finding it tough to deliver the quality healthcare that the public demands. Policy makers know that the solution will involve the smart application of artificial intelligence (AI). It has a proven ability to improve diagnostic accuracy and enable the early detection of disease, while treatment plans for patients can be personalized and administrative tasks streamlined. AI can be used to improve diagnosis and treatment of people that have felt overlooked in the past, including women—who make up most of the population. Educational institutions that teach medicine are looking at how AI can be integrated into the training of future nurses and doctors. The potential of AI to deliver impactful solutions and improved patient care is therefore recognized, but can it be the cost solution for healthcare systems? Philips, which for many years has been at the forefront of developing medical products and services in areas including diagnostic imaging, ultrasound, and image-guided therapy has been exploring the use of AI to address these challenges. As Shez Partovi, Chief Innovation & Strategy Officer at Philips explains: “With aging populations and longer waiting times for patients, we need to develop credible solutions. Philips has been harnessing AI to increase scan detection rates, lower the burden on staff, and improve diagnosis. Key to the future success of health systems is delivering value and creating partnerships for change.” Philips has identified the potential for AI to make cost effective changes both on the clinical and operational side of healthcare systems. Examples include streamlining workflows and operations, providing clinical insights, expanding access to patient care, and supporting personalized healthcare. The result enables clinicians to see more patients, diagnose disease earlier, and deliver higher quality of care. This leads to patients recovering faster and spending less time in hospital, making treatment cheaper, and lowering the cost of healthcare per patient. Yet AI on its own is not enough—Philips believes that the key lies in combining AI with the very human skills and experience that one will find in hospitals and clinics: “The aim is to create solutions that integrate into the workflows of healthcare providers and people’s daily health routines. Something must be done or we risk being the first generation facing a healthcare system worse than previous generations.” Another advantage we are seeing with the AI solutions that Philips can deliver is the ability to provide quality care from hospitals into homes, increasing access to vital care in a range of settings. This includes the ability to detect different types of heart issues early on, putting care in the hands of patients whilst clinicians can monitor issues and manage diagnoses more effectively. “In our view, AI is about supporting healthcare providers in their daily decision making, improving operational efficiency so there can be more focus on patient care, and empowering the public to take more care of their own health and wellbeing.” AI makes it so much easier for healthcare professionals to access large sets of data, enabling quicker assessment and more personalized treatment. This results in follow-up actions that have more impact, enhancing the quality of care a patient is getting, and a better outcome for that patient. Healthcare leaders are turning to virtual care and AI-enabled innovation to address pressures in the sector such as workforce shortages, financial constraints, and growing demand. By using AI, they have turned an overload of information into meaningful insights that allow care providers to provide better care to more people. Going forward, Philips is helping to build the strategic partnerships that will enable AI to be rolled out in such a way that healthcare systems can truly deliver to patients, while preventing burnout among staff. The company is also fostering a culture among healthcare stakeholders where the benefits of AI are fully understood and the will to implement grows ever stronger. The genie is out of the bottle. Artificial Intelligence is poised to change health systems in countries around the world for the better by delivering cost effective solutions. But it needs buy-in and commitment from all healthcare stakeholders. They are invited to work with Philips to create a healthcare system fit for purpose in the 21st century. More From WIRED Reviews and Guides © 2025 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices"
  },
  {
    "title": "The Amazing Ways AI Agents Will Transform Healthcare - Forbes",
    "url": "https://news.google.com/rss/articles/CBMiqAFBVV95cUxQeTAybmNiTXl2UVpNMDdDR05oU0hwNUZhR2pablhsRUttZXRqR3dWMEY5X2lSYTFFWWtNdzRuSlM2UzJWZzY2TjV1RmFXYzdITlJ4R01vdjliM1hhc0tGRHhsOUJtbkF3SlVZcm5YSnloM0ljeFhEcUtqN1JWTHRmVTNuUGwtazNveW5jcUk2MzA3ZVdyZW9HVXdWTEpnYTFpaXhkTkFOX3g?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "ByBernard Marr  ByBernard Marr,  Contributor.  AI agents represent the next transformational wave in healthcare, moving beyond simple diagnosis ... More tools to autonomous systems that can schedule appointments, create detailed medical reports, and monitor patients remotely without human intervention. Healthcare is already a hotbed of AI activity, which has more than proved its worth as a tool for diagnosing illness, monitoring recovery, and developing new medicines. But globally, the industry is still grappling with longstanding challenges, including shortages of clinical staff, aging populations, and managing the front-loaded costs of transitioning to more preventative models of healthcare. This is where AI agents, the next wave of AI transformation, will come in. Compared to existing AI (think of the current generation of language-based chatbots like ChatGPT), agentic AI is capable of carrying out far more complex tasks with minimal human interaction. To give a simple example, a non-agentic computer vision-based AI algorithm can be used to scan medical images and spot early warning signs of cancer. An agentic AI, on the other hand, could cross-reference the images with other clinical patient data, create a detailed report for a doctor and schedule a follow-up appointment, all without human involvement. This switch from passive provider of information to active action-taking is what defines the newest generation of tools and applications driven by agentic AI. Experts predict it will soon be just as transformational to healthcare as today’s cutting-edge computer vision, chatbots and other AI innovations have proven to be. So here’s an overview of how it may soon be put to work in hospitals, doctors’ surgeries and care homes near you. There are several use cases for agentic applications in healthcare. Although most are currently theoretical, they give us an idea of how agents could surpass the capability of non-agentic tools and apps. Automated triage and scheduling systems could relieve clinical and administrative staff of much of the burden of routine procedures and paperwork. Rather than simply asking patients to answer questions, it can use computer vision to carry out initial examinations and flag urgent cases for immediate help. The Prompt: Get the week’s biggest AI news on the buzziest companies and boldest breakthroughs, in your inbox.  You’re Subscribed! You’re Subscribed! AI agents have also been built to assist with clinical decision-making. By augmenting large language models like GPT-4 with tools to understand MRI, CT and other medical data, one test found an agent could reach a correct diagnosis in 91% of cases. They will also become increasingly useful in remote patient monitoring. Their ability to make more accurate decisions about when to intervene and how to protect patient privacy and security will mean more people can stay out of hospitals and be treated at home. Agents are even being put to use in clinical trials, carrying out tasks such as screening applications, matching candidates to trials and booking transportation to the test facility. For non-clinical use, the AI health monitors we use on smartwatches and fitness bands will become much smarter and more proactive. Rather than simply measuring heart rate, skin temperature and so on, they’ll be ready to give us a holistic overview of our health at any time and then monitor the action we take towards improving it. Finally, agents will help complete administrative tasks more efficiently by automating decisions around scheduling, reading and replying to emails, and handling billing and commissioning. While this can be done by existing AI on a task-by-task basis, agents will take oversight of entire workflows or even business functions, reducing human error and time spent on routine work. A great deal of academic research is currently taking place into how we can safely use and understand the impact of agentic AI in healthcare. Answering these questions will play a bit part in helping these use cases get off the ground. With greater autonomy and the ability to interact with external systems, AI agents clearly introduce new risks that could be particularly dangerous in healthcare ecosystems. Data security is an obvious one, and new security measures will be required to balance the need for agents to access personal data with the dangers this creates. Confidential patient information, as well as control over critical systems, could be at stake if agents are compromised by malicious individuals or groups or just don’t work like they’re supposed to. Agents will also force healthcare service providers to answer questions and provide assurances about accountability. AI can’t take responsibility for its actions, so how is it shared between the healthcare industry, AI developers, and the clinical staff and patients who use it? Then there’s the simple fact that AI is often wrong. Whether it’s down to bad data or hallucination, it simply isn’t right 100 percent of the time. Of course, neither are humans. So when is it right to hand over the reins? And, of course, we're far from the point where anyone thinks it’s right to let machines make decisions that affect humans without human oversight. So, how do we make sure that oversight is in place, effective and accountable? Overcoming all of these challenges will be critical to safely integrating agentic AI into the healthcare system and unlocking the benefits it promises. By the end of the decade, we can expect agentic AI to have radically changed the way healthcare is delivered, managed and experienced. Globally, healthcare has for some time understood the importance of moving from reactive to preventative care. Agents will proactively interact with wearables and home sensors to enable far earlier interventions when warning signs are detected. This will happen within an agentic ecosystem, which delivers fully personalized care by fine-tuning treatment in response to patient data. Meanwhile, the workload of clinical professionals will involve far less time spent filling in forms or reviewing notes and more time using their uniquely human skills and experience to improve patient outcomes. Access to healthcare in underserved areas could increase, with agents acting as gateways to telemedicine services, triaging initial contacts as well as freeing up human doctors to see more patients. Of course, all of this depends on solving the challenges mentioned here. Once society understands the impact agents can have, there will be a demand for evidence that it can be trusted. By establishing where the boundaries lie as we build, test and use it today, we can lay the groundwork for a safe, agentic tomorrow. One Community. Many Voices. Create a free account to share your thoughts.   • The latest must-know headlines; • Essential trends in enterprise tech, AI and digital transformation; • Tips on how to be a strong leader.  \n\t\t\t\tBy signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement.\n MEMBERSHIP OFFER 59.99"
  },
  {
    "title": "AI could be used to determine who meets new Medicaid work requirements. CHAI is convening a tiger team to assist - Fierce Healthcare",
    "url": "https://news.google.com/rss/articles/CBMiygFBVV95cUxOamZxMUo0a0JkSFZjYndUREVmTWdoQ2gzTGZjdmt0U3dhemduWWdVa0QtVzFJVzZTclRBYzE4S0c2ZnpDbld6dXM3V1VDaHJ1dWpmcUwteUVtY3ViVl9WMkEwWWhHY0NQc1FoWXJuQ0s5SGxmWGVORWRRQUowZGtkT2h3TE5aejNOUVgyeWQzZkV3TnVWbHpSQVpLRXlvUEhadTY4bDc0eXJMdGdGZG5Eb1NMd2FydFE5cXJocVRRZ0ptams2bWxCVmxB?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data. You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page. \nCloudflare Ray ID: 96463f8aa9374508\n•\n\n      Your IP:\n      Click to reveal\n34.23.160.127\n•\n\nPerformance & security by Cloudflare"
  },
  {
    "title": "GE HealthCare again tops FDA AI device list - AuntMinnie",
    "url": "https://news.google.com/rss/articles/CBMi2gFBVV95cUxPbW50LWZZTHZfMElVbFJhV0h5dmNlWTJqUkQ4c3pnYTkxNXh3RGNybGo2eGwyNml1S2ZuM25iMFJHZk9oUlZSWTlvd2xyQmNqOEhfT2lyRWNzMWIxR3ViaHFEMEVMWkFia3ZqRzZYMkw2ZFUwZXRPcXpLNXd4Q1VfNlNsOXJfbHRweTMwb3g2UHd3YXJ3R0RsQUV4akF2QzJIYkpWbHBZb1IwcVcwbVZHQl9HVENGRkFjTGRvTmdjbHFTTWFXamZET2RRSmFsRms0OHY3cU54d3JoQQ?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "GE HealthCare said that it has topped the U.S. Food and Drug Administration (FDA)'s list of AI-enabled medical device authorizations for the fourth year in a row, with 100 listed. Devices listed include AI-based Auto Positioning for CT and PET/CT scanners, AIR Recon DL for MR image reconstruction, the LOGIQ Series for ultrasound, and Precision DL for enhancing image quality in PET/CT scans, GE HealthCare said. The milestone advances GE HealthCare’s goal of attaining more than 200 authorizations by 2028, the company noted.  Post a Comment  You must be signed in to leave a comment. To sign in or create an account, enter your email address and we'll send you a one-click sign-in link."
  },
  {
    "title": "[Webinar] AI Governance in Healthcare: How Compliance Teams Can Manage Risk and Stay Ahead - JD Supra",
    "url": "https://news.google.com/rss/articles/CBMiigFBVV95cUxOLVpWWXhEYk5vZkQ1dzJfaHk0Sm9ROFhiVlE1Y2RkYzFrdGJDQkRNT0FzUHoyV29NbWJPY05tUkxudEg5dlZEUTVpY3kzYTdxMUo1RXU0cXYtRkx2ZUNWdld1RXA1d3ZUdFF4Nk9ETEN3LUxtbFM2czNJU2MzZXVScXJZNjJTd2tOUGc?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "As AI adoption accelerates in healthcare, compliance, privacy, and risk teams are under pressure to adapt. Join experts from NAVEX and Granite GRC to learn how a proactive AI governance strategy can help you stay compliant, mitigate operational risk, and protect patient safety. Why AI Governance Can’t Be an Afterthought in Healthcare As AI continues to shape everything from diagnostics to care delivery, the associated risks, including data privacy, bias, and compliance blind spots, are growing just as fast. Without oversight, even beneficial tools can introduce reputational, regulatory, and safety consequences. Join this timely conversation to learn how risk and compliance teams can lead secure AI adoption by embedding oversight into broader GRC strategies. What you’ll learn: Who should attend? This webinar is ideal for: Sound like you? Meet the speakers:  Senior Director and the Healthcare Vertical Leader NAVEX  Director-in-Charge Granite GRC Consulting  Director, Compliance & Privacy Services Granite GRC Consulting See more » © \n                    NAVEX \n                    2025 \n                 Refine your interests » Back to Top Explore 2025 Readers' Choice Awards Copyright © 2025  JD Supra, LLC"
  },
  {
    "title": "Sam Altman warns AI disrupting jobs, healthcare, youth habits - The New Indian Express",
    "url": "https://news.google.com/rss/articles/CBMisAFBVV95cUxNczIwbmVJY1VpSkkxYVBXS1ZSS1U0R08wc2NUbmxtSGxpMUN4TlV1WHAzT1N6d2FfQ3pTS1lfbnNJUUpLQnpUSE9xY1V1SEdmOXdsZVc4aGxUaUdLNmwyYXo1MjRPTDdvU0N5ZU9sX213dEI1clpiaUo4c3UxVHZvcFB5SWFoMTZvM2pGanFDTzAtaVh6NDNsOVZHR1RHVHFhdDlOVjRjSXI4YkFJWTg3aNIBvgFBVV95cUxPbkRXaXZISGs5azgzSk01ZmN3dTczMVpEMXE0b1VTMGpMMEZTTEF6a3pyQ2JoTk1wSHpBVW9QLWFPSGRQSHh0OTUzazRyZHE3VmM5b3ByWlFzYkYwaEVUYjJUVGRTeFlfMXNQQjRkUkR2aXNUcVlwVjZaNWVwQjE2V2xhXzFnUHV6dlRuZHZxUVkzYV9XY2hTVzhlaHpzTk5JeFd0ejdvOTBYQ1NHdVh3TkpEZE1HNUtXaWhwbnFR?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Advertisement OpenAI CEO Sam Altman has raised fresh alarms over the rapid impact of artificial intelligence (AI) on society. Speaking at the Federal Reserve’s ‘Capital Framework for Large Banks’ conference in Washington DC, Altman said AI is already reshaping critical sectors like employment, healthcare, and cybersecurity—and also influencing how young people make life decisions. AI is already replacing jobs Altman said that AI has moved beyond just supporting human workers—it is now replacing entire categories of jobs. One striking example he gave was in customer support, where AI tools are handling queries more efficiently than human agents. “Customer support jobs are not changing—they’re already gone in many companies,” Altman said.  He emphasised that while AI will create new kinds of work, the transition won’t be easy. Millions of workers will need retraining, and not all new jobs will appear quickly enough. He warned that policymakers must urgently develop strategies to support workers displaced by automation.  AI diagnoses better than doctors Altman shared that AI has become extremely effective in medical diagnosis, even outperforming most doctors in identifying diseases from data. But he quickly added that healthcare decisions should never be left entirely to machines. “These systems are great at pattern recognition, but they don’t have empathy or judgment,” he said. “We still need doctors and nurses to care for people, explain risks, and make moral decisions.” He stressed the importance of combining AI tools with human oversight in hospitals and clinics. Without proper safeguards, relying only on machines could lead to dangerous medical outcomes. Deepfakes will break bank security One of Altman’s most urgent warnings was about AI-powered fraud. He explained that deepfake technology—used to create fake voices, videos, and identities—is advancing so fast that it is defeating current security systems. “Voice-based authentication? Already broken,” he said. “It’s crazy we still use it.”   Altman warned that scammers can now use just a few seconds of someone’s voice to mimic them perfectly. He urged banks to stop relying on voice-print security and switch to more advanced, layered methods. “If we don’t upgrade our security systems, we’ll see a flood of financial fraud in the next 12 to 24 months,” he said. Young people emotionally dependent on ChatGPT Altman also spoke about a surprising trend: many young users are turning to AI, especially tools like ChatGPT, for emotional guidance and decision-making. While he acknowledged that AI can be helpful, he said over-reliance is “bad and dangerous”. “We’ve seen young people asking AI what to do in relationships, life choices, even how to feel,” he said. “That’s not healthy.” He encouraged parents, teachers and communities to guide children in using AI responsibly. Instead of replacing human connections, AI should support human learning and curiosity. Follow The New Indian Express channel on WhatsApp  Download the TNIE app to stay with us and follow the latest  Advertisement Advertisement Advertisement Copyright - newindianexpress.com 2024. All rights reserved."
  },
  {
    "title": "'You'd Have to Be Very Skilled to Have A Job': AI Godfather Geoffrey Hinton Predicts Healthcare Will Survive AI Disruption - Yahoo Finance",
    "url": "https://news.google.com/rss/articles/CBMiekFVX3lxTE5WYV96U2ZqOVB6UXJRYTFkd01jSVZiMDdheXVHY1ZPR2NwaXhrWXREWFNfM2lEdjN6LWZYaXB6STNzX1dER2RsdS1BUFMwZW1kTXVGYUFSZGxLLUJMaHFmRi10UG9Hd0w4aTJWaG1iRjNRRjhHWUVMMXJn?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Oops, something went wrong Oops, something went wrong Trump clashes with Powell over Fed renovations during unusual visit, says he'd 'love' lower interest rates The S&P 500 notched its 4th straight record close, as Google's strong earnings provided a tech boost. The Dow fell over 300 points. It sounds like Trump now has a new minimum tariff rate: 15% Trump is set to make a highly unusual presidential visit to the Fed building. It's another pressure point in his campaign against Powell. The S&P 500 and Nasdaq rose as Google's strong earnings and AI spending spree boosted hopes for tech The summer of 2025 is quickly turning into the latest meme stock moment. Here's how we got here. A judge blocked a rule to drop medical debt from credit reports. What now? Elon Musks warns 'rough quarters' could be ahead on earnings call as EV tax credit expires Tesla shares tick up despite earnings miss as EV maker touts 'more affordable' model Google shares fall despite earnings beat as rising capex spending spooks investors The S&P 500 and Nasdaq clinched records, and the Dow hit its highest point since December, as trade hopes boosted stocks Trump unveiled a plan that aims for US dominance in AI, breaking from Biden-era curbs on exports and misinformation use Home sales fell more than expected in June as prices reached a record high, the latest sign the market remains in a deep freeze. Dow pops, S&P 500 eyes record on US-Japan deal hopes, with Tesla and Google on deck Trump said he is 'never going to let the dollar slide.' His agenda is making that complicated. Tesla reports earnings Wednesday with Musk and Trump's rocky relationship under the spotlight. Here's what to expect. Trump announces trade deal with Japan including 15% tariff Circle stock has surged 500% since its IPO in June, but another analyst just slapped it with a Sell rating. Here's why. Upstart crypto and old-school banking are starting to speak the same language The S&P 500 eked out a fresh record as Wall Street digested a rush of earnings and trade developments Last week, Trump touted 'REAL cane sugar' Coke. Coca-Cola just confirmed it's really happening for the US market. Kohl's stock soared Tuesday, as the beat-down retailer joined Opendoor in the latest retail meme craze Stocks pulled back slightly from record highs at the open. GM stock sank after it revealed a $1.1 billion hit from Trump's tariffs. Scott Bessent said he doesn't think Powell needs to step down now — even as he called for a broad review of the Fed Trump Media's stock tests the limits of bitcoin accumulation as a strategy Ethereum has surged over 60% in the past month — and more companies are buying in AI and momentum trades are getting too crowded, JPMorgan warns. Here's where analysts are turning next. Trump tax law to add $3.4 trillion to US deficits and strip healthcare from millions, CBO says (Bloomberg) The S&P 500 closed above 6,300 for the first time, and the Nasdaq notched yet another record The meme-stock-like rally continued Monday, with retail activity in the stock surging The company announced it had hit $2 billion in bitcoin-related holdings as part of its plan to become a crypto treasury company Dow, S&P 500, Nasdaq edge up with Big Tech earnings, trade policy in focus Trump's antitrust cops are OK with new mergers. Old tech monopolies, not so much. Kraft Heinz, WK Kellogg, and PepsiCo are among the big food brands facing uncertainty about the way forward. Average savings by generation: How do boomers, Gen X, millennials, and Gen Z compare? More men are returning to the office. Here's why that matters for women. Lutnick says he is confident US will secure trade deal with EU (Reuters) 'Earnings misses are going to get punished more than usual': Wall Street raises the stakes as stocks hit records Everyone wants to be a bank now. Banks aren’t happy about it. Tesla and Alphabet join this week's earnings rush as the market hovers near record highs. Here's what to know. Connecticut wants to make generic GLP-1s. It needs RFK Jr.'s help. Lower-cost communities like Columbus, Ga. and Tulsa are trying to coax remote workers to ditch high cost-of-living areas. How to get TSA PreCheck for free with a credit card Coffee prices are soaring. Tariffs could drive them even higher. Robinhood's rise to all-time high, driven by crypto and AI hype, matches what brought major indexes to record levels The stock nearly tripled this week amid a retail investor buying spree. Here's what's fueling the hype. AI mania is worse than 1999's tech bubble, Apollo's top economist warns Fed's Goolsbee defends Powell amid Trump's attacks Nasdaq hits record, S&P 500 posts weekly gain, and Dow slips as Wall Street shrugs off tariff tensions Trump signs stablecoin bill into law, capping string of 'Crypto Week' victories \"You'd have to be very skilled to have a job,\" said AI godfather Geoffrey Hinton, warning that automation could erase much of today's intellectual labor. As generative AI floods workplaces, Hinton's comments highlight growing uncertainty about the future of work. Speaking on \"The Diary of a CEO\" podcast, Hinton argued that automation will swallow \"mundane intellectual labor\" yet spare medicine, where demand seems bottomless. The bold claim invites a pressing question: Can health care outrun algorithms while other sectors shrink? Hinton's forecast follows a grim pattern. Anthropic CEO Dario Amodei told Axios in May that AI could erase \"roughly half\" of entry‑level white‑collar roles within one to five years, warning unemployment could spike to 10% to 20%. Don't Miss: Be part of the breakthrough that could replace plastic as we know it—invest in Timeplast before the July 31st deadline and help revolutionize a $1.3T industry. $100k+ in investable assets? Match with a fiduciary advisor for free to learn how you can maximize your retirement and save on taxes – no cost, no obligation. Jensen Huang, CEO of Nvidia (NASDAQ: NVDA), pushed back. Huang told Axios last week that AI will \"create vastly more and superior jobs,\" comparing the shift to past industrial leaps. Even inside boardrooms, consensus proves elusive. Salesforce (NYSE: CRM) CEO Marc Benioff, told Business Insider at the AI for Good Global Summit in Geneva in July that customers are \"not saying, ‘I'm laying off employees because of AI advancements.' He cast the technology as a productivity booster, not a job killer Goldman Sachs (NYSE:GS) research from 2023 forecasts that generative AI could eventually automate up to 50% of tasks and boost global output by nearly $7 trillion. Hinton told Steven Bartlett, host of “The Diary of a CEO” podcast, that clinical work is \"much more elastic\" because patients always want more treatment when costs falls. He estimated that making doctors five times more efficient would yield five times more care, not layoffs. Trending: This AI-Powered Trading Platform Has 5,000+ Users, 27 Pending Patents, and a $43.97M Valuation — You Can Become an Investor for Just $500.25 Data align with this view. A 2024 McKinsey report predicted automation could replace up to 30% of U.S. jobs by 2030 and projected net hiring growth in health care, clean energy, and STEM fields. The consultancy pointed to tasks that remain difficult to automate, such as sterilizing surgical tools and assisting with in-home care. \"I think there’s something about the human empathy aspect of that and the care and so on, that’s particularly humanistic,\" Google DeepMind CEO Demis Hassabis told Wired in an interview when asked whether hospitals will adopt robot nurses. Investors appear convinced. Health‑tech startups attracted $6.4 billion in the first half of the year, up7% from 2024, according to Rock Health. See Also: Are you rich? Here’s what Americans think you need to be considered wealthy. Recent labor figures reinforce the trend. Bureau of Labor Statistics data show health‑care payrolls grew by 39,000 in June, extending a 16‑month hiring streak even as overall job creation slowed. Usage patterns reveal a disconnect between employees and leadership. According to the report \"Superagency in the Workplace: Empowering People to Unlock AI's Full Potential,\" released in January by McKinsey, 12% of employees use generative AI for at least 30% of their daily work—more than triple what executives estimate. The report urges organizations to scale training and adoption efforts to fully unlock AI's potential in the workplace. Read Next: Can you guess how many retire with a $5,000,000 nest egg? The percentage may shock you. Image: Shutterstock Up Next: Transform your trading with Benzinga Edge's one-of-a-kind market trade ideas and tools. Click now to access unique insights that can set you ahead in today's competitive market. Get the latest stock analysis from Benzinga? This article 'You'd Have to Be Very Skilled to Have A Job': AI Godfather Geoffrey Hinton Predicts Healthcare Will Survive AI Disruption originally appeared on Benzinga.com © 2025 Benzinga.com. Benzinga does not provide investment advice. All rights reserved. Sign in to access your portfolio"
  },
  {
    "title": "GE Healthcare Tops FDA List of AI Authorizations - Imaging Technology News",
    "url": "https://news.google.com/rss/articles/CBMihgFBVV95cUxPU0hmakpydEtLcm5wTnp4UGpxTUw0NU9xM3V0THdhZzFZV1M5TWNxUFc3RXhxRE5UZTZ3Mm1IRGQwMlo5WUNjUEh4SGdlMW9RSGU5WVVXRjE2ZHFmT3FZVEJ3RlZlVGJrWjh5cjh1QThGSGhjUnpUQUxvdFVXMkZQaU03NV9iUQ?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Increased R&D investments to integrate AI on devices to boost productivity, efficiency and diagnostic confidence for healthcare professionals, and drive company’s long-term growth. This is the fourth year in a row GE Healthcare has topped the list and now has 100 listed authorizations to date in the U.S. July 22, 2025 — GE HealthCare has topped a U.S. Food and Drug Administration (FDA) list of AI-enabled medical device authorizations for the fourth year in a row with 100 listed authorizations to date in the U.S. This milestone reflects GE HealthCare’s continued research and development investment and focus on developing AI solutions to advance precision care by enhancing medical devices across the care journey. Smart devices, software and cloud-based solutions, which are central to GE HealthCare’s precision care strategy, help enhance outcomes for patients, improve the daily work of care teams and boost healthcare professional efficiency.  “Our sustained leadership in AI-enabled medical devices reflects our commitment to research and development, which is powering the creation of next-generation solutions. These solutions are designed to address the toughest challenges our customers are facing including care team shortages and burnout, rising costs, and inefficient workflows,” said Dr. Taha Kass-Hout, GE HealthCare’s Global Chief Science and Technology Officer. “As we continue to drive the industry forward, we remain committed to doing so in a responsible way, building in our Responsible AI principles at every stage of our product development which include a focus on safety, validity, transparency, explainability, and fairness.” The FDA’s webpage, Artificial Intelligence-Enabled Medical Devices, provides a list of device authorizations, granted through 510(k) clearances, De Novo requests or by premarket approval (PMA). GE HealthCare’s 100 authorizations to date demonstrate innovation across imaging modalities and care pathways including oncology, cardiology, and neurology, helping to ease the burden of care and improve workflows for healthcare systems. Examples of GE HealthCare’s AI solutions include: “We’re accelerating the pace of innovation to meet the urgency of today’s healthcare challenges. Reaching this milestone is also an important step along our journey of evolving from an imaging company to a healthcare solutions provider, enabling us to deliver holistic and integrated solutions that meet our customers’ needs today and will help enable them to stay ahead in a rapidly evolving healthcare environment,” said Kass-Hout. GE HealthCare is pushing the boundaries of innovation by fostering new ways to use AI, cloud, and software to move the future of healthcare forward in a responsible way, across the care journey, and at the hospital system level. These projects and innovations run the gamut from early R&D to commercially available solutions, often the result of working closely with leading medical institutions, universities, and technology companies to bring in the best thinking from industry, technology, and academia. Regardless of a project’s maturity, GE HealthCare combines deep healthcare expertise, a commitment to responsible innovation, and pioneering spirit to help customers address pressing global challenges from aging populations, chronic disease management, remote care, and more. For more information about GE Healthcare’s AI-enabled medical device and enterprise software solutions, visit www.GEHealthCare.com.   1 “AI-based Auto Positioning,” February 2021, www.gehealthcare.com/-/jssmedia/gehc/us/images/products/revolution-ascend/files/ai-auto-positioning-white-paper.pdf?srsltid=AfmBOooIyJqujqRZlX8hYx20aPDSwn7oGMbtiGzvym3nGEMd_TqqtpFy. 2 AIR™ Recon DL, https://www.gehealthcare.ca/en-ca/products/magnetic-resonance-imaging/air-recon-dl. 3 Calculated using IB data with an estimation of 20 scans per day, 5.5 days per week, from 4 weeks after delivery to April 2025. 4 Precision DL with Omni Legend 32cm data improves Contrast Recovery (CR) by 11% on average and Contrast-to-Noise Ratio (CNR) by average of 23% as compared to non-ToF reconstruction. CR and CNR demonstrated using clinical data with inserted lesions of known size, location, and contrast. Using data from Omni Legend 32 cm, CR and CNR were measured using High Precision DL and QCHD. 5 Precision DL with Omni Legend 32cm improves feature quantitation accuracy by 14% as compared to Discovery MI with ToF reconstruction, at comparable noise level. Quantitation accuracy demonstrated using clinical data with inserted lesions of known size, location, and contrast (ground truth). Feature SUVmean from Omni Legend 32 cm with High Precision DL compared to SUVmean from Discovery MI 25 cm with QCFX. July 16, 2025 — Artificial intelligence can improve diagnostic consistency and reduce false-positives in prostate cancer ... July 21, 2025 — Siemens Healthineers has received Food and Drug Administration clearance for two multifunctional imaging ... QT Imaging Holdings, Inc. has announced the launch of its latest QTviewer, version 2.8. QTviewer stores and displays the ... July 9, 2025 — Artera, the developer of multimodal artificial intelligence (MMAI)-based prognostic and predictive cancer ... July 2, 2025 — Philips has received FDA 510(k) clearance for SmartSpeed Precise[1] MR’s latest deep learning ... July 1, 2025 — UPDATE: The final paper is now available at: JMIR AI - ChatGPT-4–Driven Liver Ultrasound Radiomics ... June 26, 2025 — Siemens Healthineers has received Food and Drug Administration clearance for the Magnetom Flow.Ace, its ... June 26, 2025 – Quibim, a global provider of quantitative medical imaging solutions, has launched AI-QUAL, a new feature ... Jun. 24, 2025 — GE HealthCare has announced that the U.S. Food and Drug Administration (FDA) approved an updated label ... June 24, 2025 —Smart Soft Healthcare has announced that CoLumbo, the company's advanced AI spine assistant, has received ... See All Webinars This is a modal window. Beginning of dialog window. Escape will cancel and close the window. End of dialog window. This is a modal window. This modal can be closed by pressing the Escape key or activating the close button. See All Videos See All Blogs  See All Comparison Charts  By continuing to browse or by clicking “Accept” you agree to the storing of cookies on your device to enhance your site experience and for analytical and marketing purposes. To learn more about how we use cookies, please see our"
  },
  {
    "title": "The World’s Fastest-Growing Market: MENA’s AI Healthcare Surge - waya.media",
    "url": "https://news.google.com/rss/articles/CBMihgFBVV95cUxPemEyUWt2YmZiYTdYTG43WldYdkRpZ0xiQ0VVemU3VmJBcGo4dXE3UUNPLTFGbFM1NUVGN0dfRmx5MUMxQk5XUC1yeVhIRGgxZ2NlNVNnNTF1YzhJV1MtQTZmTUp5SnM1RzJWNEcxMTV4Nm85X3huMV9pNmZEc1EycTlxRHFuUQ?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "Enter Your Email                             By the Numbers is a biweekly data-driven series in partnership with EFG Holding that unpacks business news and economic trends across the MENA region. Through visuals and statistics, each edition brings clarity to the numbers shaping the future of our region. Artificial intelligence is no longer a futuristic concept in Middle Eastern and North African healthcare; it’s the engine of a huge shift. Fueled by exploding data, strategic investments, and a growing demand for personalized care, the region is poised to transform how diseases are diagnosed, treatments are tailored, and lives are saved. AI in healthcare refers to technologies that mimic human intelligence to support or automate medical tasks. This includes: Its global size was estimated at USD 26.69 billion in 2024, dominated by the U.S. and China. But in MENA, a new story is unfolding, one tied to national health transformations, regulatory modernization, and cross-sector investment. Source: BCC Research.  Beyond the numbers, the data tells an interesting story: Unlike global markets driven by chronic disease burdens or rapidly growing geriatric population, MENA’s boom stems from: The digitization of health systems has led to a surge in medical data, ranging from electronic health records to imaging and genetic profiles. This explosion of data is fueling demand for AI solutions capable of processing large datasets rapidly and accurately. These databases are becoming more integrated and comprehensive, enabling AI to support earlier diagnoses, identify treatment patterns, and generate personalized insights. With chronic disease on the rise and prevention becoming more central, AI’s predictive power is emerging as a game-changer. The more data these systems ingest, the more effective and intelligent they become, positioning AI as a cornerstone of MENA’s data-driven healthcare transformation. Governments and private players across the region are significantly ramping up investments in AI infrastructure—think data centers, hospital digitalization, and national AI strategies.  Countries like Saudi Arabia and the UAE are leading the way, combining financial muscle with policy support to build high-capacity data environments for AI in healthcare.  But increasingly, private capital is stepping in to scale the transformation.  In Saudi Arabia, EFG Hermes advised on the $500M IPO of Specialized Medical Company (SMC), which is aligned with NPHIES, the Kingdom’s AI-enabled health and insurance integration platform. In Egypt, EFG Hermes also led a $190M DPI investment into Alameda Healthcare, which is deploying AI-based oncology diagnostics. Together, these moves signal that AI in MENA healthcare is becoming investable, not just aspirational. AI is powering a shift from reactive to proactive healthcare. By analyzing individual patient data—such as genetics, lifestyle, and health history—AI systems can help design more precise and effective treatment plans. This emphasis on personalized care is especially relevant in MENA, where healthcare delivery systems vary in maturity and access. AI-driven personalization offers a pathway to improve outcomes while optimizing resources. From predictive modeling to treatment customization, the advancements in AI capabilities have made it crucial to respond to modern medical needs. Unlike a few years ago, several MENA countries are now actively developing AI governance frameworks that account for data privacy, ethics, and cybersecurity. Saudi Arabia and the UAE, in particular, have taken early steps to build policy environments that enable AI adoption while safeguarding patients’ rights. This balance is essential for scaling AI across clinical settings and for building public trust in new technologies. The growth outlook is promising, but not without friction. Three structural challenges still threaten to hold the region back: While progress has been made, many MENA countries still lack comprehensive, sector-specific AI regulations. This creates uncertainty for investors and healthcare providers navigating implementation. Without regionally aligned standards, scaling AI solutions across borders remains difficult. Tailoring guidelines to local contexts—while aligning with international frameworks—will be key. AI’s potential hinges on people as much as platforms. The region faces a shortage of healthcare professionals trained in AI applications, from data interpretation to system integration. To address this, countries must invest in interdisciplinary education, bringing together healthcare, data science, and engineering through tailored programs and industry-academic partnerships. As medical data becomes the fuel for AI, the stakes of protecting it grow. Cybersecurity vulnerabilities and unclear data handling rules can stall adoption and erode trust. A proactive approach to data governance—rooted in secure infrastructure, transparent consent protocols, and regional best practices—is essential. Beyond diagnostics, expect to see AI expand into clinical decision support, workflow automation, real-time patient monitoring, and mental health tools. These use cases promise efficiency gains and improved outcomes. Collaboration will define the next chapter. Governments, hospitals, tech firms, and research institutions are increasingly joining forces to drive innovation. These alliances will be crucial for overcoming fragmentation and resource constraints. We anticipate more countries in the region to introduce clear AI health policies, paving the way for cross-border data exchange and investment. Innovation hubs, particularly in the Gulf, will likely serve as testbeds for regional rollouts. If you see something out of place or would like to contribute to this story, check out our Ethics and Policy section. \n                                    Saudi’s Half Yearly Funding Despite macroeconomic uncertainties, Saudi recorded a triple digit year-on-year funding increase. Magnitt’s H1 2025 Saudi Arabia Venture Capital report sponsored by SVC details Saudi’s VC performance. It offers insights on what is driving investment activity, and...  \n                                    Valu Valu, fintech giant, patterned with RoboGarden Egypt, AI-powered EdTech platform, to provide flexible payment plans for the “Learn to Earn” initiative.  Walid Hassouna, CEO of Valu, said, “ As we expand beyond the traditional buy-now-pay-later model, initiatives like ‘Learn...  \n                                    ZabonEx What happened? Oman-based startup, ZabonEx, secured USD 100 thousand in a pre-seed investment round. The round was led by Future Fund Oman and ITHCA Group. What is next? With the newly acquired funds, it aims to expand its smart...  \n                                    Flend Egypt’s SME financing platform, Flend, raised USD 3 million in a seed funding round compromising both equity and debt.  The equity round was led by Egypt Ventures, with participation from Camel Ventures, Sukna Ventures, Plus  VC, and Banque Misr....  \n                                    Egypt is a prime summer destination for many worldwide, however prices are on the rise due to high demand and inflation. It is becoming increasingly expensive to travel and book a stay at coastal destinations. As prices rise and Egypt...  \n                                    Qlub What happened? UAE-based restaurant payments startup, Qlub, raised USD 30 million in a new funding round. The round was co-led by Shorooq and Cherry Ventures, with participation e&, Mubadala Investments, and Legend Capital. Who are they? Founded in 2021...  \n                                    Baby Grok On July 20th 2025, Elon Musk announced on X that his artificial intelligence startup, xAI, will develop an app dedicated to kid-friendly content. He further states that it will be called Baby Grok. However, in his announcement he...  \n                                    Monsha’at Saudi’s Small and Medium Enterprises General Authority “Monsha’at” is launching a Media and Marketing week. It will run from July 20 to July 24 across its support centers in Riyadh, Madina, Jeddah,and Alkhobar.  This initiative is bringing together over...  \n                                    Maroc Telecom What happened? IFC and Maroc Telecom are building a long-term partnership to support the subsidiaries of Maroc Telecom in Chad and Mali.  Through this partnership, IFC will provide two loans for a total amount of  USD 430M (EUR...  \n                                    Ovasave What happened? UAE-based Ovasave, a Hub71 FemTech startup, secured USD 1.2 million in pre-seed funding. The round was led by PlusVC, Annex Investments, and New York-based 25 Madison. It also saw additional backing from the UAE and Saudi-based strategic...  All rights reserved. WAYA Media 2020"
  },
  {
    "title": "FDA’s Elsa AI Tool Hallucinates Studies, Sparks Concern Over Lack Of Oversight In High-Stakes Healthcare Decisions Where Accuracy Directly Impacts Public Safety And Trust - Wccftech",
    "url": "https://news.google.com/rss/articles/CBMimgJBVV95cUxOa0w1d2xWRU1MZFI5M3lvNC1uQjN6NW9LRVhJOTU4UHpZSUI2OFFCSFVWYjktQnpKZkotUlZ2eXZkM3pzVGVJVURKaG45RUpKOF9kT1BHSzZVT3lCRGI5UnVPWklBR2ZaM0RBVHVjaVY3ZGtycXVpQks5SFp6MGRUdDVVRXZaTFlEOVZRckgwYThmaVFuOVRmN1ZZZUJDSV91TEhwUmlxWWxCeVRxcFJfQ214SURHb3lzaG5xWDJxY0d5X2taZFpxUUpmMFpsUE9QUXJEbDVkaG5FZXRDRnZWN1IyeXByRG1YbG5vc21kdE9kY1I1a1Fod0p1SFhGOEtMOTlsTm1NcGV0bU1xOGs4RTVfUlI2T0kzUlHSAZ8CQVVfeXFMTXYwNXFRTWhRMkJteDF3MjdVRzFVVFphclpIRDhyMm5wM21xaHMwOTVOUTk4Rzc4Mmx0OWRDU2JFZEhJWEhla2VZU3lOMUdqZ1NXX2VxRm11LWs0Zlh1U2hLREdjMmZ0UU5sbmQ5RndOSk94bDNnSGpiQTRQcVNvVU5adkt0dlJiYTVUMjJvYThIM0RTUTVkeC02ZDJPaTZxdkZJRTJsNHpXVVBwQjNFalQ2aDVsNVFmOTdHTDY2WGRFYVRqMGF3S2ZVYlItWlFpUEtkemJGVDZWc1BqR3BMcHY5MUlPd2w0WU01cDlBZ3IwLTg5VDJQUE14eDRCM1VxcXd4ZDdqejdvUm90Y3J6V0dOWXk2RjZiU1RwU1RxTXM?oc=5&hl=en-US&gl=US&ceid=US:en",
    "text": "With artificial intelligence being adopted rapidly, varied domains are increasingly looking for ways to implement the technology in order to improve efficiency and save time. We see a vast use of AI assistants for smoother processes. It has not been long since the FDA rolled out Elsa, its generative AI tool that was meant to be a forward-thinking move, to help improve drug and medical device approval workflows, but it seems like the platform is not as smooth as we would hope. Reports from the company's former and current employees are coming forward about the tool hallucinating and often misrepresenting real research. Just like the world at large is evolving, healthcare and regulatory tech are also inclined towards adopting generative AI to help streamline processes. The U.S. Food and Drug Administration introduced Elsa, an AI tool to help make drug and device approval seamless by cutting down on bureaucratic delays and enhancing overall efficiency by reducing administrative workloads. However, what was meant to be a technological leap turned out to be a deeply concerning move, raising questions regarding overdependence on technology and human negligence. While everything looked revolutionary on paper, given how efficiently life-saving treatments could be reviewed, the internal staff at the FDA laid out the true details about the tool. According to the report by CNN, many former and current employees have expressed disquiet about the generative AI tool hallucinating, generating inaccurate summaries, and even fabricating entire clinical studies, as references to these papers do not even exist. At least three employees have revealed the troubling tendency of the tool and how it would go to the extent of distorting actual research findings. This seems especially concerning, given that the assistant's very purpose is to save time without having to be supervised. FDA leadership did not show much urgency when the issue surrounding Elsa was brought to their attention. They were also quick to point out that the staff is not required to use Elsa and that implementing the tool is completely voluntary. The staff are not made to attend the training sessions unless they want to. This means no systems are in place to ensure the tool is used properly and safely. AI hallucinations are not rare occurrences, and these glitches sometimes occur due to updates or changes. However, if the tool is being used in high-stakes settings, then proper safeguards need to be in place. The issue is not with some flaws coming up in the AI tool but rather its use without enough human supervision, especially in a field where small errors can have serious consequences for people's health.   Some posts on wccftech.com may contain affiliate links. We are a participant in the Amazon Services LLC\n\t\t\t\tAssociates Program, an affiliate advertising program designed to provide a means for sites to earn\n\t\t\t\tadvertising fees by advertising and linking to amazon.com © 2025 WCCF TECH INC. 700 - 401 West Georgia Street, Vancouver, BC, Canada"
  }
]